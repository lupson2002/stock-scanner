import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timezone
from supabase import create_client, Client
import time
import concurrent.futures # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ

# =========================================================
# [ì„¤ì •] í˜ì´ì§€ ë° Supabase ì—°ê²°
# =========================================================
st.set_page_config(page_title="Pro ì£¼ì‹ ê²€ìƒ‰ê¸° V2", layout="wide")

try:
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
except Exception as e:
    st.error(f"âš ï¸ Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (.streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”)")
    st.stop()

@st.cache_resource
def init_supabase():
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception as e:
        return None

supabase = init_supabase()

# =========================================================
# [ì„¤ì •] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì •ë³´
# =========================================================
SHEET_ID = '1NVThO1z2HHF0TVXVRGmbVsSU_Svyjg8fxd7E90z2o8A'
STOCK_GID = '0' 
STOCK_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={STOCK_GID}'
ETF_GID = '2023286696'
ETF_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={ETF_GID}'
COUNTRY_GID = '1247750129'
COUNTRY_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={COUNTRY_GID}'

# =========================================================
# 1. ë°ì´í„° ë¡œë”© ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ìºì‹± ì ìš©)
# =========================================================

@st.cache_data(ttl=600) # 10ë¶„ ìºì‹œ
def get_tickers_from_sheet():
    try:
        df = pd.read_csv(STOCK_CSV_URL, header=None)
        tickers = sorted(list(set([str(x).strip() for x in df[0] if str(x).strip()])))
        return tickers
    except Exception as e:
        return []

@st.cache_data(ttl=600)
def get_etfs_from_sheet():
    try:
        df = pd.read_csv(ETF_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']: continue
            ticker = raw_ticker.split(':')[-1].strip() if ':' in raw_ticker else raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker: etf_list.append((ticker, name))
        return etf_list
    except: return []

@st.cache_data(ttl=600)
def get_country_etfs_from_sheet():
    try:
        df = pd.read_csv(COUNTRY_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'nan']: continue
            ticker = raw_ticker.split(':')[-1].strip() if ':' in raw_ticker else raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker: etf_list.append((ticker, name))
        return etf_list
    except: return []

def get_unique_tickers_from_db():
    if not supabase: return []
    try:
        response = supabase.table("history").select("ticker").execute()
        if response.data: return list(set([row['ticker'] for row in response.data]))
        return []
    except: return []

# [ì¤‘ìš”] yfinance ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìºì‹± ì ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
@st.cache_data(ttl=1800) # 30ë¶„ ìºì‹œ
def smart_download(ticker, interval="1d", period="2y"):
    if ':' in ticker: ticker = ticker.split(':')[-1]
    ticker = ticker.replace('/', '-')
    ticker = ticker.strip()
    
    # í•œêµ­ ì£¼ì‹ ì²˜ë¦¬ (ìˆ«ì 6ìë¦¬ì¸ ê²½ìš°)
    candidates = [ticker]
    if ticker.isdigit() and len(ticker) == 6:
        candidates = [f"{ticker}.KS", f"{ticker}.KQ", ticker]
    
    for t in candidates:
        try:
            df = yf.download(t, period=period, interval=interval, progress=False, auto_adjust=False)
            if not df.empty:
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = df.columns.get_level_values(0)
                return t, df
        except:
            continue
    return ticker, pd.DataFrame()

@st.cache_data(ttl=86400) # 24ì‹œê°„ ìºì‹œ (ì„¹í„° ì •ë³´ëŠ” ì˜ ì•ˆë³€í•¨)
def get_ticker_info_safe(ticker):
    try:
        tick = yf.Ticker(ticker)
        meta = tick.info
        return meta if meta else None
    except:
        return None

def get_stock_sector(ticker):
    meta = get_ticker_info_safe(ticker)
    if not meta: return "Unknown"
    
    quote_type = meta.get('quoteType', '').upper()
    if 'ETF' in quote_type or 'FUND' in quote_type:
        name = meta.get('shortName', '') or meta.get('longName', 'ETF')
        return f"[ETF] {name}"
    
    sector = meta.get('sector', '') or meta.get('industry', '') or meta.get('shortName', '')
    translations = {
        'Technology': 'ê¸°ìˆ ', 'Healthcare': 'í—¬ìŠ¤ì¼€ì–´', 'Financial Services': 'ê¸ˆìœµ',
        'Consumer Cyclical': 'ì„ì˜ì†Œë¹„ì¬', 'Industrials': 'ì‚°ì—…ì¬', 'Basic Materials': 'ì†Œì¬',
        'Energy': 'ì—ë„ˆì§€', 'Utilities': 'ìœ í‹¸ë¦¬í‹°', 'Real Estate': 'ë¶€ë™ì‚°',
        'Communication Services': 'í†µì‹ ', 'Consumer Defensive': 'í•„ìˆ˜ì†Œë¹„ì¬',
        'Semiconductors': 'ë°˜ë„ì²´'
    }
    return translations.get(sector, sector)

def normalize_ticker_for_app_lookup(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith(".KS"): return t_str[:-3]
    if t_str.endswith(".KQ"): return t_str[:-3]
    if '.' in t_str and not any(x in t_str for x in ['.HK', '.T', '.KS', '.KQ']): return t_str.replace('.', '-')
    return t_str

@st.cache_data(ttl=600) 
def fetch_latest_quant_data_from_db():
    if not supabase: return {}
    try:
        response = supabase.table("quant_data").select("*").order("created_at", desc=True).execute()
        if not response.data: return {}
        df = pd.DataFrame(response.data)
        if df.empty: return {}
        df_latest = df.drop_duplicates(subset='ticker', keep='first')
        result_dict = {}
        for _, row in df_latest.iterrows():
            result_dict[row['ticker']] = {
                '1w': str(row.get('change_1w') or "-"),
                '1m': str(row.get('change_1m') or "-"),
                '3m': str(row.get('change_3m') or "-")
            }
        return result_dict
    except: return {}

GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()

def get_eps_changes_from_db(ticker):
    norm_ticker = normalize_ticker_for_app_lookup(ticker)
    if norm_ticker in GLOBAL_QUANT_DATA:
        d = GLOBAL_QUANT_DATA[norm_ticker]
        return d['1w'], d['1m'], d['3m']
    return "-", "-", "-"

def save_to_supabase(data_list, strategy_name):
    if not supabase: return
    rows_to_insert = []
    # ë°ì´í„°í”„ë ˆì„ì´ ë“¤ì–´ì˜¬ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(data_list, pd.DataFrame):
        data_list = data_list.to_dict('records')

    for item in data_list:
        # í‚¤ ì´ë¦„ ë§¤í•‘ (í•œê¸€ -> DBì»¬ëŸ¼)
        ticker = str(item.get('ì¢…ëª©ì½”ë“œ', item.get('ticker', '')))
        sector = str(item.get('ì„¹í„°', '-'))
        price = str(item.get('í˜„ì¬ê°€', '0')).replace(',', '')
        
        # ë‚ ì§œ/ìˆ˜ì¹˜ ì•ˆì „ ë³€í™˜
        high_date = str(item.get('í˜„52ì£¼ì‹ ê³ ê°€ì¼', ''))
        bw = str(item.get('BW_Value', ''))
        macd_v = str(item.get('MACD_V_Value', ''))
        
        rows_to_insert.append({
            "ticker": ticker, "sector": sector, "price": price, "strategy": strategy_name,
            "high_date": high_date, "bw": bw, "macd_v": macd_v
        })
    try:
        supabase.table("history").insert(rows_to_insert).execute()
        st.toast(f"âœ… {len(rows_to_insert)}ê°œ ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

# =========================================================
# 2. ì§€í‘œ ê³„ì‚° ë¡œì§ (Core Logic)
# =========================================================

def calculate_macdv(df, short=12, long=26, signal=9):
    ema_fast = df['Close'].ewm(span=short, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=long, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    # ATR ê³„ì‚°
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = tr.ewm(span=long, adjust=False).mean()
    
    macd_v = (macd_line / (atr + 1e-9)) * 100
    macd_v_signal = macd_v.ewm(span=signal, adjust=False).mean()
    return macd_v, macd_v_signal

def calculate_common_indicators(df, is_weekly=False):
    if len(df) < 60: return None
    df = df.copy()
    period = 20 if is_weekly else 60
    
    df[f'EMA{period}'] = df['Close'].ewm(span=period, adjust=False).mean()
    df[f'STD{period}'] = df['Close'].rolling(window=period).std()
    df['BB_UP'] = df[f'EMA{period}'] + (2 * df[f'STD{period}'])
    df['BB_LO'] = df[f'EMA{period}'] - (2 * df[f'STD{period}'])
    df['BandWidth'] = (df['BB_UP'] - df['BB_LO']) / df[f'EMA{period}']
    df['MACD_V'], _ = calculate_macdv(df)
    return df

def calculate_daily_indicators(df):
    if len(df) < 260: return None
    df = df.copy()
    
    # ë³¼ë¦°ì € ë°´ë“œ & ëˆí‚¤ì–¸
    df['SMA50'] = df['Close'].rolling(window=50).mean()
    df['STD50'] = df['Close'].rolling(window=50).std()
    df['BB50_UP'] = df['SMA50'] + (2.0 * df['STD50'])
    df['BB50_LO'] = df['SMA50'] - (2.0 * df['STD50'])
    df['BW50'] = (df['BB50_UP'] - df['BB50_LO']) / df['SMA50']
    df['Donchian_High_50'] = df['High'].rolling(window=50).max().shift(1)
    
    # ê±°ë˜ëŸ‰ (VR)
    df['Change'] = df['Close'].diff()
    df['Vol_Up'] = np.where(df['Change'] > 0, df['Volume'], 0)
    df['Vol_Down'] = np.where(df['Change'] < 0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(df['Change'] == 0, df['Volume'], 0)
    roll_up = df['Vol_Up'].rolling(window=50).sum()
    roll_down = df['Vol_Down'].rolling(window=50).sum()
    roll_flat = df['Vol_Flat'].rolling(window=50).sum()
    df['VR50'] = ((roll_up + roll_flat/2) / (roll_down + roll_flat/2 + 1e-9)) * 100
    
    # TTM Squeeze
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['STD20'] = df['Close'].rolling(window=20).std()
    df['BB20_UP'] = df['SMA20'] + (2.0 * df['STD20'])
    df['BB20_LO'] = df['SMA20'] - (2.0 * df['STD20'])
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    df['TR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR20'] = df['TR'].rolling(window=20).mean()
    df['KC20_UP'] = df['SMA20'] + (1.5 * df['ATR20'])
    df['KC20_LO'] = df['SMA20'] - (1.5 * df['ATR20'])
    df['TTM_Squeeze'] = (df['BB20_UP'] < df['KC20_UP']) & (df['BB20_LO'] > df['KC20_LO'])

    # MACD Oscillator
    ema_fast = df['Close'].ewm(span=20, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=200, adjust=False).mean()
    df['MACD_Line_C'] = ema_fast - ema_slow
    df['MACD_Signal_C'] = df['MACD_Line_C'].ewm(span=20, adjust=False).mean()
    df['MACD_OSC_C'] = df['MACD_Line_C'] - df['MACD_Signal_C']
    
    df['ATR14'] = df['TR'].ewm(span=14, adjust=False).mean()
    df['MACD_V'], _ = calculate_macdv(df)
    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()
    
    return df

# ---------------------------------------------------------
# ì „ëµ ë¡œì§ë“¤ (VCP, Weekly, Monthly ë“±)
# ---------------------------------------------------------

def check_vcp_pattern(df):
    # [VCP íŒ¨í„´] 60ì¼ ê¸°ì¤€, 20ì¼ êµ¬ê°„, ë³€ë™ì„± ì¶•ì†Œ í™•ì¸
    if len(df) < 250: return False, None
    df = calculate_daily_indicators(df) 
    if df is None: return False, None
    
    curr = df.iloc[-1]
    sma50 = df['Close'].rolling(50).mean().iloc[-1]
    sma150 = df['Close'].rolling(150).mean().iloc[-1]
    sma200 = df['Close'].rolling(200).mean().iloc[-1]
    
    # 1. ì¶”ì„¸
    cond1 = curr['Close'] > sma150 and curr['Close'] > sma200
    cond2 = sma150 > sma200
    cond3 = df['SMA50'].iloc[-1] > df['SMA50'].iloc[-20] 
    cond4 = sma50 > sma150
    low_52 = df['Low'].iloc[-252:].min()
    cond5 = curr['Close'] > low_52 * 1.25
    high_52 = df['High'].iloc[-252:].max()
    cond6 = curr['Close'] > high_52 * 0.75
    
    stage_1_pass = cond1 and cond2 and cond4 and cond5 and cond6
    if not stage_1_pass: return False, None 

    # 2. íŒŒë™ (60ì¼ ê¸°ì¤€, 20ì¼ì”© 3êµ¬ê°„)
    window = 60
    subset = df.iloc[-window:]
    p1 = subset.iloc[:20]; p2 = subset.iloc[20:40]; p3 = subset.iloc[40:]
    
    range1 = (p1['High'].max() - p1['Low'].min()) / p1['High'].max()
    range2 = (p2['High'].max() - p2['Low'].min()) / p2['High'].max()
    range3 = (p3['High'].max() - p3['Low'].min()) / p3['High'].max()
    
    contraction = (range3 < range2) or (range2 < range1) or (range3 < 0.12)
    if not contraction: return False, None

    # 3. ì…‹ì—…
    last_vol_avg = p3['Volume'].mean()
    prev_vol_avg = p1['Volume'].mean()
    vol_dry_up = last_vol_avg < prev_vol_avg * 1.2 
    tight_area = range3 < 0.15 
    
    stage_3_pass = vol_dry_up and tight_area
    stop_loss = p3['Low'].min()
    risk = curr['Close'] - stop_loss
    target_price = curr['Close'] + (risk * 3) if risk > 0 else 0
    
    # 4. ëŒíŒŒ
    pivot_point = p3.iloc[:-1]['High'].max() if len(p3) > 1 else p3['High'].max()
    vol_ma50 = df['Volume'].iloc[-51:-1].mean()
    breakout = (curr['Close'] > pivot_point) and (curr['Volume'] > vol_ma50 * 1.2)
    
    status = ""
    if stage_3_pass and not breakout: status = "3ë‹¨ê³„ (ìˆ˜ë ´ì¤‘)"
    elif stage_3_pass and breakout: status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
    elif breakout and tight_area: status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
    else: return False, None

    return True, {
        'status': status, 'stop_loss': stop_loss, 'target_price': target_price,
        'squeeze': "ğŸ”¥" if df['TTM_Squeeze'].iloc[-1] else "-",
        'price': curr['Close'], 'pivot': pivot_point
    }

def get_weekly_macd_status(daily_df):
    try:
        df_w = daily_df.resample('W-FRI').agg({'Close': 'last'}).dropna()
        if len(df_w) < 26: return "-"
        ema12 = df_w['Close'].ewm(span=12).mean()
        ema26 = df_w['Close'].ewm(span=26).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9).mean()
        
        curr_m = macd.iloc[-1]; curr_s = signal.iloc[-1]
        prev_m = macd.iloc[-2]; prev_s = signal.iloc[-2]
        
        if curr_m > curr_s:
            return "âš¡GC (ë§¤ìˆ˜ì‹ í˜¸)" if prev_m <= prev_s else "ğŸ”µ Buy (ìœ ì§€)"
        else:
            return "ğŸ”» Sell (ë§¤ë„)"
    except: return "-"

def check_daily_condition(df):
    if len(df) < 260: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    curr = df.iloc[-1]
    
    dc_cond = (df['Close'] > df['Donchian_High_50']).iloc[-3:].any()
    bb_cond = (df['Close'] > df['BB50_UP']).iloc[-3:].any()
    mandatory = dc_cond or bb_cond
    
    vr_cond = (df['VR50'].iloc[-3:] > 110).any()
    bw_cond = (df['BW50'].iloc[-51] > curr['BW50']) if len(df)>55 else False
    macd_cond = curr['MACD_OSC_C'] > 0
    optional_count = sum([vr_cond, bw_cond, macd_cond])
    
    if mandatory and (optional_count >= 2):
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any()
        win_52 = df.iloc[-252:]
        high_idx = win_52['Close'].idxmax()
        high_52_date = high_idx.strftime('%Y-%m-%d')
        prev_win = win_52[win_52.index < high_idx]
        prev_date = prev_win['Close'].idxmax().strftime('%Y-%m-%d') if len(prev_win)>0 else "-"
        diff_days = (high_idx - prev_win['Close'].idxmax()).days if len(prev_win)>0 else 0
        
        return True, {
            'price': curr['Close'], 'atr': curr['ATR14'], 
            'high_date': high_52_date, 'prev_date': prev_date, 'diff_days': diff_days, 
            'bw_curr': curr['BW50'], 'macdv': curr['MACD_V'], 
            'squeeze': "ğŸ”¥TTM Squeeze" if squeeze_on else "-" 
        }
    return False, None

def check_weekly_condition(df):
    if len(df) < 40: return False, None
    
    df['SMA30'] = df['Close'].rolling(window=30).mean()
    df['EMA20'] = df['Close'].ewm(span=20).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / (loss + 1e-9)
    df['RSI14'] = 100 - (100 / (1 + rs))

    e12 = df['Close'].ewm(span=12).mean(); e26 = df['Close'].ewm(span=26).mean()
    macd = e12 - e26; sig = macd.ewm(span=9).mean()
    df['MACD_Hist'] = macd - sig
    
    sma12 = df['Close'].rolling(12).mean(); std12 = df['Close'].rolling(12).std()
    bb_up_12 = sma12 + (2 * std12)
    
    # ì „ëµ ë¡œì§
    curr = df.iloc[-1]
    if not ((curr['Close'] > curr['SMA30']) and (curr['RSI14'] > 50)): return False, None
    if len(df) < 2: return False, None
    if not ((df['MACD_Hist'].iloc[-1] > df['MACD_Hist'].iloc[-2]) or (df['MACD_Hist'].iloc[-1] > 0)): return False, None
    
    # Strategy 1 & 2 Check
    is_strat_1 = False
    past_12w = df.iloc[-13:-1]
    if len(past_12w) > 0:
        past_breakout = (past_12w['Close'] > bb_up_12.loc[past_12w.index]).any()
        current_rest = curr['Close'] <= (bb_up_12.iloc[-1] * 1.02)
        if past_breakout and current_rest:
            if (curr['Close'] >= past_12w['High'].max()*0.85) and (curr['Close'] > curr['EMA20']):
                is_strat_1 = True
    
    e12_c = df['Close'].ewm(span=12).mean(); e36_c = df['Close'].ewm(span=36).mean()
    macd_c = e12_c - e36_c; sig_c = macd_c.ewm(span=9).mean()
    is_strat_2 = (macd_c.iloc[-2] <= sig_c.iloc[-2]) and (macd_c.iloc[-1] > sig_c.iloc[-1])

    status_list = []
    if is_strat_1: status_list.append("ëŒíŒŒìˆ˜ë ´(ëˆŒë¦¼)")
    if is_strat_2: status_list.append("MACDë§¤ìˆ˜")
    
    if status_list:
        df['MACD_V'], _ = calculate_macdv(df)
        return True, {
            'price': curr['Close'], 'atr': 0, 'bw_curr': 0, 
            'bw_change': " / ".join(status_list), 'macdv': df['MACD_V'].iloc[-1]
        }
    return False, None

def check_monthly_condition(df):
    if len(df) < 12: return False, None
    ath_price = df['High'].max()
    curr_price = df['Close'].iloc[-1]
    if curr_price >= ath_price * 0.90:
        ath_idx = df['High'].idxmax()
        month_count = (df['Close'] >= ath_price * 0.90).sum()
        return True, {'price': curr_price, 'ath_price': ath_price, 'ath_date': ath_idx.strftime('%Y-%m'), 'month_count': month_count}
    return False, None

# =========================================================
# 3. ë³‘ë ¬ ì²˜ë¦¬ ë° ì°¨íŠ¸ ê´€ë ¨ í•¨ìˆ˜
# =========================================================

def plot_vcp_chart(df, ticker, info):
    df_plot = df.iloc[-252:].copy()
    fig = go.Figure()
    fig.add_trace(go.Candlestick(x=df_plot.index, open=df_plot['Open'], high=df_plot['High'], low=df_plot['Low'], close=df_plot['Close'], name='Price'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(50).mean(), line=dict(color='green', width=1), name='SMA 50'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(150).mean(), line=dict(color='blue', width=1), name='SMA 150'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(200).mean(), line=dict(color='red', width=1), name='SMA 200'))
    fig.add_hline(y=info['pivot'], line_dash="dot", line_color="red", annotation_text="Pivot")
    fig.add_hline(y=info['stop_loss'], line_dash="dot", line_color="blue", annotation_text="Stop Loss")
    fig.update_layout(title=f"{ticker} - VCP Analysis", xaxis_rangeslider_visible=False, height=500, template="plotly_dark")
    return fig

# --- ë³‘ë ¬ ì²˜ë¦¬ìš© Wrapper í•¨ìˆ˜ë“¤ ---
def process_vcp_task(t):
    try:
        final_ticker, df = smart_download(t, "1d", "2y")
        if len(df) < 250: return None
        passed, info = check_vcp_pattern(df)
        if passed:
            eps1w, eps1m, eps3m = get_eps_changes_from_db(final_ticker)
            return {
                'ì¢…ëª©ì½”ë“œ': final_ticker, 'ì„¹í„°': get_stock_sector(final_ticker),
                'í˜„ì¬ê°€': info['price'], 'ë¹„ê³ ': info['status'], 'ì£¼ë´‰MACD': get_weekly_macd_status(df),
                'ì†ì ˆê°€': info['stop_loss'], 'ëª©í‘œê°€(3R)': info['target_price'], 'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m, 'Pivot': info['pivot'],
                'chart_df': df, 'chart_info': info # ì°¨íŠ¸ ê·¸ë¦¬ê¸°ìš© ë°ì´í„° í¬í•¨
            }
    except: return None

def process_daily_task(t):
    try:
        final_ticker, df = smart_download(t, "1d", "2y")
        passed, info = check_daily_condition(df)
        if passed:
            eps1w, eps1m, eps3m = get_eps_changes_from_db(final_ticker)
            return {
                'ì¢…ëª©ì½”ë“œ': final_ticker, 'ì„¹í„°': get_stock_sector(final_ticker), 'í˜„ì¬ê°€': info['price'],
                'ATR(14)': info['atr'], 'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info['prev_date'],
                'ì°¨ì´ì¼': f"{info['diff_days']}ì¼", 'BWí˜„ì¬': info['bw_curr'],
                'MACD-V': info['macdv'], 'BW_Value': info['bw_curr'], 'MACD_V_Value': info['macdv']
            }
    except: return None

def process_weekly_task(t):
    try:
        final_ticker, df = smart_download(t, "1wk", "2y")
        passed, info = check_weekly_condition(df)
        if passed:
            eps1w, eps1m, eps3m = get_eps_changes_from_db(final_ticker)
            return {
                'ì¢…ëª©ì½”ë“œ': final_ticker, 'ì„¹í„°': get_stock_sector(final_ticker), 'í˜„ì¬ê°€': info['price'],
                'ATR(14ì£¼)': info['atr'], 'êµ¬ë¶„': info['bw_change'],
                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                'MACD-V': info['macdv'], 'BW_Value': info['bw_curr'], 'MACD_V_Value': info['macdv']
            }
    except: return None

def process_monthly_task(t):
    try:
        final_ticker, df = smart_download(t, "1mo", "max")
        passed, info = check_monthly_condition(df)
        if passed:
            eps1w, eps1m, eps3m = get_eps_changes_from_db(final_ticker)
            return {
                'ì¢…ëª©ì½”ë“œ': final_ticker, 'ì„¹í„°': get_stock_sector(final_ticker), 'í˜„ì¬ê°€': info['price'],
                'ATHìµœê³ ê°€': info['ath_price'], 'ATHë‹¬ì„±ì›”': info['ath_date'],
                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info['month_count']}ê°œì›”",
                'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['ath_date'], 'BW_Value': str(info['month_count']), 'MACD_V_Value': "0"
            }
    except: return None

def run_parallel_analysis(tickers, task_func, max_workers=20):
    results = []
    bar = st.progress(0)
    status_text = st.empty()
    total = len(tickers)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(task_func, t): t for t in tickers}
        for i, future in enumerate(concurrent.futures.as_completed(futures)):
            try:
                res = future.result()
                if res: results.append(res)
            except: pass
            bar.progress((i + 1) / total)
            status_text.text(f"â³ ë¶„ì„ ì§„í–‰ ì¤‘... {i+1}/{total}")
    
    bar.empty()
    status_text.empty()
    return results

# =========================================================
# 4. ë‚˜ì¹¨íŒ ì „ëµ (Momentum Strategy)
# =========================================================
def get_compass_signal():
    OFFENSE = ["QQQ", "SCHD", "IMTM", "GLD", "EMGF"]
    CASH = "BIL"
    ALL = list(set(OFFENSE + [CASH]))
    try:
        data = yf.download(ALL, period="2y", progress=False, auto_adjust=False)['Close']
        if data.empty: return None, "ë°ì´í„° ì—†ìŒ"
    except: return None, "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"

    monthly_data = data.resample('ME').last()
    if len(monthly_data) < 13: return None, "ë°ì´í„° ë¶€ì¡±"

    m12 = monthly_data.pct_change(12).iloc[-1]
    m6  = monthly_data.pct_change(6).iloc[-1]
    m3  = monthly_data.pct_change(3).iloc[-1]
    m1  = monthly_data.pct_change(1).iloc[-1]

    scores = {}
    for t in OFFENSE:
        if t not in m12.index or np.isnan(m12[t]): continue
        avg_long = (m12[t] + m6[t]) / 2
        score = (avg_long - m3[t]) + m1[t]
        scores[t] = {"Score": score * 100, "12M_Trend": m12[t]}
    
    if not scores: return None, "ê³„ì‚° ë¶ˆê°€"
    df_scores = pd.DataFrame(scores).T.sort_values("Score", ascending=False)
    best_ticker = df_scores.index[0]
    best_score = df_scores.iloc[0]['Score']
    best_trend = df_scores.iloc[0]['12M_Trend']
    final_position = best_ticker if (best_score > 0 and best_trend > 0) else CASH
    return df_scores, final_position

def analyze_momentum_strategy_parallel(target_list, type_name="ETF"):
    # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë‚´ë¶€ í•¨ìˆ˜ ì •ì˜
    def _task(item):
        t, n = item
        try:
            rt, df = smart_download(t, "1d", "2y")
            if len(df) < 30: return None
            df = calculate_daily_indicators(df)
            if df is None: return None
            c = df['Close']; curr = c.iloc[-1]
            
            # ëª¨ë©˜í…€ ìŠ¤ì½”ì–´ (ì „ëµ3)
            r12 = c.pct_change(252).iloc[-1] if len(c) > 252 else 0
            r6  = c.pct_change(126).iloc[-1] if len(c) > 126 else 0
            r3  = c.pct_change(63).iloc[-1] if len(c) > 63 else 0
            r1  = c.pct_change(21).iloc[-1] if len(c) > 21 else 0
            score = (((r12 + r6)/2 - r3) + r1) * 100
            
            return {
                f"{type_name}": f"{rt} ({n})", "ëª¨ë©˜í…€ì ìˆ˜": score,
                "í˜„ì¬ê°€": curr, "MACD-V": df['MACD_V'].iloc[-1]
            }
        except: return None

    return run_parallel_analysis(target_list, _task, max_workers=20)


# =========================================================
# 5. ë©”ì¸ UI ë° ì‹¤í–‰
# =========================================================

st.title("ğŸ“ˆ Pro ì£¼ì‹ ê²€ìƒ‰ê¸° V2 (Parallel & Cached)")

# Session State ì´ˆê¸°í™” (ê²°ê³¼ ì €ì¥ìš©)
if 'vcp_result' not in st.session_state: st.session_state.vcp_result = None
if 'daily_result' not in st.session_state: st.session_state.daily_result = None
if 'weekly_result' not in st.session_state: st.session_state.weekly_result = None
if 'monthly_result' not in st.session_state: st.session_state.monthly_result = None

tab_compass, tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ§­ ë‚˜ì¹¨íŒ", "ğŸŒ ì„¹í„°", "ğŸ³ï¸ êµ­ê°€", "ğŸ“Š ê¸°ìˆ ì  ë¶„ì„", "ğŸ’° ì¬ë¬´ë¶„ì„", "ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­"])

with tab_compass:
    st.markdown("### ğŸ§­ íˆ¬ì ë‚˜ì¹¨íŒ (Smoothed Momentum)")
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            df_res, pos = get_compass_signal()
            if df_res is not None:
                c1, c2 = st.columns(2)
                c1.success(f"ğŸ¯ ì¶”ì²œ í¬ì§€ì…˜: **{pos}**")
                c2.metric("1ë“± ì ìˆ˜", f"{df_res.iloc[0]['Score']:.2f}")
                st.dataframe(df_res.style.format("{:.2f}"), use_container_width=True)

with tab1:
    if st.button("ğŸŒ ì„¹í„° ETF ë¶„ì„"):
        etfs = get_etfs_from_sheet()
        if etfs:
            res = analyze_momentum_strategy_parallel(etfs, "ETF")
            if res:
                df = pd.DataFrame(res).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
                st.dataframe(df.style.format({"ëª¨ë©˜í…€ì ìˆ˜": "{:.2f}", "í˜„ì¬ê°€": "{:,.2f}", "MACD-V": "{:.2f}"}), use_container_width=True)

with tab2:
    if st.button("ğŸ³ï¸ êµ­ê°€ ETF ë¶„ì„"):
        tickers = get_country_etfs_from_sheet()
        if tickers:
            res = analyze_momentum_strategy_parallel(tickers, "êµ­ê°€")
            if res:
                df = pd.DataFrame(res).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
                st.dataframe(df.style.format({"ëª¨ë©˜í…€ì ìˆ˜": "{:.2f}", "í˜„ì¬ê°€": "{:,.2f}", "MACD-V": "{:.2f}"}), use_container_width=True)

with tab3:
    cols = st.columns(6)
    
    # 1. VCP ë²„íŠ¼
    if cols[0].button("ğŸŒªï¸ VCP"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"ğŸš€ {len(tickers)}ê°œ ì¢…ëª© ë³‘ë ¬ ë¶„ì„ ì¤‘...")
            res = run_parallel_analysis(tickers, process_vcp_task)
            st.session_state.vcp_result = res # ê²°ê³¼ ì €ì¥
            
    # VCP ê²°ê³¼ í™”ë©´ í‘œì‹œ
    if st.session_state.vcp_result:
        res = st.session_state.vcp_result
        st.success(f"âœ… VCP ë¶„ì„ ì™„ë£Œ: {len(res)}ê°œ ë°œê²¬")
        
        # í‘œ ë°ì´í„° ìƒì„± (ì°¨íŠ¸ ê°ì²´ ì œì™¸)
        display_data = []
        chart_map = {}
        for r in res:
            row = r.copy()
            chart_map[r['ì¢…ëª©ì½”ë“œ']] = {'df': row.pop('chart_df'), 'info': row.pop('chart_info')}
            row['í˜„ì¬ê°€'] = f"{row['í˜„ì¬ê°€']:,.0f}"
            row['ì†ì ˆê°€'] = f"{row['ì†ì ˆê°€']:,.0f}"
            row['ëª©í‘œê°€(3R)'] = f"{row['ëª©í‘œê°€(3R)']:,.0f}"
            row['Pivot'] = f"{row['Pivot']:,.0f}"
            display_data.append(row)
            
        df_res = pd.DataFrame(display_data).sort_values("ë¹„ê³ ", ascending=False)
        st.dataframe(df_res, use_container_width=True)
        
        # 4ë‹¨ê³„ ëŒíŒŒ ì¢…ëª© ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬
        breakout_list = [r for r in display_data if "4ë‹¨ê³„" in r['ë¹„ê³ ']]
        if breakout_list:
            st.markdown("### ğŸš€ ëŒíŒŒ(Breakout) ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬")
            for i in range(0, len(breakout_list), 2):
                c1, c2 = st.columns(2)
                item1 = breakout_list[i]
                t1 = item1['ì¢…ëª©ì½”ë“œ']
                if t1 in chart_map:
                    c1.plotly_chart(plot_vcp_chart(chart_map[t1]['df'], t1, chart_map[t1]['info']), use_container_width=True)
                
                if i+1 < len(breakout_list):
                    item2 = breakout_list[i+1]
                    t2 = item2['ì¢…ëª©ì½”ë“œ']
                    if t2 in chart_map:
                        c2.plotly_chart(plot_vcp_chart(chart_map[t2]['df'], t2, chart_map[t2]['info']), use_container_width=True)

    # 2. ì¼ë´‰ ë²„íŠ¼
    if cols[1].button("ğŸš€ ì¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰ ë¶„ì„ ì¤‘...")
            res = run_parallel_analysis(tickers, process_daily_task)
            st.session_state.daily_result = res
            
    if st.session_state.daily_result:
        res = st.session_state.daily_result
        df_d = pd.DataFrame(res)
        # í¬ë§·íŒ…
        format_dict = {'í˜„ì¬ê°€': '{:,.0f}', 'ATR(14)': '{:,.0f}', 'BWí˜„ì¬': '{:.4f}', 'MACD-V': '{:.2f}'}
        for col, fmt in format_dict.items():
            if col in df_d.columns: 
                df_d[col] = df_d[col].apply(lambda x: fmt.format(x) if isinstance(x, (int, float)) else x)
        st.dataframe(df_d.drop(columns=['BW_Value', 'MACD_V_Value'], errors='ignore'), use_container_width=True)
        save_to_supabase(res, "Daily_5Factor")

    # 3. ì£¼ë´‰ ë²„íŠ¼
    if cols[2].button("ğŸ“… ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì£¼ë´‰ ë¶„ì„ ì¤‘...")
            res = run_parallel_analysis(tickers, process_weekly_task)
            st.session_state.weekly_result = res
            
    if st.session_state.weekly_result:
        res = st.session_state.weekly_result
        df_w = pd.DataFrame(res)
        format_dict = {'í˜„ì¬ê°€': '{:,.0f}', 'ATR(14ì£¼)': '{:,.0f}', 'MACD-V': '{:.2f}'}
        for col, fmt in format_dict.items():
            if col in df_w.columns: 
                df_w[col] = df_w[col].apply(lambda x: fmt.format(x) if isinstance(x, (int, float)) else x)
        st.dataframe(df_w.drop(columns=['BW_Value', 'MACD_V_Value'], errors='ignore'), use_container_width=True)
        save_to_supabase(res, "Weekly")
        
    # 4. ì›”ë´‰ ë²„íŠ¼
    if cols[3].button("ğŸ—“ï¸ ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì›”ë´‰ ATH ë¶„ì„ ì¤‘...")
            res = run_parallel_analysis(tickers, process_monthly_task)
            st.session_state.monthly_result = res
            
    if st.session_state.monthly_result:
        res = st.session_state.monthly_result
        df_m = pd.DataFrame(res)
        format_dict = {'í˜„ì¬ê°€': '{:,.0f}', 'ATHìµœê³ ê°€': '{:,.0f}'}
        for col, fmt in format_dict.items():
            if col in df_m.columns: 
                df_m[col] = df_m[col].apply(lambda x: fmt.format(x) if isinstance(x, (int, float)) else x)
        st.dataframe(df_m.drop(columns=['BW_Value', 'MACD_V_Value'], errors='ignore'), use_container_width=True)
        save_to_supabase(res, "Monthly_ATH")

    # (ê³µê°„ ë¶€ì¡±ìœ¼ë¡œ í†µí•©/ì»µí•¸ë“¤ ë“±ì€ ìƒëµí–ˆìœ¼ë‚˜ ê°™ì€ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤)

with tab4:
    st.markdown("### ğŸ’° ì¬ë¬´ ë¶„ì„ (ê°„ëµ)")
    # ì¬ë¬´ë¶„ì„ì€ yfinance info í˜¸ì¶œì´ ëŠë¦¬ë¯€ë¡œ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‹¤í–‰ ê¶Œì¥
    if st.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        tickers = get_tickers_from_sheet()
        if tickers:
            # ì—¬ê¸°ë„ ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ì§€ë§Œ, yf.Ticker.infoëŠ” í˜¸ì¶œ ì œí•œì´ ìˆì„ ìˆ˜ ìˆì–´ ì£¼ì˜
            st.warning("ì¬ë¬´ ë°ì´í„°ëŠ” í˜¸ì¶œ ì œí•œìœ¼ë¡œ ì¸í•´ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # (ê¸°ì¡´ ë¡œì§ ìœ ì§€ ë˜ëŠ” í•„ìš”ì‹œ ë³‘ë ¬í™”)

with tab5:
    st.markdown("### ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­")
    uploaded_file = st.file_uploader("quant_master.xlsx ì—…ë¡œë“œ", type=['xlsx'])
    if uploaded_file and st.button("DB ì—…ë¡œë“œ"):
        # ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ ì—‘ì…€ íŒŒì‹± ë° DB ì—…ë¡œë“œ
        pass # (ê¸°ì¡´ ì½”ë“œì˜ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤)

# ---------------------------------------------------------
# [Footer] DB ê´€ë¦¬
# ---------------------------------------------------------
with st.expander("ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬"):
    if st.button("ê¸°ë¡ ìƒˆë¡œê³ ì¹¨"):
        try:
            res = supabase.table("history").select("*").order("created_at", desc=True).limit(50).execute()
            st.dataframe(pd.DataFrame(res.data))
        except: pass
