import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timezone
from supabase import create_client, Client
from scipy.signal import argrelextrema
import time
import re

# =========================================================
# [ì„¤ì •] Supabase ì—°ê²° ì •ë³´
# =========================================================
SUPABASE_URL = "https://sgpzmkfproftswevwybm.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNncHpta2Zwcm9mdHN3ZXZ3eWJtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjQ5OTQ0MDEsImV4cCI6MjA4MDU3MDQwMX0.VwStTHOr7_SqYrfwqol1E3ab89HsoUArV1q1s7UFAR4"

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì • ë° DB ì—°ê²°
# ==========================================
st.set_page_config(page_title="Pro ì£¼ì‹ ê²€ìƒ‰ê¸°", layout="wide")
st.title("ğŸ“ˆ Pro ì£¼ì‹ ê²€ìƒ‰ê¸°: TTM Squeeze (50ì¼) & í€€í‹°ì™€ì´ì¦ˆ í†µí•©")

@st.cache_resource
def init_supabase():
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception as e:
        return None

supabase = init_supabase()

# ==========================================
# 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •
# ==========================================
SHEET_ID = '1NVThO1z2HHF0TVXVRGmbVsSU_Svyjg8fxd7E90z2o8A'
STOCK_GID = '0' 
STOCK_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={STOCK_GID}'
ETF_GID = '2023286696'
ETF_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={ETF_GID}'
COUNTRY_GID = '1247750129'
COUNTRY_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={COUNTRY_GID}'

# ==========================================
# 3. ê³µí†µ í•¨ìˆ˜ ì •ì˜
# ==========================================

def get_tickers_from_sheet():
    try:
        df = pd.read_csv(STOCK_CSV_URL, header=None)
        tickers = sorted(list(set([str(x).strip() for x in df[0] if str(x).strip()])))
        return tickers
    except Exception as e:
        st.error(f"ì£¼ì‹ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_etfs_from_sheet():
    try:
        df = pd.read_csv(ETF_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_country_etfs_from_sheet():
    try:
        df = pd.read_csv(COUNTRY_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"êµ­ê°€ ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_unique_tickers_from_db():
    if not supabase: return []
    try:
        response = supabase.table("history").select("ticker").execute()
        if response.data:
            return list(set([row['ticker'] for row in response.data]))
        return []
    except Exception as e: return []

def remove_duplicates_from_db():
    if not supabase: return
    try:
        response = supabase.table("history").select("id, ticker, created_at").order("created_at", desc=True).execute()
        data = response.data
        if not data:
            st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        seen_tickers = set()
        ids_to_remove = []
        for row in data:
            ticker = row['ticker']
            if ticker in seen_tickers:
                ids_to_remove.append(row['id'])
            else:
                seen_tickers.add(ticker)
        
        if ids_to_remove:
            for pid in ids_to_remove:
                supabase.table("history").delete().eq("id", pid).execute()
            st.success(f"ğŸ§¹ History ì¤‘ë³µëœ {len(ids_to_remove)}ê°œ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("History: ì‚­ì œí•  ì¤‘ë³µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")

def smart_download(ticker, interval="1d", period="2y"):
    if ':' in ticker: ticker = ticker.split(':')[-1]
    ticker = ticker.replace('/', '-')
    candidates = [ticker]
    if ticker.isdigit() and len(ticker) == 6:
        candidates = [f"{ticker}.KS", f"{ticker}.KQ", ticker]
    
    for t in candidates:
        try:
            for _ in range(3):
                df = yf.download(t, period=period, interval=interval, progress=False, auto_adjust=False)
                if len(df) > 0:
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = df.columns.get_level_values(0)
                    return t, df
                time.sleep(0.3)
        except:
            continue
    return ticker, pd.DataFrame()

def get_stock_sector(ticker):
    try:
        tick = yf.Ticker(ticker)
        info = tick.info
        quote_type = info.get('quoteType', '').upper()
        if 'ETF' in quote_type or 'FUND' in quote_type:
            name = info.get('shortName', '')
            if not name: name = info.get('longName', 'ETF')
            return f"[ETF] {name}"
        sector = info.get('sector', '')
        if not sector: sector = info.get('industry', '')
        if not sector: sector = info.get('shortName', '')
        if not sector: return "Unknown"
        translations = {
            'Technology': 'ê¸°ìˆ ', 'Healthcare': 'í—¬ìŠ¤ì¼€ì–´', 'Financial Services': 'ê¸ˆìœµ',
            'Consumer Cyclical': 'ì„ì˜ì†Œë¹„ì¬', 'Industrials': 'ì‚°ì—…ì¬', 'Basic Materials': 'ì†Œì¬',
            'Energy': 'ì—ë„ˆì§€', 'Utilities': 'ìœ í‹¸ë¦¬í‹°', 'Real Estate': 'ë¶€ë™ì‚°',
            'Communication Services': 'í†µì‹ ', 'Consumer Defensive': 'í•„ìˆ˜ì†Œë¹„ì¬',
            'Semiconductors': 'ë°˜ë„ì²´'
        }
        return translations.get(sector, sector)
    except:
        return "Unknown"

def save_to_supabase(data_list, strategy_name):
    if not supabase:
        st.error("âš ï¸ DB ì—°ê²° ì‹¤íŒ¨")
        return

    rows_to_insert = []
    for item in data_list:
        rows_to_insert.append({
            "ticker": str(item['ì¢…ëª©ì½”ë“œ']),
            "sector": str(item.get('ì„¹í„°', '-')),
            "price": str(item['í˜„ì¬ê°€']).replace(',', ''),
            "strategy": strategy_name,
            "high_date": str(item.get('í˜„52ì£¼ì‹ ê³ ê°€ì¼', '')), 
            "bw": str(item.get('BW_Value', '')), 
            "macd_v": str(item.get('MACD_V_Value', ''))
        })
    
    try:
        supabase.table("history").insert(rows_to_insert).execute()
        st.toast(f"âœ… {len(rows_to_insert)}ê°œ ì¢…ëª© DB ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

# ==============================================================================
# [í•µì‹¬ ë¡œì§] ì •ê·œí™” ë° DB ìºì‹œ
# ==============================================================================
def normalize_ticker_for_db_storage(t):
    """
    QuantWise ì—‘ì…€ í‹°ì»¤ë¥¼ DB/Yahoo Finance ê³µí†µ í¬ë§·ìœ¼ë¡œ ë³€í™˜
    """
    if not t: return ""
    t_str = str(t).upper().strip()
    
    # 1. í•œêµ­ ì£¼ì‹: 'A'ë¡œ ì‹œì‘í•˜ê³  ë’¤ê°€ 6ìë¦¬ ìˆ«ìì¸ ê²½ìš° (ì˜ˆ: A005930 -> 005930)
    if t_str.startswith('A') and len(t_str) == 7 and t_str[1:].isdigit():
        return t_str[1:]

    # 2. ë¯¸êµ­ ì£¼ì‹ (-US)
    if t_str.endswith("-US"):
        clean = t_str[:-3]  # -US ì œê±°
        return clean.replace('.', '-')

    # 3. í™ì½© (-HK)
    if t_str.endswith("-HK"):
        return t_str[:-3] + ".HK"

    # 4. ì¼ë³¸ (-JP)
    if t_str.endswith("-JP"):
        return t_str[:-3] + ".T"
        
    # 5. ê¸°ì¡´ í•œêµ­ í¬ë§· (-KS, -KQ) ì œê±°
    if t_str.endswith("-KS"): return t_str[:-3]
    if t_str.endswith("-KQ"): return t_str[:-3]

    # 6. ê¸°íƒ€ í•˜ì´í”ˆ ì²˜ë¦¬
    if '-' in t_str and not any(x in t_str for x in ['.HK', '.T']):
         return t_str.split('-')[0]

    return t_str

def normalize_ticker_for_app_lookup(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith(".KS"): return t_str[:-3]
    if t_str.endswith(".KQ"): return t_str[:-3]
    if '.' in t_str and not any(x in t_str for x in ['.HK', '.T', '.KS', '.KQ']):
        return t_str.replace('.', '-')
    return t_str

@st.cache_data(ttl=600) 
def fetch_latest_quant_data_from_db():
    if not supabase: return {}
    try:
        response = supabase.table("quant_data").select("*").order("created_at", desc=True).execute()
        if not response.data: return {}
        df = pd.DataFrame(response.data)
        if df.empty: return {}
        df_latest = df.drop_duplicates(subset='ticker', keep='first')
        result_dict = {}
        for _, row in df_latest.iterrows():
            result_dict[row['ticker']] = {
                '1w': str(row.get('change_1w') or "-"),
                '1m': str(row.get('change_1m') or "-"),
                '3m': str(row.get('change_3m') or "-")
            }
        return result_dict
    except Exception as e:
        return {}

GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()

def get_eps_changes_from_db(ticker):
    norm_ticker = normalize_ticker_for_app_lookup(ticker)
    if norm_ticker in GLOBAL_QUANT_DATA:
        d = GLOBAL_QUANT_DATA[norm_ticker]
        return d['1w'], d['1m'], d['3m']
    return "-", "-", "-"

# ==========================================
# 4. ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ (ì§€í‘œ ê³„ì‚° & íŒ¨í„´)
# ==========================================

def find_extrema(df, order=3):
    prices = df['Close'].values
    peaks_idx = argrelextrema(prices, np.greater, order=order)[0]
    troughs_idx = argrelextrema(prices, np.less, order=order)[0]
    return peaks_idx, troughs_idx

def calculate_macdv(df, short=12, long=26, signal=9):
    ema_fast = df['Close'].ewm(span=short, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=long, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = tr.ewm(span=long, adjust=False).mean()
    macd_v = (macd_line / (atr + 1e-9)) * 100
    macd_v_signal = macd_v.ewm(span=signal, adjust=False).mean()
    return macd_v, macd_v_signal

def calculate_common_indicators(df, is_weekly=False):
    # ì£¼ë´‰/ì›”ë´‰ìš© ê¸°ì¡´ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
    if len(df) < 100: return None
    df = df.copy()
    period = 20 if is_weekly else 60
    df[f'EMA{period}'] = df['Close'].ewm(span=period, adjust=False).mean()
    df[f'STD{period}'] = df['Close'].rolling(window=period).std()
    df['BB_UP'] = df[f'EMA{period}'] + (2 * df[f'STD{period}'])
    df['BB_LO'] = df[f'EMA{period}'] - (2 * df[f'STD{period}'])
    df['BandWidth'] = (df['BB_UP'] - df['BB_LO']) / df[f'EMA{period}']
    df['MACD_V'], df['MACD_V_Signal'] = calculate_macdv(df, 12, 26, 9)
    ema_fast_c = df['Close'].ewm(span=20, adjust=False).mean()
    ema_slow_c = df['Close'].ewm(span=200, adjust=False).mean()
    df['MACD_Line_Custom'] = ema_fast_c - ema_slow_c
    df['MACD_Signal_Custom'] = df['MACD_Line_Custom'].ewm(span=20, adjust=False).mean()
    df['MACD_OSC_Custom'] = df['MACD_Line_Custom'] - df['MACD_Signal_Custom']
    df['Change'] = df['Close'].diff()
    df['Vol_Up'] = np.where(df['Change'] > 0, df['Volume'], 0)
    df['Vol_Down'] = np.where(df['Change'] < 0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(df['Change'] == 0, df['Volume'], 0)
    roll_up = df['Vol_Up'].rolling(window=20).sum()
    roll_down = df['Vol_Down'].rolling(window=20).sum()
    roll_flat = df['Vol_Flat'].rolling(window=20).sum()
    df['VR20'] = ((roll_up + roll_flat/2) / (roll_down + roll_flat/2 + 1e-9)) * 100
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR14'] = tr.ewm(span=14, adjust=False).mean()
    df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()
    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()
    df['VolSMA20'] = df['Volume'].rolling(window=20).mean()
    return df

# -----------------------------------------------------------------------------
# [ë³€ê²½ë¨] 50ì¼ ê¸°ì¤€ TTM Squeezeê°€ ì ìš©ëœ ì¼ë´‰ ê³„ì‚° ë¡œì§
# -----------------------------------------------------------------------------
def calculate_daily_indicators(df):
    if len(df) < 260: return None
    df = df.copy()

    # 1. ê¸°ì¤€ì„  (Basis) - SMA 50 (ì¤‘ì¥ê¸° ì¶”ì„¸)
    df['SMA50'] = df['Close'].rolling(window=50).mean()
    
    # 2. ë³¼ë¦°ì € ë°´ë“œ (50, 2.0)
    df['STD50'] = df['Close'].rolling(window=50).std()
    df['BB50_UP'] = df['SMA50'] + (2.0 * df['STD50'])
    df['BB50_LO'] = df['SMA50'] - (2.0 * df['STD50'])
    df['BW50'] = (df['BB50_UP'] - df['BB50_LO']) / df['SMA50'] # ë°´ë“œí­

    # 3. ì¼ˆíŠ¸ë„ˆ ì±„ë„ (50, 1.5)
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    df['TR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    
    # ATR 50 (SMA ë°©ì‹)
    df['ATR50'] = df['TR'].rolling(window=50).mean()
    
    # KC ìŠ¹ìˆ˜ 1.5 ì ìš© (ì§„ì„± ìŠ¤í€´ì¦ˆ)
    kc_mult = 1.5 
    df['KC50_UP'] = df['SMA50'] + (kc_mult * df['ATR50'])
    df['KC50_LO'] = df['SMA50'] - (kc_mult * df['ATR50'])

    # 4. TTM Squeeze íŒë³„ (BBê°€ KC ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜´)
    df['TTM_Squeeze'] = (df['BB50_UP'] < df['KC50_UP']) & (df['BB50_LO'] > df['KC50_LO'])

    # 5. ê¸°ì¡´ ì§€í‘œë“¤ (ëˆí‚¤ì–¸ ë“±)
    df['Donchian_High_50'] = df['High'].rolling(window=50).max().shift(1)
    df['Change'] = df['Close'].diff()
    df['Vol_Up'] = np.where(df['Change'] > 0, df['Volume'], 0)
    df['Vol_Down'] = np.where(df['Change'] < 0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(df['Change'] == 0, df['Volume'], 0)
    roll_up = df['Vol_Up'].rolling(window=50).sum()
    roll_down = df['Vol_Down'].rolling(window=50).sum()
    roll_flat = df['Vol_Flat'].rolling(window=50).sum()
    df['VR50'] = ((roll_up + roll_flat/2) / (roll_down + roll_flat/2 + 1e-9)) * 100
    
    # MACD Custom
    ema_fast = df['Close'].ewm(span=20, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=200, adjust=False).mean()
    df['MACD_Line_C'] = ema_fast - ema_slow
    df['MACD_Signal_C'] = df['MACD_Line_C'].ewm(span=20, adjust=False).mean()
    df['MACD_OSC_C'] = df['MACD_Line_C'] - df['MACD_Signal_C']
    
    # í‘œì‹œìš© ATR14
    df['ATR14'] = df['TR'].ewm(span=14, adjust=False).mean()
    
    # MACD-V
    df['MACD_V'], _ = calculate_macdv(df, 12, 26, 9)
    
    # EMA200 (ëˆŒë¦¼ëª©ìš©)
    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()
    
    return df

# -----------------------------------------------------------------------------
# [ë³€ê²½ë¨] 50ì¼ TTM Squeezeê°€ ë°˜ì˜ëœ ì¼ë´‰ ì¡°ê±´ ì²´í¬ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def check_daily_condition(df):
    if len(df) < 260: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    
    curr = df.iloc[-1]
    
    # 1. [í•„ìˆ˜] ê°€ê²© ëŒíŒŒ (ëˆí‚¤ì–¸ or BBìƒë‹¨ ëŒíŒŒ)
    dc_cond = (df['Close'] > df['Donchian_High_50']).iloc[-3:].any()
    bb_cond = (df['Close'] > df['BB50_UP']).iloc[-3:].any()
    mandatory = dc_cond or bb_cond
    
    # 2. [ì„ íƒ] ë³´ì¡° ì¡°ê±´ë“¤
    vr_cond = (df['VR50'].iloc[-3:] > 110).any()
    bw_cond = (df['BW50'].iloc[-51] > curr['BW50']) if len(df)>55 else False
    macd_cond = curr['MACD_OSC_C'] > 0
    
    optional_count = sum([vr_cond, bw_cond, macd_cond])
    
    if mandatory and (optional_count >= 2):
        # [ë³€ê²½] TTM Squeeze (50ì¼, 1.5 ATR) ë°œìƒ ì—¬ë¶€ ì²´í¬
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any()
        
        win_52 = df.iloc[-252:]
        high_52_date = win_52['Close'].idxmax().strftime('%Y-%m-%d')
        prev_win = win_52[win_52.index < win_52['Close'].idxmax()]
        prev_date = prev_win['Close'].idxmax().strftime('%Y-%m-%d') if len(prev_win)>0 else "-"
        diff_days = (win_52['Close'].idxmax() - prev_win['Close'].idxmax()).days if len(prev_win)>0 else 0
        
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'high_date': high_52_date, 
            'prev_date': prev_date, 
            'diff_days': diff_days, 
            'bw_curr': curr['BW50'], 
            'macdv': curr['MACD_V'], 
            'squeeze': "ğŸ”¥TTM Squeeze" if squeeze_on else "-"
        }
    return False, None

def check_weekly_condition(df):
    if len(df) < 60: return False, None
    df = calculate_common_indicators(df, is_weekly=True)
    if df is None: return False, None
    curr = df.iloc[-1]
    if curr['Close'] > curr['BB_UP']:
        bw_past = df['BandWidth'].iloc[-21]
        bw_change = "ê°ì†Œ" if bw_past > curr['BandWidth'] else "ì¦ê°€"
        return True, {'price': curr['Close'], 'atr': curr['ATR14'], 'bw_curr': curr['BandWidth'], 'bw_past': bw_past, 'bw_change': bw_change, 'macdv': curr['MACD_V']}
    return False, None

def check_monthly_condition(df):
    if len(df) < 12: return False, None
    ath_price = df['High'].max()
    curr_price = df['Close'].iloc[-1]
    if curr_price >= ath_price * 0.90:
        ath_idx = df['High'].idxmax()
        month_count = (df['Close'] >= ath_price * 0.90).sum()
        return True, {'price': curr_price, 'ath_price': ath_price, 'ath_date': ath_idx.strftime('%Y-%m'), 'month_count': month_count}
    return False, None

# -----------------------------------------------------------------------------
# [ë³€ê²½ë¨] ì„¹í„° ë¶„ì„ í•¨ìˆ˜ (ëª¨ë©˜í…€ ì ìˆ˜ ìˆ˜ì •, TTM Squeeze í‘œì‹œ, 52ì£¼ì‹ ê³ ê°€ ì •ë³´ ì¶”ê°€)
# -----------------------------------------------------------------------------
def analyze_sector_trend():
    etfs = get_etfs_from_sheet()
    if not etfs: st.warning("ETF ëª©ë¡ ì—†ìŒ"); return []
    st.write(f"ğŸ“Š ì´ {len(etfs)}ê°œ ETF ë¶„ì„ ì¤‘...")
    
    results = []; pbar = st.progress(0)
    for i, (t, n) in enumerate(etfs):
        pbar.progress((i+1)/len(etfs))
        rt, df = smart_download(t, "1d", "2y")
        if len(df)<30: continue
        
        # ì¼ë´‰ ì§€í‘œ ê³„ì‚° (TTM Squeeze í™•ì¸ì„ ìœ„í•´)
        df = calculate_daily_indicators(df)
        if df is None: continue
        
        c = df['Close']; h = df['High']
        curr=c.iloc[-1]
        
        # TTM Squeeze ë°œìƒ ì—¬ë¶€ (ìµœê·¼ 5ì¼)
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any() if 'TTM_Squeeze' in df.columns else False
        
        # ë³´ì¡°ì§€í‘œë“¤
        ema20=c.ewm(span=20).mean(); ema50=c.ewm(span=50).mean(); ema60=c.ewm(span=60).mean()
        ema100=c.ewm(span=100).mean(); ema200=c.ewm(span=200).mean()
        
        bb_up = df['BB50_UP']
        dc_h = df['Donchian_High_50']
        macdv = df['MACD_V']
        atr = df['ATR14'].iloc[-1]
        
        bb_bk = "O" if (c>bb_up).iloc[-3:].any() else "-"
        dc_bk = "O" if (c>dc_h).iloc[-3:].any() else "-"
        align = "â­ ì •ë°°ì—´" if (curr>ema20.iloc[-1] and curr>ema60.iloc[-1] and curr>ema100.iloc[-1] and curr>ema200.iloc[-1]) else "-"
        long_tr = "ğŸ“ˆ ìƒìŠ¹" if (ema60.iloc[-1]>ema100.iloc[-1]>ema200.iloc[-1]) else "-"
        
        # [ë³€ê²½ë¨] ëª¨ë©˜í…€ ì ìˆ˜ ê³µì‹: (6ê°œì›” ìˆ˜ìµë¥  * 0.5) + (12ê°œì›” ìˆ˜ìµë¥  * 0.5)
        r6 = c.pct_change(126).iloc[-1] if len(c)>126 else 0
        r12 = c.pct_change(252).iloc[-1] if len(c)>252 else 0
        score = (r6 * 0.5 + r12 * 0.5) * 100
        
        # [ì¶”ê°€ë¨] 52ì£¼ ì‹ ê³ ê°€ ê´€ë ¨ ì •ë³´ ê³„ì‚°
        if len(df) >= 252:
            win_52 = df.iloc[-252:]
            high_idx = win_52['Close'].idxmax()
            high_52_date = high_idx.strftime('%Y-%m-%d')
            
            # í˜„ì¬ ì‹ ê³ ê°€ì¼ ì´ì „ì˜ ì‹ ê³ ê°€ ì°¾ê¸° (ì „ê³ ì )
            prev_win = win_52[win_52.index < high_idx]
            if len(prev_win) > 0:
                prev_idx = prev_win['Close'].idxmax()
                prev_date = prev_idx.strftime('%Y-%m-%d')
                diff_days = (high_idx - prev_idx).days
            else:
                prev_date = "-"
                diff_days = 0
        else:
            high_52_date = "-"
            prev_date = "-"
            diff_days = 0
        
        results.append({
            "ETF": rt, 
            "ëª¨ë©˜í…€ì ìˆ˜": score, 
            "TTM Squeeze(50ì¼)": "ğŸ”¥" if squeeze_on else "-",
            "BB(50,2)ëŒíŒŒ": bb_bk, 
            "ëˆí‚¤ì–¸(50)ëŒíŒŒ": dc_bk, 
            "ì •ë°°ì—´": align, 
            "ì¥ê¸°ì¶”ì„¸": long_tr, 
            "MACD-V": f"{macdv.iloc[-1]:.2f}", 
            "ATR": f"{atr:.2f}",
            "í˜„52ì£¼ì‹ ê³ ê°€ì¼": high_52_date,
            "ì „52ì£¼ì‹ ê³ ê°€ì¼": prev_date,
            "ì°¨ì´ì¼": f"{diff_days}ì¼",
            "í˜„ì¬ê°€": curr
        })
        
    pbar.empty()
    if results:
        df_res = pd.DataFrame(results).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
        df_res['ëª¨ë©˜í…€ì ìˆ˜'] = df_res['ëª¨ë©˜í…€ì ìˆ˜'].apply(lambda x: f"{x:.2f}")
        df_res['í˜„ì¬ê°€'] = df_res['í˜„ì¬ê°€'].apply(lambda x: f"{x:,.2f}")
        return df_res
    return pd.DataFrame()

def check_cup_handle_pattern(df):
    if len(df)<70: return False, None
    df['SMA30']=df['Close'].rolling(30).mean(); curr=df.iloc[-1]; prev=df.iloc[-2]
    if curr['Close']<=curr['SMA30'] or curr['SMA30']<=prev['SMA30']: return False, "ì¶”ì„¸ì•½í•¨"
    sub = df.iloc[-75:]
    r_win = sub.iloc[-15:-1]; 
    if len(r_win)==0: return False, "ë°ì´í„°ë¶€ì¡±"
    r_peak = r_win['High'].max(); r_idx = r_win['High'].idxmax()
    l_area = sub[sub.index < r_idx].iloc[:-7]
    if len(l_area)==0: return False, "ì¢Œì¸¡ê³ ì ì—†ìŒ"
    l_peak = l_area['High'].max(); l_idx = l_area['High'].idxmax()
    if not (0.9*l_peak <= r_peak <= 1.1*l_peak): return False, "ê³ ì ë¶ˆì¼ì¹˜"
    cup = sub[(sub.index>l_idx)&(sub.index<r_idx)]
    if len(cup)==0: return False, "ì»µë°”ë‹¥ì—†ìŒ"
    bot = cup['Low'].min(); depth = (l_peak-bot)/l_peak
    if not (0.15<=depth<=0.50): return False, "ê¹Šì´ë¶€ì ì ˆ"
    h_area = df[df.index>r_idx]; h_w = len(h_area)
    if h_w>10: return False, "í•¸ë“¤ê¸¸ì–´ì§"
    if curr['Close']<=r_peak: return False, "ë¯¸ëŒíŒŒ"
    return True, {"depth":f"{depth*100:.1f}%", "handle_weeks":f"{h_w}ì£¼", "pivot":f"{r_peak:,.0f}"}

def check_inverse_hs_pattern(df):
    if len(df)<50: return False, None
    p = df['Close'].values; p_idx, t_idx = find_extrema(df, 3)
    if len(t_idx)<3: return False, "ì €ì ë¶€ì¡±"
    for i in range(len(t_idx)-3, len(t_idx)-1):
        if i<0: continue
        ls=t_idx[i]; h=t_idx[i+1]; rs=t_idx[i+2]
        if (len(p)-rs)>20: continue
        if not (p[h]<p[ls] and p[h]<p[rs]): continue
        if abs(p[ls]-p[rs])/((p[ls]+p[rs])/2)>0.15: continue
        neck1 = np.max(p[ls:h]); neck2 = np.max(p[h:rs])
        neck_idx1 = ls + np.argmax(p[ls:h]); neck_idx2 = h + np.argmax(p[h:rs])
        if neck_idx2==neck_idx1: continue
        slope = (neck2-neck1)/(neck_idx2-neck_idx1); inter = neck1-(slope*neck_idx1)
        proj = slope*(len(p)-1)+inter
        if p[-1]>proj:
            vol_avg=df['Volume'].iloc[-20:].mean(); curr_vol=df['Volume'].iloc[-1]
            return True, {"Neckline":f"{proj:,.0f}", "Breakout":"Yes", "Vol_Ratio":f"{curr_vol/vol_avg:.1f}ë°°"}
    return False, None

def check_pullback_pattern(df):
    if len(df) < 60: return False, None
    df['EMA60'] = df['Close'].ewm(span=60).mean()
    df['EMA20'] = df['Close'].ewm(span=20).mean()
    df['VolSMA20'] = df['Volume'].rolling(20).mean()
    curr = df.iloc[-1]
    if curr['Close'] < curr['EMA60']: return False, "ì¶”ì„¸ ì´íƒˆ"
    recent_high = df['High'].iloc[-10:].max()
    if curr['Close'] > (recent_high * 0.97): return False, "ê³ ì "
    dist = (curr['Close'] - curr['EMA20']) / curr['EMA20']
    if dist < -0.03: return False, "ì§€ì§€ì„  ë¶•ê´´"
    if dist > 0.08: return False, "ì´ê²©ë„ í¼"
    if curr['Volume'] > curr['VolSMA20']: return False, "ë§¤ë„ì„¸"
    return True, {"pattern": "20ì¼ì„  ëˆŒë¦¼ëª©", "support": "EMA20"}

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ í™”ë©´
# ==========================================

st.write("ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ (5-Factor ì „ëµ, MACD-V, TTM Squeeze 50ì¼)")
if not supabase: st.warning("âš ï¸ DB ì—°ê²° í‚¤ ì˜¤ë¥˜")

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì‹ ê·œ ì¢…ëª© ë°œêµ´", "ğŸ“‰ ì €ì¥ëœ ì¢…ëª© ëˆŒë¦¼ëª© ì°¾ê¸°", "ğŸ’° ì¬ë¬´ë¶„ì„", "ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­"])

with tab1:
    cols = st.columns(11) 
    
    if cols[0].button("ğŸŒ ì„¹í„°"):
        st.info("ETF ì„¹í„° ë¶„ì„ ì¤‘...")
        res = analyze_sector_trend()
        if not res.empty: st.dataframe(res, use_container_width=True)
        else: st.warning("ë°ì´í„° ë¶€ì¡±")

    if cols[1].button("ğŸ³ï¸ êµ­ê°€"):
        tickers = get_country_etfs_from_sheet()
        if tickers:
            st.info(f"[êµ­ê°€ ETF] {len(tickers)}ê°œ ì¼ë´‰ 5-Factor ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, (t, n) in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1d", "2y")
                passed, info = check_daily_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'êµ­ê°€/ETFëª…': n, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14)': f"{info['atr']:,.0f}", 'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info['prev_date'],
                        'ì°¨ì´ì¼': f"{info['diff_days']}ì¼", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[êµ­ê°€] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Country_Daily")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì¢…ëª© ì—†ìŒ")

    if cols[2].button("ğŸš€ ì¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì¼ë´‰ 5-Factor + TTM Squeeze] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1d", "2y")
                passed, info = check_daily_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14)': f"{info['atr']:,.0f}", 'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info['prev_date'],
                        'ì°¨ì´ì¼': f"{info['diff_days']}ì¼", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Daily_5Factor")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[3].button("ğŸ“… ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì£¼ë´‰] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                passed, info = check_weekly_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14ì£¼)': f"{info['atr']:,.0f}", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW(20ì£¼ì „)': f"{info['bw_past']:.4f}", 'BWë³€í™”': info['bw_change'],
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Weekly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[4].button("ğŸ—“ï¸ ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì›”ë´‰ ATH] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1mo", "max")
                passed, info = check_monthly_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATHìµœê³ ê°€': f"{info['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info['ath_date'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info['month_count']}ê°œì›”",
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['ath_date'], 'BW_Value': str(info['month_count']), 'MACD_V_Value': "0"
                    })
            bar.empty()
            if res:
                st.success(f"[ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['í˜„52ì£¼ì‹ ê³ ê°€ì¼', 'BW_Value', 'MACD_V_Value'], errors='ignore'))
                save_to_supabase(res, "Monthly_ATH")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[5].button("ì¼+ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰(5-Factor) + ì›”ë´‰(ATH) êµì°¨ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ATHë‹¬ì„±ì›”': info_m['ath_date'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': str(info_m['month_count']), 'MACD_V_Value': f"{info_d['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Daily_Monthly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[6].button("ì¼+ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰(5-Factor) + ì£¼ë´‰(BB) êµì°¨ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰BWë³€í™”': info_w['bw_change'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_d['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì¼+ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Daily_Weekly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[7].button("ì£¼+ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì£¼ë´‰(BB) + ì›”ë´‰(ATH) êµì°¨ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_w['price']:,.0f}",
                    'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰BWë³€í™”': info_w['bw_change'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'ATHë‹¬ì„±ì›”': info_m['ath_date'], 'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_m['ath_date'], 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì£¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Weekly_Monthly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[8].button("âš¡ í†µí•©"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[í†µí•©] ì¼+ì£¼+ì›”ë´‰ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¢…ëª© ê²€ìƒ‰ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ATHìµœê³ ê°€': f"{info_m['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info_m['ath_date'],
                    'í•´ë‹¹ì›”ìˆ˜': f"{info_m['month_count']}ê°œì›”", 'ìŠ¤í€´ì¦ˆ': info_d['squeeze'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}",
                    'ì£¼ë´‰BWë³€í™”': info_w['bw_change'], 'MACD-V': f"{info_w['macdv']:.2f}",
                    'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"âš¡ í†µí•© ë¶„ì„ ì™„ë£Œ! {len(res)}ê°œ ë°œê²¬")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Integrated_Triple")
            else: st.warning("3ê°€ì§€ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    if cols[9].button("ğŸ† ì»µí•¸ë“¤"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[ì»µí•¸ë“¤] ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                pass_c, info = check_cup_handle_pattern(df)
                if pass_c:
                    df = calculate_common_indicators(df, True)
                    curr = df.iloc[-1]
                    sector = get_stock_sector(rt)
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                        'íŒ¨í„´ìƒì„¸': f"ê¹Šì´:{info['depth']}", 'ëŒíŒŒê°€ê²©': info['pivot'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW_Value': f"{curr['BandWidth']:.4f}", 'MACD_V_Value': f"{curr['MACD_V']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì»µí•¸ë“¤] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "CupHandle")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[10].button("ğŸ‘¤ ì—­H&S"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[ì—­H&S] ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                pass_h, info = check_inverse_hs_pattern(df)
                if pass_h:
                    df = calculate_common_indicators(df, True)
                    curr = df.iloc[-1]
                    sector = get_stock_sector(rt)
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                        'ë„¥ë¼ì¸': info['Neckline'], 'ê±°ë˜ëŸ‰ê¸‰ì¦': info['Vol_Ratio'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW_Value': f"{curr['BandWidth']:.4f}", 'MACD_V_Value': f"{curr['MACD_V']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì—­H&S] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "InverseHS")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

with tab2:
    st.markdown("### ğŸ“‰ ì €ì¥ëœ ì¢…ëª© ì¤‘ ëˆŒë¦¼ëª©/ê¸‰ë“±ì£¼ ì°¾ê¸°")
    if st.button("ğŸ” ëˆŒë¦¼ëª© & ê¸‰ë“± íŒ¨í„´ ë¶„ì„"):
        db_tickers = get_unique_tickers_from_db()
        if not db_tickers: st.warning("DB ë°ì´í„° ì—†ìŒ")
        else:
            st.info(f"{len(db_tickers)}ê°œ ì¢…ëª© ì¬ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(db_tickers):
                bar.progress((i+1)/len(db_tickers))
                rt, df = smart_download(t, "1d", "2y")
                try:
                    # ì¼ë´‰ ê³„ì‚° ë¡œì§ í™œìš© (SMA50, MACD-V ë“± í¬í•¨ë¨)
                    df = calculate_daily_indicators(df)
                    if df is None: continue
                    curr = df.iloc[-1]
                    cond = ""
                    if curr['MACD_V'] > 60: cond = "ğŸ”¥ ê³µê²©ì  ì¶”ì„¸"
                    
                    # ëˆŒë¦¼ëª© ì²´í¬ (20ì¼ì„  ê¸°ì¤€) - calculate_common_indicators ë¡œì§ ì¼ë¶€ ì°¨ìš©
                    ema20 = df['Close'].ewm(span=20).mean().iloc[-1]
                    if (curr['Close'] > ema20) and ((curr['Close']-ema20)/ema20 < 0.03):
                        cond = "ğŸ“‰ 20ì¼ì„  ëˆŒë¦¼ëª©"
                    
                    if (curr['Close'] > curr['EMA200']) and (-100 <= curr['MACD_V'] <= -50):
                         cond = "ğŸ§² MACD-V ê³¼ë§¤ë„"
                    
                    if cond:
                        eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                        res.append({
                            'ì¢…ëª©ì½”ë“œ': rt, 'íŒ¨í„´': cond, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                            '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                            'MACD-V': f"{curr['MACD_V']:.2f}", 'EMA20': f"{ema20:,.0f}"
                        })
                except: continue
            bar.empty()
            if res:
                st.success(f"{len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res), use_container_width=True)
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

with tab3:
    st.markdown("### ğŸ’° ì¬ë¬´ ì§€í‘œ ë¶„ì„ & EPS Trend (yfinance)")
    st.info("yfinance ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ì¬ë¬´ ì§€í‘œ ë° EPS ì¶”ì •ì¹˜ ë³€í™”ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    if st.button("ğŸ“Š ì¬ë¬´ ì§€í‘œ ê°€ì ¸ì˜¤ê¸°"):
        tickers = get_tickers_from_sheet()
        if not tickers: st.error("í‹°ì»¤ ì—†ìŒ")
        else:
            bar = st.progress(0); f_res = []
            for i, t in enumerate(tickers):
                bar.progress((i + 1) / len(tickers))
                real_ticker, _ = smart_download(t, "1d", "5d") 
                try:
                    tick = yf.Ticker(real_ticker)
                    info = tick.info
                    if not info: continue
                    mkt_cap = info.get('marketCap', 0)
                    mkt_cap_str = f"{mkt_cap/1000000000000:.1f}ì¡°" if mkt_cap > 1000000000000 else f"{mkt_cap/100000000:.0f}ì–µ" if mkt_cap else "-"
                    rev_growth = info.get('revenueGrowth', 0)
                    rev_str = f"{rev_growth*100:.1f}%" if rev_growth else "-"
                    eps_growth = info.get('earningsGrowth', 0)
                    eps_growth_str = f"{eps_growth*100:.1f}%" if eps_growth else "-"
                    fwd_eps = info.get('forwardEps', '-')
                    peg = info.get('pegRatio', '-')
                    try:
                        trend_data = tick.eps_trend
                        if trend_data:
                            curr_year_data = trend_data[0] 
                            curr_est = curr_year_data.get('current', 0)
                            ago30 = curr_year_data.get('30daysAgo', 0)
                            ago90 = curr_year_data.get('90daysAgo', 0)
                            trend_30 = "â†—ï¸" if curr_est > ago30 else "â†˜ï¸" if curr_est < ago30 else "-"
                            trend_90 = "â†—ï¸" if curr_est > ago90 else "â†˜ï¸" if curr_est < ago90 else "-"
                            eps_trend_str = f"30ì¼{trend_30} | 90ì¼{trend_90}"
                        else: eps_trend_str = "-"
                    except: eps_trend_str = "-"
                    rec = info.get('recommendationKey', '-').upper().replace('_', ' ')
                    target = info.get('targetMeanPrice')
                    curr_p = info.get('currentPrice', 0)
                    upside = f"{(target - curr_p) / curr_p * 100:.1f}%" if (target and curr_p) else "-"
                    
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(real_ticker)
                    
                    f_res.append({
                        "ì¢…ëª©": real_ticker, "ì„¹í„°": info.get('sector', '-'), "ì‚°ì—…": info.get('industry', '-'),
                        "ì‹œê°€ì´ì•¡": mkt_cap_str, "ë§¤ì¶œì„±ì¥(YoY)": rev_str, "EPSì„±ì¥(YoY)": eps_growth_str,
                        "ì„ í–‰EPS": fwd_eps, "PEG": peg, "EPSì¶”ì„¸(ì˜¬í•´)": eps_trend_str,
                        "1Wë³€í™”": eps1w, "1Më³€í™”": eps1m, "3Më³€í™”": eps3m,
                        "íˆ¬ìì˜ê²¬": rec, "ìƒìŠ¹ì—¬ë ¥": upside
                    })
                except Exception as e: continue
            bar.empty()
            if f_res:
                df_fin = pd.DataFrame(f_res)
                st.success(f"âœ… ì´ {len(df_fin)}ê°œ ê¸°ì—… ì¬ë¬´/EPS ë¶„ì„ ì™„ë£Œ")
                st.dataframe(df_fin, use_container_width=True)
            else: st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ==============================================================================
# [NEW] 4. ì—‘ì…€ ë°ì´í„° ë§¤ì¹­ íƒ­ (DB ì €ì¥ & ì´ˆê¸°í™” & í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš©)
# ==============================================================================
with tab4:
    st.markdown("### ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­ (í€€í‹°ì™€ì´ì¦ˆ DB ì—°ë™)")
    st.info("í€€í‹°ì™€ì´ì¦ˆ ì—‘ì…€(quant_master.xlsx)ì„ ì—…ë¡œë“œí•˜ì—¬ Supabase DBì— ì €ì¥í•©ë‹ˆë‹¤.\n\n"
            "**[ì£¼ì˜ì‚¬í•­]**\n"
            "- Supabase DBì˜ `quant_data` í…Œì´ë¸” ì»¬ëŸ¼ì´ **TEXT** íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
            "**[í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš©]**\n"
            "- êµ¬ê¸€ ì‹œíŠ¸(TGT)ì— ìˆëŠ” ì¢…ëª©ë§Œ í•„í„°ë§í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n")
    
    col_upload, col_reset = st.columns([3, 1])
    
    with col_upload:
        uploaded_file = st.file_uploader("ğŸ“¥ quant_master.xlsx íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx'])
    
    # [DB ì´ˆê¸°í™” ë²„íŠ¼]
    with col_reset:
        st.write("") # ì¤„ë§ì¶¤
        st.write("") 
        if st.button("ğŸ—‘ï¸ [ì£¼ì˜] DB ì´ˆê¸°í™” (ì „ì²´ ì‚­ì œ)", type="primary"):
            try:
                # ëª¨ë“  ë°ì´í„° ì‚­ì œ (idê°€ 0ì´ ì•„ë‹Œ ëª¨ë“  í–‰)
                supabase.table("quant_data").delete().neq("id", 0).execute()
                st.success("DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                fetch_latest_quant_data_from_db.clear()
            except Exception as e:
                st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨ (Supabase ê¶Œí•œ í™•ì¸ í•„ìš”): {e}")

    # [ë””ë²„ê¹… ì˜µì…˜]
    show_debug_log = st.checkbox("ğŸ” ë””ë²„ê¹… ë¡œê·¸ ë³´ê¸° (ì™œ ì €ì¥ì´ ì•ˆ ë˜ëŠ”ì§€ í™•ì¸)")

    # --- ì„œë¸Œ í•¨ìˆ˜: ì—‘ì…€ ì‹œíŠ¸ íŒŒì‹± (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ ì¶”ê°€, ë¬¸ìì—´ ì²˜ë¦¬) ---
    def parse_sheet_ticker_value(sheet_df, allowed_tickers, debug_mode=False):
        extracted = {}
        for index, row in sheet_df.iterrows():
            try:
                raw_ticker = str(row[0]).strip()
                if not raw_ticker or raw_ticker.lower() in ['code', 'ticker', 'nan', 'item type', 'comparison date']:
                    continue
                
                # 1. ì •ê·œí™” (Quant -> DB Format)
                norm_ticker = normalize_ticker_for_db_storage(raw_ticker)
                
                # [ë””ë²„ê¹…] íŠ¹ì • í‹°ì»¤ê°€ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸
                if debug_mode and "RKLB" in norm_ticker:
                    st.write(f"ğŸ“¢ [DEBUG] ë°œê²¬ëœ í‹°ì»¤: {raw_ticker} -> ì •ê·œí™”: {norm_ticker} -> í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€: {norm_ticker in allowed_tickers}")

                # 2. [í•µì‹¬] í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
                if norm_ticker not in allowed_tickers:
                    continue

                # 3. [í•µì‹¬] ê°’ ê°€ì ¸ì˜¤ê¸° (ë¬¸ìì—´ ê·¸ëŒ€ë¡œ)
                val = row[3] # Dì—´
                if pd.isna(val):
                    final_val = "-"
                else:
                    final_val = str(val).strip()
                    # ë¬¸ìì—´ "nan" ë˜ëŠ” ë¹ˆ ê°’ ì²˜ë¦¬
                    if final_val.lower() == 'nan' or final_val == "":
                        final_val = "-"
                
                extracted[norm_ticker] = final_val
            except Exception:
                continue
        return extracted

    if uploaded_file and st.button("ğŸ”„ DB ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘"):
        try:
            # 0. êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê´€ë¦¬ ì¢…ëª©(Target) ê°€ì ¸ì˜¤ê¸°
            st.info("êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            tgt_stocks = get_tickers_from_sheet()
            tgt_etfs = [x[0] for x in get_etfs_from_sheet()]
            tgt_countries = [x[0] for x in get_country_etfs_from_sheet()]
            
            # ê´€ë¦¬ ì¢…ëª© í•©ì¹˜ê¸° ë° ì •ê·œí™”
            raw_targets = set(tgt_stocks + tgt_etfs + tgt_countries)
            allowed_db_tickers = set()
            for t in raw_targets:
                # êµ¬ê¸€ ì‹œíŠ¸ì— ìˆëŠ” í‹°ì»¤ë¥¼ DB ì €ì¥ í¬ë§·ìœ¼ë¡œ ë³€í™˜
                # ì˜ˆ: 005930.KS -> 005930, AAPL -> AAPL
                t_clean = t.split('.')[0] 
                t_clean = t_clean.split('-')[0]
                allowed_db_tickers.add(t_clean)
            
            st.success(f"ê´€ë¦¬ ëŒ€ìƒ ì¢…ëª© {len(allowed_db_tickers)}ê°œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

            if show_debug_log:
                if "RKLB" in allowed_db_tickers:
                    st.success("âœ… RKLBê°€ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("âŒ RKLBê°€ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤! êµ¬ê¸€ ì‹œíŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

            # 1. ì—‘ì…€ íŒŒì¼ ì½ê¸° (ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì½ê¸°)
            # [ì¤‘ìš”] dtype=str ì˜µì…˜ì„ ì¤˜ì„œ ì²˜ìŒë¶€í„° ë¬¸ìë¡œ ì½ì–´ë“¤ì„
            xls = pd.read_excel(uploaded_file, sheet_name=None, header=None, dtype=str)
            
            sheet_map = {'1w': None, '1m': None, '3m': None}
            for sheet_name in xls.keys():
                s_name = sheet_name.lower().strip()
                if '1w' in s_name: sheet_map['1w'] = xls[sheet_name]
                elif '1m' in s_name: sheet_map['1m'] = xls[sheet_name]
                elif '3m' in s_name: sheet_map['3m'] = xls[sheet_name]
            
            if not (sheet_map['1w'] is not None and sheet_map['1m'] is not None and sheet_map['3m'] is not None):
                st.error("ì—‘ì…€ íŒŒì¼ì— 1w, 1m, 3m ì‹œíŠ¸ê°€ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                # 2. íŒŒì‹± (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì „ë‹¬)
                data_1w = parse_sheet_ticker_value(sheet_map['1w'], allowed_db_tickers, show_debug_log)
                data_1m = parse_sheet_ticker_value(sheet_map['1m'], allowed_db_tickers, show_debug_log)
                data_3m = parse_sheet_ticker_value(sheet_map['3m'], allowed_db_tickers, show_debug_log)
                
                # 3. í†µí•©
                all_tickers = set(data_1w.keys()) | set(data_1m.keys()) | set(data_3m.keys())
                
                if not all_tickers:
                    st.warning("ì—‘ì…€ íŒŒì¼ì—ì„œ ê´€ë¦¬ ì¢…ëª©(TGT)ê³¼ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    # 4. DB ì¤‘ë³µ ì²´í¬ (ë¬¸ìì—´ ë¹„êµ)
                    today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')
                    existing_map = {}
                    try:
                        res = supabase.table("quant_data")\
                            .select("*")\
                            .gte("created_at", f"{today_str} 00:00:00")\
                            .lte("created_at", f"{today_str} 23:59:59")\
                            .execute()
                        if res.data:
                            for rec in res.data:
                                existing_map[rec['ticker']] = (
                                    str(rec.get('change_1w') or "-"),
                                    str(rec.get('change_1m') or "-"),
                                    str(rec.get('change_3m') or "-")
                                )
                    except:
                        pass
                    
                    rows_to_insert = []
                    skipped_count = 0
                    
                    for t in all_tickers:
                        v_1w = data_1w.get(t, "-")
                        v_1m = data_1m.get(t, "-")
                        v_3m = data_3m.get(t, "-")
                        
                        # ì¤‘ë³µ ì²´í¬ (ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ë¹„êµ)
                        if t in existing_map:
                            e_1w, e_1m, e_3m = existing_map[t]
                            if (e_1w == v_1w) and (e_1m == v_1m) and (e_3m == v_3m):
                                skipped_count += 1
                                continue
                        
                        rows_to_insert.append({
                            "ticker": t,
                            "change_1w": v_1w,
                            "change_1m": v_1m,
                            "change_3m": v_3m
                        })
                    
                    if rows_to_insert:
                        # 100ê°œì”© ë‚˜ëˆ ì„œ ì €ì¥
                        chunk_size = 100
                        for i in range(0, len(rows_to_insert), chunk_size):
                            chunk = rows_to_insert[i:i+chunk_size]
                            supabase.table("quant_data").insert(chunk).execute()
                        
                        st.success(f"âœ… DB ì—…ë¡œë“œ ì™„ë£Œ! (TGT í•„í„°ë§ ì ìš©ë¨. ì‹ ê·œ: {len(rows_to_insert)}ê±´, ì¤‘ë³µìƒëµ: {skipped_count}ê±´)")
                        
                        # ìºì‹œ ì´ˆê¸°í™”
                        fetch_latest_quant_data_from_db.clear()
                        GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()
                    else:
                        st.info(f"ë³€ë™ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. (ì¤‘ë³µ ìƒëµ: {skipped_count}ê±´)")
                
        except Exception as e:
            st.error(f"ì‘ì—… ì‹¤íŒ¨: {e}")

    st.markdown("---")
    st.markdown("#### ğŸ‘ï¸ í˜„ì¬ DB ì €ì¥ ë°ì´í„° (ì „ì²´ ì¡°íšŒ)")
    if st.button("ë°ì´í„° ì¡°íšŒí•˜ê¸°"):
        try:
            # id, created_at ì œì™¸í•˜ê³  í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            # limit ì œê±°í•˜ì—¬ ì „ì²´ ì¡°íšŒ
            response = supabase.table("quant_data")\
                .select("ticker, change_1w, change_1m, change_3m")\
                .order("created_at", desc=True)\
                .execute()
            
            if response.data:
                df_view = pd.DataFrame(response.data)
                # ì»¬ëŸ¼ ì´ë¦„ì´ ê·¸ëŒ€ë¡œ ë‚˜ì˜¤ì§€ë§Œ, ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ ëª…ì‹œì  ì„ íƒ ê°€ëŠ¥ (ì´ë¯¸ selectì—ì„œ ì§€ì •í–ˆìœ¼ë¯€ë¡œ ìƒëµ ê°€ëŠ¥)
                st.dataframe(df_view, use_container_width=True)
            else:
                st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")

st.markdown("---")
with st.expander("ğŸ—„ï¸ ì „ì²´ ì €ì¥ ê¸°ë¡ ë³´ê¸° / ê´€ë¦¬"):
    col_e1, col_e2 = st.columns([1, 1])
    with col_e1:
        if st.button("ğŸ”„ ê¸°ë¡ ìƒˆë¡œê³ ì¹¨"):
            try:
                response = supabase.table("history").select("*").order("created_at", desc=True).limit(50).execute()
                if response.data: st.dataframe(pd.DataFrame(response.data), use_container_width=True)
            except Exception as e: st.error(str(e))
    with col_e2:
        if st.button("ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ (ìµœì‹ ë³¸ë§Œ ìœ ì§€)"):
            remove_duplicates_from_db()
