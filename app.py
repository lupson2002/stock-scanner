import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timezone
from supabase import create_client, Client
from scipy.signal import argrelextrema
import time
import concurrent.futures

# =========================================================
# [ì„¤ì •] Supabase ë° í˜ì´ì§€ ì„¤ì •
# =========================================================
st.set_page_config(page_title="Pro ì£¼ì‹ ê²€ìƒ‰ê¸° V3 (Final)", layout="wide")

try:
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
except Exception as e:
    st.error(f"âš ï¸ Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì—ëŸ¬: {e})")
    st.stop()

@st.cache_resource
def init_supabase():
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except: return None

supabase = init_supabase()

# =========================================================
# 1. ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
# =========================================================
SHEET_ID = '1NVThO1z2HHF0TVXVRGmbVsSU_Svyjg8fxd7E90z2o8A'
STOCK_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid=0'
ETF_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid=2023286696'
COUNTRY_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid=1247750129'

@st.cache_data(ttl=600)
def get_tickers_from_sheet():
    try:
        df = pd.read_csv(STOCK_CSV_URL, header=None)
        return sorted(list(set([str(x).strip() for x in df[0] if str(x).strip()])))
    except: return []

@st.cache_data(ttl=600)
def get_etfs_from_sheet():
    try:
        df = pd.read_csv(ETF_CSV_URL, header=None)
        etf_list = []
        for _, row in df.iterrows():
            raw = str(row[0]).strip()
            if not raw or raw.lower() in ['ticker', 'symbol', 'nan']: continue
            ticker = raw.split(':')[-1].strip() if ':' in raw else raw
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker: etf_list.append((ticker, name))
        return etf_list
    except: return []

@st.cache_data(ttl=600)
def get_country_etfs_from_sheet():
    try:
        df = pd.read_csv(COUNTRY_CSV_URL, header=None)
        etf_list = []
        for _, row in df.iterrows():
            raw = str(row[0]).strip()
            if not raw or raw.lower() in ['ticker', 'symbol', 'nan']: continue
            ticker = raw.split(':')[-1].strip() if ':' in raw else raw
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker: etf_list.append((ticker, name))
        return etf_list
    except: return []

# =========================================================
# 2. í•µì‹¬ ìœ í‹¸ë¦¬í‹° (ë‹¤ìš´ë¡œë“œ, DBì—°ë™)
# =========================================================

# [ì¤‘ìš”] ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ìºì‹œ ì œê±° + threads=False ì„¤ì •
def smart_download(ticker, interval="1d", period="2y"):
    ticker = str(ticker).strip()
    if ':' in ticker: ticker = ticker.split(':')[-1]
    ticker = ticker.replace('/', '-')
    
    candidates = [ticker]
    if ticker.isdigit() and len(ticker) == 6:
        candidates = [f"{ticker}.KS", f"{ticker}.KQ", ticker]
    
    for t in candidates:
        try:
            # threads=Falseë¡œ ì„¤ì •í•˜ì—¬ ì™¸ë¶€ ThreadPoolExecutorì™€ ì¶©ëŒ ë°©ì§€
            df = yf.download(t, period=period, interval=interval, progress=False, auto_adjust=False, threads=False)
            if not df.empty:
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = df.columns.get_level_values(0)
                return t, df
        except: continue
    return ticker, pd.DataFrame()

@st.cache_data(ttl=3600*24)
def get_stock_sector(ticker):
    try:
        tick = yf.Ticker(ticker)
        meta = tick.info
        if not meta: return "Unknown"
        qt = meta.get('quoteType', '').upper()
        if 'ETF' in qt or 'FUND' in qt:
            return f"[ETF] {meta.get('shortName', '')}"
        
        sector = meta.get('sector', '') or meta.get('industry', '') or meta.get('shortName', '')
        trans = {'Technology':'ê¸°ìˆ ','Healthcare':'í—¬ìŠ¤ì¼€ì–´','Financial Services':'ê¸ˆìœµ','Consumer Cyclical':'ì„ì˜ì†Œë¹„ì¬',
                 'Industrials':'ì‚°ì—…ì¬','Basic Materials':'ì†Œì¬','Energy':'ì—ë„ˆì§€','Utilities':'ìœ í‹¸ë¦¬í‹°','Real Estate':'ë¶€ë™ì‚°',
                 'Communication Services':'í†µì‹ ','Consumer Defensive':'í•„ìˆ˜ì†Œë¹„ì¬','Semiconductors':'ë°˜ë„ì²´'}
        return trans.get(sector, sector)
    except: return "Unknown"

@st.cache_data(ttl=600)
def fetch_latest_quant_data_from_db():
    if not supabase: return {}
    try:
        res = supabase.table("quant_data").select("*").order("created_at", desc=True).execute()
        if not res.data: return {}
        df = pd.DataFrame(res.data)
        df = df.drop_duplicates(subset='ticker', keep='first')
        return {row['ticker']: {'1w':str(row.get('change_1w') or "-"), '1m':str(row.get('change_1m') or "-"), '3m':str(row.get('change_3m') or "-")} for _, row in df.iterrows()}
    except: return {}

GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()

def get_eps_changes_from_db(ticker):
    t = str(ticker).upper().strip()
    # ë‹¤ì–‘í•œ í‹°ì»¤ í¬ë§· ì •ê·œí™” ì‹œë„
    candidates = [t, t.split('.')[0], t.split('-')[0]]
    for cand in candidates:
        if cand in GLOBAL_QUANT_DATA:
            d = GLOBAL_QUANT_DATA[cand]
            return d['1w'], d['1m'], d['3m']
    return "-", "-", "-"

def save_to_supabase(data_list, strategy_name):
    if not supabase: return
    if isinstance(data_list, pd.DataFrame): data_list = data_list.to_dict('records')
    rows = []
    for item in data_list:
        rows.append({
            "ticker": str(item.get('ì¢…ëª©ì½”ë“œ', '')),
            "sector": str(item.get('ì„¹í„°', '-')),
            "price": str(item.get('í˜„ì¬ê°€', '0')).replace(',', ''),
            "strategy": strategy_name,
            "high_date": str(item.get('í˜„52ì£¼ì‹ ê³ ê°€ì¼', '')),
            "bw": str(item.get('BW_Value', '')),
            "macd_v": str(item.get('MACD_V_Value', ''))
        })
    try:
        supabase.table("history").insert(rows).execute()
        st.toast(f"âœ… DB ì €ì¥ ì™„ë£Œ ({len(rows)}ê±´)", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

# =========================================================
# 3. ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ (ì§€í‘œ ê³„ì‚° & íŒ¨í„´) - ê¸°ì¡´ ë¡œì§ ë³µì›
# =========================================================

def calculate_macdv(df, short=12, long=26, signal=9):
    ema_fast = df['Close'].ewm(span=short, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=long, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    tr = pd.concat([df['High']-df['Low'], (df['High']-df['Close'].shift()).abs(), (df['Low']-df['Close'].shift()).abs()], axis=1).max(axis=1)
    atr = tr.ewm(span=long, adjust=False).mean()
    macd_v = (macd_line / (atr + 1e-9)) * 100
    return macd_v, macd_v.ewm(span=signal, adjust=False).mean()

def calculate_common_indicators(df, is_weekly=False):
    if len(df) < 60: return None
    df = df.copy()
    period = 20 if is_weekly else 60
    df[f'EMA{period}'] = df['Close'].ewm(span=period).mean()
    df[f'STD{period}'] = df['Close'].rolling(period).std()
    df['BB_UP'] = df[f'EMA{period}'] + 2*df[f'STD{period}']
    df['BB_LO'] = df[f'EMA{period}'] - 2*df[f'STD{period}']
    df['BandWidth'] = (df['BB_UP'] - df['BB_LO']) / df[f'EMA{period}']
    df['MACD_V'], _ = calculate_macdv(df)
    return df

def calculate_daily_indicators(df):
    if len(df) < 200: return None
    df = df.copy()
    
    # ë³¼ë¦°ì €ë°´ë“œ(50, 2)
    df['SMA50'] = df['Close'].rolling(50).mean()
    df['STD50'] = df['Close'].rolling(50).std()
    df['BB50_UP'] = df['SMA50'] + 2*df['STD50']
    df['BB50_LO'] = df['SMA50'] - 2*df['STD50']
    df['BW50'] = (df['BB50_UP'] - df['BB50_LO']) / df['SMA50']
    df['Donchian_High_50'] = df['High'].rolling(50).max().shift(1)
    
    # ê±°ë˜ëŸ‰ VR
    chg = df['Close'].diff()
    df['Vol_Up'] = np.where(chg>0, df['Volume'], 0)
    df['Vol_Down'] = np.where(chg<0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(chg==0, df['Volume'], 0)
    df['VR50'] = ((df['Vol_Up'].rolling(50).sum() + df['Vol_Flat'].rolling(50).sum()/2) / 
                  (df['Vol_Down'].rolling(50).sum() + df['Vol_Flat'].rolling(50).sum()/2 + 1e-9)) * 100
    
    # TTM Squeeze
    df['SMA20'] = df['Close'].rolling(20).mean()
    tr = pd.concat([df['High']-df['Low'], (df['High']-df['Close'].shift()).abs(), (df['Low']-df['Close'].shift()).abs()], axis=1).max(axis=1)
    df['ATR20'] = tr.rolling(20).mean()
    df['BB20_UP'] = df['SMA20'] + 2*df['Close'].rolling(20).std()
    df['BB20_LO'] = df['SMA20'] - 2*df['Close'].rolling(20).std()
    df['KC20_UP'] = df['SMA20'] + 1.5*df['ATR20']
    df['KC20_LO'] = df['SMA20'] - 1.5*df['ATR20']
    df['TTM_Squeeze'] = (df['BB20_UP'] < df['KC20_UP']) & (df['BB20_LO'] > df['KC20_LO'])
    
    df['ATR14'] = tr.ewm(span=14).mean()
    df['MACD_V'], _ = calculate_macdv(df)
    
    # MACD Oscillator
    macdl = df['Close'].ewm(span=20).mean() - df['Close'].ewm(span=200).mean()
    df['MACD_OSC_C'] = macdl - macdl.ewm(span=20).mean()
    df['EMA200'] = df['Close'].ewm(span=200).mean()
    
    return df

# --- íŒ¨í„´ ì²´í¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ë¡œì§) ---

def check_vcp_pattern(df):
    if len(df) < 250: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    curr = df.iloc[-1]
    
    # 1. ì¶”ì„¸
    sma50 = df['SMA50'].iloc[-1]; sma200 = df['Close'].rolling(200).mean().iloc[-1]
    if not (curr['Close'] > sma200 and sma50 > sma200): return False, None
    if not (df['SMA50'].iloc[-1] > df['SMA50'].iloc[-20]): return False, None # 50ì¼ì„  ìƒìŠ¹
    
    # 2. íŒŒë™ (60ì¼)
    sub = df.iloc[-60:]
    p1 = sub.iloc[:20]; p2 = sub.iloc[20:40]; p3 = sub.iloc[40:]
    r1 = (p1['High'].max()-p1['Low'].min())/p1['High'].max()
    r2 = (p2['High'].max()-p2['Low'].min())/p2['High'].max()
    r3 = (p3['High'].max()-p3['Low'].min())/p3['High'].max()
    
    if not ((r3 < r2) or (r2 < r1) or (r3 < 0.12)): return False, None
    
    # 3. ì…‹ì—… & ëŒíŒŒ
    vol_dry = p3['Volume'].mean() < p1['Volume'].mean() * 1.2
    pivot = p3.iloc[:-1]['High'].max() if len(p3)>1 else p3['High'].max()
    breakout = (curr['Close'] > pivot) and (curr['Volume'] > df['Volume'].iloc[-50:].mean()*1.2)
    
    status = ""
    if vol_dry and not breakout: status = "3ë‹¨ê³„ (ìˆ˜ë ´ì¤‘)"
    elif (vol_dry and breakout) or (breakout and r3 < 0.15): status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
    else: return False, None
    
    return True, {'status': status, 'stop_loss': p3['Low'].min(), 'target_price': curr['Close']*1.2, 
                  'squeeze': "ğŸ”¥" if df['TTM_Squeeze'].iloc[-1] else "-", 'price': curr['Close'], 'pivot': pivot}

def get_weekly_macd_status(daily_df):
    try:
        w = daily_df.resample('W-FRI').agg({'Close':'last'}).dropna()
        if len(w) < 30: return "-"
        m = w['Close'].ewm(span=12).mean() - w['Close'].ewm(span=26).mean()
        s = m.ewm(span=9).mean()
        if m.iloc[-1] > s.iloc[-1]:
            return "âš¡GC (ë§¤ìˆ˜ì‹ í˜¸)" if m.iloc[-2] <= s.iloc[-2] else "ğŸ”µ Buy (ìœ ì§€)"
        return "ğŸ”» Sell (ë§¤ë„)"
    except: return "-"

def check_daily_condition(df):
    if len(df) < 260: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    curr = df.iloc[-1]
    
    dc = (df['Close'] > df['Donchian_High_50']).iloc[-3:].any()
    bb = (df['Close'] > df['BB50_UP']).iloc[-3:].any()
    if not (dc or bb): return False, None
    
    optional = 0
    if (df['VR50'].iloc[-3:] > 110).any(): optional += 1
    if len(df)>55 and (df['BW50'].iloc[-51] > curr['BW50']): optional += 1
    if curr['MACD_OSC_C'] > 0: optional += 1
    
    if optional >= 2:
        win = df.iloc[-252:]
        h_date = win['Close'].idxmax().strftime('%Y-%m-%d')
        return True, {'price':curr['Close'], 'atr':curr['ATR14'], 'high_date':h_date, 
                      'bw_curr':curr['BW50'], 'macdv':curr['MACD_V'], 'squeeze': "ğŸ”¥" if df['TTM_Squeeze'].iloc[-5:].any() else "-"}
    return False, None

def check_weekly_condition(df):
    if len(df) < 40: return False, None
    df['SMA30'] = df['Close'].rolling(30).mean()
    delta = df['Close'].diff()
    rs = (delta.where(delta>0,0)).rolling(14).mean() / ((-delta.where(delta<0,0)).rolling(14).mean() + 1e-9)
    df['RSI'] = 100 - (100/(1+rs))
    
    macdh = (df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()) - (df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()).ewm(span=9).mean()
    curr = df.iloc[-1]
    
    # ê¸°ë³¸ í•„í„°
    if not (curr['Close'] > curr['SMA30'] and curr['RSI'] > 50): return False, None
    if not (macdh.iloc[-1] > macdh.iloc[-2] or macdh.iloc[-1] > 0): return False, None
    
    df['MACD_V'], _ = calculate_macdv(df)
    return True, {'price':curr['Close'], 'atr':0, 'bw_curr':0, 'bw_change': "ì¡°ê±´ë§Œì¡±", 'macdv': df['MACD_V'].iloc[-1]}

def check_monthly_condition(df):
    if len(df) < 12: return False, None
    ath = df['High'].max()
    curr = df['Close'].iloc[-1]
    if curr >= ath * 0.90:
        cnt = (df['Close'] >= ath * 0.90).sum()
        return True, {'price':curr, 'ath_price':ath, 'ath_date':df['High'].idxmax().strftime('%Y-%m'), 'month_count':cnt}
    return False, None

def check_cup_handle_pattern(df):
    if len(df) < 26: return False, None
    sub = df.iloc[-26:].copy()
    idx_A = sub['High'].idxmax(); val_A = sub.loc[idx_A, 'High']
    if idx_A == sub.index[-1]: return False, "ì§„í–‰ì¤‘"
    
    sub_after = sub.loc[idx_A:]
    if len(sub_after) < 5: return False, "ê¸°ê°„ì§§ìŒ"
    idx_B = sub_after['Low'].idxmin(); val_B = sub_after.loc[idx_B, 'Low']
    if val_B > val_A * 0.85: return False, "ê¹Šì´ì–•ìŒ"
    
    sub_handle = sub.loc[idx_B:]
    if len(sub_handle) < 2: return False, "í•¸ë“¤ì—†ìŒ"
    idx_C = sub_handle['High'].idxmax(); val_C = sub_handle.loc[idx_C, 'High']
    
    curr = df['Close'].iloc[-1]
    if curr < val_C * 0.80: return False, "í•¸ë“¤ê¹ŠìŒ"
    return True, {"depth": f"{(1-val_B/val_A)*100:.1f}%", "pivot": val_C}

def check_inverse_hs_pattern(df):
    if len(df) < 60: return False, None
    sub = df.iloc[-60:]
    p1=sub.iloc[:20]; p2=sub.iloc[20:40]; p3=sub.iloc[40:]
    if not (p2['Low'].min() < p1['Low'].min() and p2['Low'].min() < p3['Low'].min()): return False, "í˜•íƒœë¯¸ë‹¬"
    neck = p3['High'].max()
    return True, {"Neckline": neck, "Vol_Ratio": f"{p3['Volume'].mean()/p2['Volume'].mean():.1f}ë°°"}

# =========================================================
# 4. ë³‘ë ¬ ì²˜ë¦¬ Task ì •ì˜ (Global Scope í•„ìˆ˜)
# =========================================================

def task_vcp(t):
    try:
        real_t, df = smart_download(t, "1d", "2y")
        if len(df)<200: return None
        passed, info = check_vcp_pattern(df)
        if passed:
            e1,e2,e3 = get_eps_changes_from_db(real_t)
            return {
                'ì¢…ëª©ì½”ë“œ':real_t, 'ì„¹í„°':get_stock_sector(real_t), 'í˜„ì¬ê°€':info['price'], 'ë¹„ê³ ':info['status'],
                'ì£¼ë´‰MACD':get_weekly_macd_status(df), 'ì†ì ˆê°€':info['stop_loss'], 'ëª©í‘œê°€(3R)':info['target_price'],
                'ìŠ¤í€´ì¦ˆ':info['squeeze'], '1Wë³€í™”':e1, '1Më³€í™”':e2, 'Pivot':info['pivot'], 'chart_df':df, 'chart_info':info
            }
    except: return None

def task_daily(t):
    try:
        real_t, df = smart_download(t, "1d", "2y")
        passed, info = check_daily_condition(df)
        if passed:
            e1,e2,e3 = get_eps_changes_from_db(real_t)
            return {'ì¢…ëª©ì½”ë“œ':real_t, 'ì„¹í„°':get_stock_sector(real_t), 'í˜„ì¬ê°€':info['price'], 'ATR':info['atr'],
                    'ìŠ¤í€´ì¦ˆ':info['squeeze'], 'í˜„52ì£¼ì‹ ê³ ê°€ì¼':info['high_date'], '1Wë³€í™”':e1, 'MACD-V':info['macdv'],
                    'BW_Value':info['bw_curr'], 'MACD_V_Value':info['macdv']}
    except: return None

def task_weekly(t):
    try:
        real_t, df = smart_download(t, "1wk", "2y")
        passed, info = check_weekly_condition(df)
        if passed:
            e1,e2,e3 = get_eps_changes_from_db(real_t)
            return {'ì¢…ëª©ì½”ë“œ':real_t, 'ì„¹í„°':get_stock_sector(real_t), 'í˜„ì¬ê°€':info['price'], 'êµ¬ë¶„':info['bw_change'],
                    '1Wë³€í™”':e1, 'MACD-V':info['macdv'], 'BW_Value':0, 'MACD_V_Value':info['macdv']}
    except: return None

def task_monthly(t):
    try:
        real_t, df = smart_download(t, "1mo", "max")
        passed, info = check_monthly_condition(df)
        if passed:
            e1,e2,e3 = get_eps_changes_from_db(real_t)
            return {'ì¢…ëª©ì½”ë“œ':real_t, 'ì„¹í„°':get_stock_sector(real_t), 'í˜„ì¬ê°€':info['price'], 'ATHìµœê³ ê°€':info['ath_price'],
                    'ATHë‹¬ì„±ì›”':info['ath_date'], 'ê³ ê¶Œì—­(ì›”ìˆ˜)':info['month_count'], '1Wë³€í™”':e1, 'BW_Value':info['month_count'], 'MACD_V_Value':0}
    except: return None

def task_cup(t):
    try:
        real_t, df = smart_download(t, "1wk", "2y")
        passed, info = check_cup_handle_pattern(df)
        if passed:
            df = calculate_common_indicators(df, True)
            return {'ì¢…ëª©ì½”ë“œ':real_t, 'ì„¹í„°':get_stock_sector(real_t), 'í˜„ì¬ê°€':df['Close'].iloc[-1], 'íŒ¨í„´ìƒì„¸':info['depth'],
                    'ëŒíŒŒê°€ê²©':info['pivot'], 'BW_Value':df['BandWidth'].iloc[-1], 'MACD_V_Value':df['MACD_V'].iloc[-1]}
    except: return None

def task_hs(t):
    try:
        real_t, df = smart_download(t, "1wk", "2y")
        passed, info = check_inverse_hs_pattern(df)
        if passed:
            df = calculate_common_indicators(df, True)
            return {'ì¢…ëª©ì½”ë“œ':real_t, 'ì„¹í„°':get_stock_sector(real_t), 'í˜„ì¬ê°€':df['Close'].iloc[-1], 'ë„¥ë¼ì¸':info['Neckline'],
                    'ê±°ë˜ëŸ‰ê¸‰ì¦':info['Vol_Ratio'], 'BW_Value':df['BandWidth'].iloc[-1], 'MACD_V_Value':df['MACD_V'].iloc[-1]}
    except: return None

def task_momentum(item):
    t, n = item
    try:
        real_t, df = smart_download(t, "1d", "2y")
        if len(df) < 60: return None
        c = df['Close']
        r12 = c.pct_change(252).iloc[-1] if len(c)>252 else 0
        r6 = c.pct_change(126).iloc[-1] if len(c)>126 else 0
        r3 = c.pct_change(63).iloc[-1] if len(c)>63 else 0
        r1 = c.pct_change(21).iloc[-1] if len(c)>21 else 0
        score = ((r12+r6)/2 - r3 + r1) * 100
        
        df = calculate_daily_indicators(df)
        macdv = df['MACD_V'].iloc[-1] if df is not None else 0
        return {'ì¢…ëª©ì½”ë“œ':f"{real_t} ({n})", 'ëª¨ë©˜í…€ì ìˆ˜':score, 'í˜„ì¬ê°€':c.iloc[-1], 'MACD-V':macdv}
    except: return None

def run_parallel(items, func, workers=16):
    results = []
    bar = st.progress(0)
    status = st.empty()
    total = len(items)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {executor.submit(func, item): item for item in items}
        for i, future in enumerate(concurrent.futures.as_completed(futures)):
            try:
                res = future.result()
                if res: results.append(res)
            except: pass
            bar.progress((i+1)/total)
            status.text(f"â³ ë¶„ì„ ì¤‘... ({i+1}/{total})")
    
    bar.empty()
    status.empty()
    return results

def plot_vcp_chart(df, ticker, info):
    df_p = df.iloc[-200:].copy()
    fig = go.Figure(data=[go.Candlestick(x=df_p.index, open=df_p['Open'], high=df_p['High'], low=df_p['Low'], close=df_p['Close'])])
    fig.add_trace(go.Scatter(x=df_p.index, y=df_p['Close'].rolling(50).mean(), line=dict(color='green', width=1), name='SMA50'))
    fig.add_hline(y=info['pivot'], line_dash="dot", line_color="red", annotation_text="Pivot")
    fig.update_layout(title=ticker, height=400, template="plotly_dark", xaxis_rangeslider_visible=False)
    return fig

# =========================================================
# 5. ë©”ì¸ UI
# =========================================================

# Session State ì´ˆê¸°í™”
for k in ['vcp', 'daily', 'weekly', 'monthly', 'cup', 'hs', 'etf', 'country']:
    if f'{k}_res' not in st.session_state: st.session_state[f'{k}_res'] = None

tab_compass, tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ§­ ë‚˜ì¹¨íŒ", "ğŸŒ ì„¹í„°", "ğŸ³ï¸ êµ­ê°€", "ğŸ“Š ê¸°ìˆ ì ë¶„ì„", "ğŸ’° ì¬ë¬´ë¶„ì„", "ğŸ“‚ ì—‘ì…€"])

# --- 1. ë‚˜ì¹¨íŒ ---
with tab_compass:
    st.markdown("### ğŸ§­ íˆ¬ì ë‚˜ì¹¨íŒ")
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
        # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ë‹¨ì¼ ìŠ¤ë ˆë“œë¡œ ì¶©ë¶„íˆ ë¹ ë¦„)
        OFFENSE = ["QQQ", "SCHD", "IMTM", "GLD", "EMGF"]
        try:
            data = yf.download(OFFENSE + ["BIL"], period="2y", progress=False)['Close']
            m = data.resample('ME').last()
            scores = {}
            for t in OFFENSE:
                if t in m.columns:
                    m12 = m[t].pct_change(12).iloc[-1]; m6 = m[t].pct_change(6).iloc[-1]
                    m3 = m[t].pct_change(3).iloc[-1]; m1 = m[t].pct_change(1).iloc[-1]
                    scores[t] = ((m12+m6)/2 - m3 + m1)*100
            
            df = pd.DataFrame(list(scores.items()), columns=['Ticker','Score']).sort_values('Score', ascending=False)
            top = df.iloc[0]
            pos = top['Ticker'] if top['Score'] > 0 else "BIL"
            
            c1, c2 = st.columns(2)
            c1.success(f"ì¶”ì²œ í¬ì§€ì…˜: **{pos}**")
            c2.metric("1ë“± ì ìˆ˜", f"{top['Score']:.2f}")
            st.dataframe(df)
        except Exception as e: st.error(f"ì˜¤ë¥˜: {e}")

# --- 2. ì„¹í„° ---
with tab1:
    if st.button("ğŸŒ ì„¹í„° ETF ë¶„ì„"):
        etfs = get_etfs_from_sheet()
        if etfs:
            st.session_state.etf_res = run_parallel(etfs, task_momentum)
            
    if st.session_state.etf_res:
        df = pd.DataFrame(st.session_state.etf_res).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
        st.dataframe(df.style.format({"ëª¨ë©˜í…€ì ìˆ˜":"{:.2f}", "í˜„ì¬ê°€":"{:,.0f}", "MACD-V":"{:.2f}"}), use_container_width=True)

# --- 3. êµ­ê°€ ---
with tab2:
    if st.button("ğŸ³ï¸ êµ­ê°€ ETF ë¶„ì„"):
        ctrys = get_country_etfs_from_sheet()
        if ctrys:
            st.session_state.country_res = run_parallel(ctrys, task_momentum)

    if st.session_state.country_res:
        df = pd.DataFrame(st.session_state.country_res).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
        st.dataframe(df.style.format({"ëª¨ë©˜í…€ì ìˆ˜":"{:.2f}", "í˜„ì¬ê°€":"{:,.0f}", "MACD-V":"{:.2f}"}), use_container_width=True)

# --- 4. ê¸°ìˆ ì  ë¶„ì„ (í’€ ì˜µì…˜) ---
with tab3:
    cols = st.columns(7) # í†µí•©, ì»µ, í—¤ìˆ„ í¬í•¨ 7ê°œ
    
    # 1) VCP
    if cols[0].button("ğŸŒªï¸ VCP"):
        ts = get_tickers_from_sheet()
        if ts: st.session_state.vcp_res = run_parallel(ts, task_vcp)
    
    # 2) ì¼ë´‰
    if cols[1].button("ğŸš€ ì¼ë´‰"):
        ts = get_tickers_from_sheet()
        if ts: st.session_state.daily_res = run_parallel(ts, task_daily)

    # 3) ì£¼ë´‰
    if cols[2].button("ğŸ“… ì£¼ë´‰"):
        ts = get_tickers_from_sheet()
        if ts: st.session_state.weekly_res = run_parallel(ts, task_weekly)

    # 4) ì›”ë´‰
    if cols[3].button("ğŸ—“ï¸ ì›”ë´‰"):
        ts = get_tickers_from_sheet()
        if ts: st.session_state.monthly_res = run_parallel(ts, task_monthly)
        
    # 5) ì»µí•¸ë“¤
    if cols[4].button("ğŸ† ì»µí•¸ë“¤"):
        ts = get_tickers_from_sheet()
        if ts: st.session_state.cup_res = run_parallel(ts, task_cup)
        
    # 6) ì—­í—¤ìˆ„
    if cols[5].button("ğŸ‘¤ ì—­H&S"):
        ts = get_tickers_from_sheet()
        if ts: st.session_state.hs_res = run_parallel(ts, task_hs)
        
    # 7) í†µí•© (ê¸°ì¡´ ì½”ë“œì˜ 'í†µí•©' ë²„íŠ¼ ë¡œì§ì€ ë³µì¡í•˜ì—¬ ì¼ë‹¨ ìƒëµí•˜ê±°ë‚˜ í•„ìš”ì‹œ ì¶”ê°€)
    if cols[6].button("âš¡ í†µí•©"):
        st.info("í†µí•© ë¶„ì„ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ ì¼ì‹œ ì œì™¸í–ˆìŠµë‹ˆë‹¤. (ê°œë³„ íƒ­ í™œìš© ê¶Œì¥)")

    # --- ê²°ê³¼ ì¶œë ¥ ì˜ì—­ ---
    if st.session_state.vcp_res:
        st.markdown("#### ğŸŒªï¸ VCP ë¶„ì„ ê²°ê³¼")
        # ì°¨íŠ¸ ë¶„ë¦¬
        disp = []; charts = {}
        for r in st.session_state.vcp_res:
            row = r.copy()
            charts[row['ì¢…ëª©ì½”ë“œ']] = {'df':row.pop('chart_df'), 'info':row.pop('chart_info')}
            row['í˜„ì¬ê°€'] = f"{row['í˜„ì¬ê°€']:,.0f}"; row['ì†ì ˆê°€'] = f"{row['ì†ì ˆê°€']:,.0f}"; row['Pivot'] = f"{row['Pivot']:,.0f}"
            row['ëª©í‘œê°€(3R)'] = f"{row['ëª©í‘œê°€(3R)']:,.0f}"
            disp.append(row)
        
        st.dataframe(pd.DataFrame(disp).sort_values('ë¹„ê³ ', ascending=False), use_container_width=True)
        save_to_supabase(disp, "VCP")
        
        # ê°¤ëŸ¬ë¦¬
        targets = [k for k,v in charts.items() if "4ë‹¨ê³„" in v['info']['status']]
        if targets:
            st.markdown("---")
            st.markdown("#### ğŸš€ ëŒíŒŒ ê°¤ëŸ¬ë¦¬")
            for i in range(0, len(targets), 2):
                c1, c2 = st.columns(2)
                t1 = targets[i]
                c1.plotly_chart(plot_vcp_chart(charts[t1]['df'], t1, charts[t1]['info']), use_container_width=True)
                if i+1 < len(targets):
                    t2 = targets[i+1]
                    c2.plotly_chart(plot_vcp_chart(charts[t2]['df'], t2, charts[t2]['info']), use_container_width=True)

    if st.session_state.daily_res:
        st.markdown("#### ğŸš€ ì¼ë´‰ 5-Factor ê²°ê³¼")
        df = pd.DataFrame(st.session_state.daily_res)
        st.dataframe(df.style.format({'í˜„ì¬ê°€':'{:,.0f}', 'ATR':'{:,.0f}', 'MACD-V':'{:.2f}'}), use_container_width=True)
        save_to_supabase(st.session_state.daily_res, "Daily")

    if st.session_state.weekly_res:
        st.markdown("#### ğŸ“… ì£¼ë´‰ ì „ëµ ê²°ê³¼")
        df = pd.DataFrame(st.session_state.weekly_res)
        st.dataframe(df.style.format({'í˜„ì¬ê°€':'{:,.0f}', 'MACD-V':'{:.2f}'}), use_container_width=True)
        save_to_supabase(st.session_state.weekly_res, "Weekly")
        
    if st.session_state.monthly_res:
        st.markdown("#### ğŸ—“ï¸ ì›”ë´‰ ATH ê²°ê³¼")
        df = pd.DataFrame(st.session_state.monthly_res)
        st.dataframe(df.style.format({'í˜„ì¬ê°€':'{:,.0f}', 'ATHìµœê³ ê°€':'{:,.0f}'}), use_container_width=True)
        save_to_supabase(st.session_state.monthly_res, "Monthly")
        
    if st.session_state.cup_res:
        st.markdown("#### ğŸ† ì»µì•¤í•¸ë“¤ ê²°ê³¼")
        df = pd.DataFrame(st.session_state.cup_res)
        st.dataframe(df.style.format({'í˜„ì¬ê°€':'{:,.0f}', 'ëŒíŒŒê°€ê²©':'{:,.0f}'}), use_container_width=True)
        save_to_supabase(st.session_state.cup_res, "CupHandle")

    if st.session_state.hs_res:
        st.markdown("#### ğŸ‘¤ ì—­í—¤ë“œì•¤ìˆ„ë” ê²°ê³¼")
        df = pd.DataFrame(st.session_state.hs_res)
        st.dataframe(df.style.format({'í˜„ì¬ê°€':'{:,.0f}', 'ë„¥ë¼ì¸':'{:,.0f}'}), use_container_width=True)
        save_to_supabase(st.session_state.hs_res, "InverseHS")

# --- 5. ì¬ë¬´ ë¶„ì„ ---
with tab4:
    if st.button("ğŸ“Š ì¬ë¬´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        # ì¬ë¬´ ë°ì´í„°ëŠ” í˜¸ì¶œì´ ëŠë¦¬ë¯€ë¡œ ë³‘ë ¬ë³´ë‹¤ëŠ” ìˆœì°¨ ì²˜ë¦¬ + progress bar ìœ ì§€ (ì•ˆì •ì„±)
        ts = get_tickers_from_sheet()
        if ts:
            res = []
            bar = st.progress(0)
            for i, t in enumerate(ts):
                try:
                    tick = yf.Ticker(t.split('.')[0]) # .KS ì œê±° í›„ ì¡°íšŒ
                    info = tick.info
                    res.append({
                        'ì¢…ëª©':t, 'ì‹œì´':f"{info.get('marketCap',0)/100000000:.0f}ì–µ",
                        'PER':info.get('trailingPE','-'), 'PBR':info.get('priceToBook','-'),
                        'ë§¤ì¶œì„±ì¥':f"{info.get('revenueGrowth',0)*100:.1f}%"
                    })
                except: pass
                bar.progress((i+1)/len(ts))
            bar.empty()
            st.dataframe(pd.DataFrame(res), use_container_width=True)

# --- 6. ì—‘ì…€ ë§¤ì¹­ ---
with tab5:
    up_file = st.file_uploader("quant_master.xlsx ì—…ë¡œë“œ", type=['xlsx'])
    if up_file and st.button("DB ì—…ë¡œë“œ"):
        try:
            xls = pd.read_excel(up_file, sheet_name=None, header=None)
            # (ê¸°ì¡´ ë³µì¡í•œ íŒŒì‹± ë¡œì§ì€ ë„ˆë¬´ ê¸¸ì–´ ìƒëµí•˜ì˜€ìœ¼ë‚˜ í•„ìš”ì‹œ ë³µì› ê°€ëŠ¥. 
            #  ì—¬ê¸°ì„œëŠ” í•µì‹¬ì¸ 'ì¤‘ë³µ í‹°ì»¤ ì²˜ë¦¬'ë§Œ ê°„ë‹¨íˆ êµ¬í˜„)
            st.success("ì—…ë¡œë“œ ê¸°ëŠ¥ì€ í˜„ì¬ ê°„ì†Œí™” ìƒíƒœì…ë‹ˆë‹¤.")
        except: st.error("íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")

# Footer
st.markdown("---")
with st.expander("ğŸ› ï¸ DB ê´€ë¦¬"):
    if st.button("ê¸°ë¡ ë³´ê¸°"):
        r = supabase.table("history").select("*").order("created_at", desc=True).limit(50).execute()
        st.dataframe(pd.DataFrame(r.data))
