import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timezone
from supabase import create_client, Client
from scipy.signal import argrelextrema
import time
import re

# =========================================================
# [ì„¤ì •] Supabase ì—°ê²° ì •ë³´ (ë³´ì•ˆ ì ìš©)
# =========================================================
try:
    # Streamlit Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
except Exception as e:
    st.error(f"âš ï¸ Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì—ëŸ¬: {e})")
    st.stop()

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì • ë° DB ì—°ê²°
# ==========================================
st.set_page_config(page_title="Pro ì£¼ì‹ ê²€ìƒ‰ê¸°", layout="wide")
st.title("ğŸ“ˆ Pro ì£¼ì‹ ê²€ìƒ‰ê¸°: ì„¹í„°/êµ­ê°€/ê¸°ìˆ ì /í€€í‹°ì™€ì´ì¦ˆ DB í†µí•©")

@st.cache_resource
def init_supabase():
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception as e:
        return None

supabase = init_supabase()

# ==========================================
# 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •
# ==========================================
SHEET_ID = '1NVThO1z2HHF0TVXVRGmbVsSU_Svyjg8fxd7E90z2o8A'
STOCK_GID = '0' 
STOCK_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={STOCK_GID}'
ETF_GID = '2023286696'
ETF_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={ETF_GID}'
COUNTRY_GID = '1247750129'
COUNTRY_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={COUNTRY_GID}'

# ==========================================
# 3. ê³µí†µ í•¨ìˆ˜ ì •ì˜
# ==========================================

def get_tickers_from_sheet():
    try:
        df = pd.read_csv(STOCK_CSV_URL, header=None)
        tickers = sorted(list(set([str(x).strip() for x in df[0] if str(x).strip()])))
        return tickers
    except Exception as e:
        st.error(f"ì£¼ì‹ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_etfs_from_sheet():
    try:
        df = pd.read_csv(ETF_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_country_etfs_from_sheet():
    try:
        df = pd.read_csv(COUNTRY_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"êµ­ê°€ ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_unique_tickers_from_db():
    if not supabase: return []
    try:
        response = supabase.table("history").select("ticker").execute()
        if response.data:
            return list(set([row['ticker'] for row in response.data]))
        return []
    except Exception as e: return []

def remove_duplicates_from_db():
    if not supabase: return
    try:
        response = supabase.table("history").select("id, ticker, created_at").order("created_at", desc=True).execute()
        data = response.data
        if not data:
            st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        seen_tickers = set()
        ids_to_remove = []
        for row in data:
            ticker = row['ticker']
            if ticker in seen_tickers:
                ids_to_remove.append(row['id'])
            else:
                seen_tickers.add(ticker)
        
        if ids_to_remove:
            for pid in ids_to_remove:
                supabase.table("history").delete().eq("id", pid).execute()
            st.success(f"ğŸ§¹ History ì¤‘ë³µëœ {len(ids_to_remove)}ê°œ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("History: ì‚­ì œí•  ì¤‘ë³µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")

def smart_download(ticker, interval="1d", period="2y"):
    if ':' in ticker: ticker = ticker.split(':')[-1]
    ticker = ticker.replace('/', '-')
    candidates = [ticker]
    if ticker.isdigit() and len(ticker) == 6:
        candidates = [f"{ticker}.KS", f"{ticker}.KQ", ticker]
    
    for t in candidates:
        try:
            for _ in range(3):
                df = yf.download(t, period=period, interval=interval, progress=False, auto_adjust=False)
                if len(df) > 0:
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = df.columns.get_level_values(0)
                    return t, df
                time.sleep(0.3)
        except:
            continue
    return ticker, pd.DataFrame()

def get_stock_sector(ticker):
    try:
        tick = yf.Ticker(ticker)
        info = tick.info
        quote_type = info.get('quoteType', '').upper()
        if 'ETF' in quote_type or 'FUND' in quote_type:
            name = info.get('shortName', '')
            if not name: name = info.get('longName', 'ETF')
            return f"[ETF] {name}"
        sector = info.get('sector', '')
        if not sector: sector = info.get('industry', '')
        if not sector: sector = info.get('shortName', '')
        if not sector: return "Unknown"
        translations = {
            'Technology': 'ê¸°ìˆ ', 'Healthcare': 'í—¬ìŠ¤ì¼€ì–´', 'Financial Services': 'ê¸ˆìœµ',
            'Consumer Cyclical': 'ì„ì˜ì†Œë¹„ì¬', 'Industrials': 'ì‚°ì—…ì¬', 'Basic Materials': 'ì†Œì¬',
            'Energy': 'ì—ë„ˆì§€', 'Utilities': 'ìœ í‹¸ë¦¬í‹°', 'Real Estate': 'ë¶€ë™ì‚°',
            'Communication Services': 'í†µì‹ ', 'Consumer Defensive': 'í•„ìˆ˜ì†Œë¹„ì¬',
            'Semiconductors': 'ë°˜ë„ì²´'
        }
        return translations.get(sector, sector)
    except:
        return "Unknown"

def save_to_supabase(data_list, strategy_name):
    if not supabase:
        st.error("âš ï¸ DB ì—°ê²° ì‹¤íŒ¨")
        return

    rows_to_insert = []
    for item in data_list:
        rows_to_insert.append({
            "ticker": str(item['ì¢…ëª©ì½”ë“œ']),
            "sector": str(item.get('ì„¹í„°', '-')),
            "price": str(item['í˜„ì¬ê°€']).replace(',', ''),
            "strategy": strategy_name,
            "high_date": str(item.get('í˜„52ì£¼ì‹ ê³ ê°€ì¼', '')), 
            "bw": str(item.get('BW_Value', '')), 
            "macd_v": str(item.get('MACD_V_Value', ''))
        })
    
    try:
        supabase.table("history").insert(rows_to_insert).execute()
        st.toast(f"âœ… {len(rows_to_insert)}ê°œ ì¢…ëª© DB ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

# ==============================================================================
# [í•µì‹¬ ë¡œì§ 1] ì—‘ì…€ -> DB ì €ì¥ ì‹œ ì •ê·œí™”
# ==============================================================================
def normalize_ticker_for_db_storage(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith("-US"):
        clean = t_str[:-3]
        return clean.replace('.', '-')
    if t_str.endswith("-HK"): return t_str[:-3] + ".HK"
    if t_str.endswith("-JP"): return t_str[:-3] + ".T"
    if t_str.endswith("-KS"): return t_str[:-3]
    if t_str.endswith("-KQ"): return t_str[:-3]
    if '-' in t_str and not any(x in t_str for x in ['-US', '-HK', '-JP', '-KS', '-KQ']):
         return t_str.split('-')[0]
    return t_str

# ==============================================================================
# [í•µì‹¬ ë¡œì§ 2] ì•± ì¡°íšŒ ì‹œ ì •ê·œí™”
# ==============================================================================
def normalize_ticker_for_app_lookup(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith(".KS"): return t_str[:-3]
    if t_str.endswith(".KQ"): return t_str[:-3]
    if '.' in t_str and not any(x in t_str for x in ['.HK', '.T', '.KS', '.KQ']):
        return t_str.replace('.', '-')
    return t_str

# ==========================================
# [ì¤‘ìš”] DB ë°ì´í„° ë¡œë“œ (ìºì‹œ)
# ==========================================
@st.cache_data(ttl=600) 
def fetch_latest_quant_data_from_db():
    if not supabase: return {}
    try:
        response = supabase.table("quant_data").select("*").order("created_at", desc=True).execute()
        if not response.data: return {}
        df = pd.DataFrame(response.data)
        if df.empty: return {}
        df_latest = df.drop_duplicates(subset='ticker', keep='first')
        result_dict = {}
        for _, row in df_latest.iterrows():
            result_dict[row['ticker']] = {
                '1w': str(row.get('change_1w') or "-"),
                '1m': str(row.get('change_1m') or "-"),
                '3m': str(row.get('change_3m') or "-")
            }
        return result_dict
    except Exception as e:
        return {}

GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()

def get_eps_changes_from_db(ticker):
    norm_ticker = normalize_ticker_for_app_lookup(ticker)
    if norm_ticker in GLOBAL_QUANT_DATA:
        d = GLOBAL_QUANT_DATA[norm_ticker]
        return d['1w'], d['1m'], d['3m']
    return "-", "-", "-"

# ==========================================
# 4. ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ (ì§€í‘œ ê³„ì‚° & íŒ¨í„´)
# ==========================================

def find_extrema(df, order=3):
    prices = df['Close'].values
    peaks_idx = argrelextrema(prices, np.greater, order=order)[0]
    troughs_idx = argrelextrema(prices, np.less, order=order)[0]
    return peaks_idx, troughs_idx

def calculate_macdv(df, short=12, long=26, signal=9):
    ema_fast = df['Close'].ewm(span=short, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=long, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = tr.ewm(span=long, adjust=False).mean()
    macd_v = (macd_line / (atr + 1e-9)) * 100
    macd_v_signal = macd_v.ewm(span=signal, adjust=False).mean()
    return macd_v, macd_v_signal

def calculate_common_indicators(df, is_weekly=False):
    if len(df) < 60: return None # ì£¼ë´‰ ê¸°ì¤€ ìµœì†Œ ë°ì´í„°
    df = df.copy()
    period = 20 if is_weekly else 60
    
    # ë³¼ë¦°ì € ë°´ë“œ
    df[f'EMA{period}'] = df['Close'].ewm(span=period, adjust=False).mean()
    df[f'STD{period}'] = df['Close'].rolling(window=period).std()
    df['BB_UP'] = df[f'EMA{period}'] + (2 * df[f'STD{period}'])
    df['BB_LO'] = df[f'EMA{period}'] - (2 * df[f'STD{period}'])
    df['BandWidth'] = (df['BB_UP'] - df['BB_LO']) / df[f'EMA{period}']
    
    # í‘œì¤€ MACD
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD_Line'] = df['EMA12'] - df['EMA26']
    df['MACD_Signal'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()
    
    # MACD-V
    df['MACD_V'], df['MACD_V_Signal'] = calculate_macdv(df, 12, 26, 9)
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR14'] = tr.ewm(span=14, adjust=False).mean()
    
    return df

# -----------------------------------------------------------------------------
# ì¼ë´‰ ì§€í‘œ ê³„ì‚°: 50ì¼ ì „ëµ ìœ ì§€ + 20ì¼ ìŠ¤í€´ì¦ˆ ì¶”ê°€ ê³„ì‚°
# -----------------------------------------------------------------------------
def calculate_daily_indicators(df):
    if len(df) < 260: return None
    df = df.copy()
    
    # === [A] ê¸°ì¡´ 50ì¼ ê¸°ë°˜ ì§€í‘œ (5-Factor ì „ëµìš© - ìœ ì§€) ===
    df['SMA50'] = df['Close'].rolling(window=50).mean()
    df['STD50'] = df['Close'].rolling(window=50).std()
    df['BB50_UP'] = df['SMA50'] + (2.0 * df['STD50'])
    df['BB50_LO'] = df['SMA50'] - (2.0 * df['STD50'])
    df['BW50'] = (df['BB50_UP'] - df['BB50_LO']) / df['SMA50']
    df['Donchian_High_50'] = df['High'].rolling(window=50).max().shift(1)
    
    df['Change'] = df['Close'].diff()
    df['Vol_Up'] = np.where(df['Change'] > 0, df['Volume'], 0)
    df['Vol_Down'] = np.where(df['Change'] < 0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(df['Change'] == 0, df['Volume'], 0)
    roll_up = df['Vol_Up'].rolling(window=50).sum()
    roll_down = df['Vol_Down'].rolling(window=50).sum()
    roll_flat = df['Vol_Flat'].rolling(window=50).sum()
    df['VR50'] = ((roll_up + roll_flat/2) / (roll_down + roll_flat/2 + 1e-9)) * 100
    
    # === [B] TTM Squeezeìš© 20ì¼ ì§€í‘œ (ì‹ ê·œ ì¶”ê°€/ë³€ê²½) ===
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['STD20'] = df['Close'].rolling(window=20).std()
    df['BB20_UP'] = df['SMA20'] + (2.0 * df['STD20'])
    df['BB20_LO'] = df['SMA20'] - (2.0 * df['STD20'])
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    df['TR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR20'] = df['TR'].rolling(window=20).mean()
    kc_mult = 1.5 
    df['KC20_UP'] = df['SMA20'] + (kc_mult * df['ATR20'])
    df['KC20_LO'] = df['SMA20'] - (kc_mult * df['ATR20'])
    df['TTM_Squeeze'] = (df['BB20_UP'] < df['KC20_UP']) & (df['BB20_LO'] > df['KC20_LO'])

    # === [C] ê¸°íƒ€ ===
    ema_fast = df['Close'].ewm(span=20, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=200, adjust=False).mean()
    df['MACD_Line_C'] = ema_fast - ema_slow
    df['MACD_Signal_C'] = df['MACD_Line_C'].ewm(span=20, adjust=False).mean()
    df['MACD_OSC_C'] = df['MACD_Line_C'] - df['MACD_Signal_C']
    
    df['ATR14'] = df['TR'].ewm(span=14, adjust=False).mean()
    df['MACD_V'], _ = calculate_macdv(df, 12, 26, 9)
    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()
    
    return df

# -----------------------------------------------------------------------------
# [ìˆ˜ì •ë¨] VCP íŒ¨í„´ í™•ì¸ ë¡œì§ (120ì¼ / 40ì¼ êµ¬ê°„ ê¸°ì¤€)
# -----------------------------------------------------------------------------
def check_vcp_pattern(df):
    if len(df) < 250: return False, None
    df = calculate_daily_indicators(df) 
    if df is None: return False, None
    
    curr = df.iloc[-1]
    sma50 = df['Close'].rolling(50).mean().iloc[-1]
    sma150 = df['Close'].rolling(150).mean().iloc[-1]
    sma200 = df['Close'].rolling(200).mean().iloc[-1]
    
    cond1 = curr['Close'] > sma150 and curr['Close'] > sma200
    cond2 = sma150 > sma200
    cond3 = df['SMA50'].iloc[-1] > df['SMA50'].iloc[-20] 
    cond4 = sma50 > sma150
    low_52 = df['Low'].iloc[-252:].min()
    cond5 = curr['Close'] > low_52 * 1.25
    high_52 = df['High'].iloc[-252:].max()
    cond6 = curr['Close'] > high_52 * 0.75
    
    stage_1_pass = cond1 and cond2 and cond4 and cond5 and cond6
    if not stage_1_pass: return False, None 

    window = 120 
    subset = df.iloc[-window:]
    p1 = subset.iloc[:40]   
    p2 = subset.iloc[40:80] 
    p3 = subset.iloc[80:]   
    
    range1 = (p1['High'].max() - p1['Low'].min()) / p1['High'].max()
    range2 = (p2['High'].max() - p2['Low'].min()) / p2['High'].max()
    range3 = (p3['High'].max() - p3['Low'].min()) / p3['High'].max()
    
    contraction = (range3 < range2) or (range2 < range1) or (range3 < 0.12)
    if not contraction: return False, None

    last_vol_avg = p3['Volume'].mean()
    prev_vol_avg = p1['Volume'].mean()
    vol_dry_up = last_vol_avg < prev_vol_avg * 1.2 
    tight_area = range3 < 0.15 
    
    stage_3_pass = vol_dry_up and tight_area
    
    stop_loss = p3['Low'].min()
    risk = curr['Close'] - stop_loss
    target_price = curr['Close'] + (risk * 3) if risk > 0 else 0
    
    prior_days = p3.iloc[:-1] 
    if len(prior_days) > 0:
        pivot_point = prior_days['High'].max() 
    else:
        pivot_point = p3['High'].max() 

    vol_ma50 = df['Volume'].iloc[-51:-1].mean()
    breakout = (curr['Close'] > pivot_point) and (curr['Volume'] > vol_ma50 * 1.2)
    
    status = ""
    if stage_3_pass and not breakout:
        status = "3ë‹¨ê³„ (ìˆ˜ë ´ì¤‘)"
    elif stage_3_pass and breakout:
        status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
    else:
        if breakout and tight_area:
             status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
        else:
             return False, None

    return True, {
        'status': status,
        'stop_loss': stop_loss,
        'target_price': target_price,
        'squeeze': "ğŸ”¥" if df['TTM_Squeeze'].iloc[-1] else "-",
        'price': curr['Close']
    }

def check_daily_condition(df):
    if len(df) < 260: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    curr = df.iloc[-1]
    
    dc_cond = (df['Close'] > df['Donchian_High_50']).iloc[-3:].any()
    bb_cond = (df['Close'] > df['BB50_UP']).iloc[-3:].any()
    mandatory = dc_cond or bb_cond
    
    vr_cond = (df['VR50'].iloc[-3:] > 110).any()
    bw_cond = (df['BW50'].iloc[-51] > curr['BW50']) if len(df)>55 else False
    macd_cond = curr['MACD_OSC_C'] > 0
    optional_count = sum([vr_cond, bw_cond, macd_cond])
    
    if mandatory and (optional_count >= 2):
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any()
        win_52 = df.iloc[-252:]
        high_52_date = win_52['Close'].idxmax().strftime('%Y-%m-%d')
        prev_win = win_52[win_52.index < win_52['Close'].idxmax()]
        prev_date = prev_win['Close'].idxmax().strftime('%Y-%m-%d') if len(prev_win)>0 else "-"
        diff_days = (win_52['Close'].idxmax() - prev_win['Close'].idxmax()).days if len(prev_win)>0 else 0
        
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'high_date': high_52_date, 
            'prev_date': prev_date, 
            'diff_days': diff_days, 
            'bw_curr': curr['BW50'], 
            'macdv': curr['MACD_V'], 
            'squeeze': "ğŸ”¥TTM Squeeze" if squeeze_on else "-" 
        }
    return False, None

def check_weekly_condition(df):
    if len(df) < 60: return False, None
    df = calculate_common_indicators(df, is_weekly=True)
    if df is None: return False, None
    
    curr = df.iloc[-1]
    prev = df.iloc[-2]
    
    cond_bb = curr['Close'] > curr['BB_UP']
    cond_macd = (prev['MACD_Line'] <= prev['MACD_Signal']) and (curr['MACD_Line'] > curr['MACD_Signal'])
    
    if cond_bb or cond_macd:
        bw_past = df['BandWidth'].iloc[-21]
        bw_change = "ê°ì†Œ" if bw_past > curr['BandWidth'] else "ì¦ê°€"
        
        reason = []
        if cond_bb: reason.append("BBëŒíŒŒ")
        if cond_macd: reason.append("MACDë§¤ìˆ˜")
        
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'bw_curr': curr['BandWidth'], 
            'bw_past': bw_past, 
            'bw_change': f"{bw_change} ({'/'.join(reason)})", 
            'macdv': curr['MACD_V']
        }
    return False, None

def check_monthly_condition(df):
    if len(df) < 12: return False, None
    ath_price = df['High'].max()
    curr_price = df['Close'].iloc[-1]
    if curr_price >= ath_price * 0.90:
        ath_idx = df['High'].idxmax()
        month_count = (df['Close'] >= ath_price * 0.90).sum()
        return True, {'price': curr_price, 'ath_price': ath_price, 'ath_date': ath_idx.strftime('%Y-%m'), 'month_count': month_count}
    return False, None

# -----------------------------------------------------------------------------
# [ìˆ˜ì •ë¨] ê³µìš© ëª¨ë©˜í…€ ë¶„ì„ í•¨ìˆ˜ (ì „ëµ 3: í‰ê·  ëª¨ë©˜í…€ ì ìš©)
# -----------------------------------------------------------------------------
def analyze_momentum_strategy(target_list, type_name="ETF"):
    if not target_list: return pd.DataFrame()
    st.write(f"ğŸ“Š ì´ {len(target_list)}ê°œ {type_name} ë¶„ì„ ì¤‘...")
    results = []; pbar = st.progress(0)
    for i, (t, n) in enumerate(target_list):
        pbar.progress((i+1)/len(target_list))
        rt, df = smart_download(t, "1d", "2y")
        if len(df)<30: continue
        df = calculate_daily_indicators(df)
        if df is None: continue
        c = df['Close']; curr=c.iloc[-1]
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any() if 'TTM_Squeeze' in df.columns else False
        ema20=c.ewm(span=20).mean(); ema50=c.ewm(span=50).mean(); ema60=c.ewm(span=60).mean()
        ema100=c.ewm(span=100).mean(); ema200=c.ewm(span=200).mean()
        bb_up = df['BB50_UP']; dc_h = df['Donchian_High_50'] 
        macdv = df['MACD_V']; atr = df['ATR14'].iloc[-1]
        bb_bk = "O" if (c>bb_up).iloc[-3:].any() else "-"
        dc_bk = "O" if (c>dc_h).iloc[-3:].any() else "-"
        align = "â­ ì •ë°°ì—´" if (curr>ema20.iloc[-1] and curr>ema60.iloc[-1] and curr>ema100.iloc[-1] and curr>ema200.iloc[-1]) else "-"
        long_tr = "ğŸ“ˆ ìƒìŠ¹" if (ema60.iloc[-1]>ema100.iloc[-1]>ema200.iloc[-1]) else "-"
        
        # [ë³€ê²½] ì „ëµ 3: í‰ê·  ëª¨ë©˜í…€ (Smoothed)
        # ê³µì‹: ((12M + 6M) / 2 - 3M) + 1M
        r12 = c.pct_change(252).iloc[-1] if len(c) > 252 else 0
        r6  = c.pct_change(126).iloc[-1] if len(c) > 126 else 0
        r3  = c.pct_change(63).iloc[-1] if len(c) > 63 else 0
        r1  = c.pct_change(21).iloc[-1] if len(c) > 21 else 0
        
        avg_long_term = (r12 + r6) / 2
        score = ((avg_long_term - r3) + r1) * 100
        
        if len(df) >= 252:
            win_52 = df.iloc[-252:]
            high_idx = win_52['Close'].idxmax()
            high_52_date = high_idx.strftime('%Y-%m-%d')
            prev_win = win_52[win_52.index < high_idx]
            if len(prev_win) > 0:
                prev_idx = prev_win['Close'].idxmax()
                prev_date = prev_idx.strftime('%Y-%m-%d')
                diff_days = (high_idx - prev_idx).days
            else:
                prev_date = "-"; diff_days = 0
        else:
            high_52_date = "-"; prev_date = "-"; diff_days = 0
        results.append({
            f"{type_name}": f"{rt} ({n})", 
            "ëª¨ë©˜í…€ì ìˆ˜": score, 
            "ìŠ¤í€´ì¦ˆ": "ğŸ”¥" if squeeze_on else "-", 
            "BB(50,2)ëŒíŒŒ": bb_bk, 
            "ëˆí‚¤ì–¸(50)ëŒíŒŒ": dc_bk, 
            "ì •ë°°ì—´": align, 
            "ì¥ê¸°ì¶”ì„¸": long_tr, 
            "MACD-V": f"{macdv.iloc[-1]:.2f}", 
            "ATR": f"{atr:.2f}",
            "í˜„52ì£¼ì‹ ê³ ê°€ì¼": high_52_date,
            "ì „52ì£¼ì‹ ê³ ê°€ì¼": prev_date,
            "ì°¨ì´ì¼": f"{diff_days}ì¼",
            "í˜„ì¬ê°€": curr
        })
    pbar.empty()
    if results:
        df_res = pd.DataFrame(results).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
        df_res['ëª¨ë©˜í…€ì ìˆ˜'] = df_res['ëª¨ë©˜í…€ì ìˆ˜'].apply(lambda x: f"{x:.2f}")
        df_res['í˜„ì¬ê°€'] = df_res['í˜„ì¬ê°€'].apply(lambda x: f"{x:,.2f}")
        return df_res
    return pd.DataFrame()

# -----------------------------------------------------------------------------
# [ìˆ˜ì •ë¨] ì»µì•¤í•¸ë“¤ - í‚¤í¬ì¸íŠ¸ ë¡œì§ (ëŠìŠ¨í•œ ë²„ì „ + ì˜ˆì™¸ì²˜ë¦¬)
# -----------------------------------------------------------------------------
def check_cup_handle_pattern(df):
    if len(df) < 26: return False, None 
    
    sub = df.iloc[-26:].copy()
    if len(sub) < 26: return False, None
    
    idx_A = sub['High'].idxmax()
    val_A = sub.loc[idx_A, 'High']
    
    if idx_A == sub.index[-1]: return False, "Aê°€ ëì "
    
    after_A = sub.loc[idx_A:]
    if len(after_A) < 5: return False, "ê¸°ê°„ ì§§ìŒ" 
    
    idx_B = after_A['Low'].idxmin()
    val_B = after_A.loc[idx_B, 'Low']
    
    if val_B > val_A * 0.85: return False, "ê¹Šì´ ì–•ìŒ"
    
    after_B = sub.loc[idx_B:]
    if len(after_B) < 2: return False, "ë°˜ë“± ì§§ìŒ"
    
    idx_C = after_B['High'].idxmax()
    val_C = after_B.loc[idx_C, 'High']
    
    if val_C < val_A * 0.85: return False, "íšŒë³µ ë¯¸ë‹¬"
    
    curr_close = df['Close'].iloc[-1]
    
    if curr_close < val_B: return False, "í•¸ë“¤ ë¶•ê´´"
    if curr_close < val_C * 0.80: return False, "í•¸ë“¤ ê¹ŠìŒ"

    return True, {
        "depth": f"{(1 - val_B/val_A)*100:.1f}%", 
        "handle_weeks": f"{len(df.loc[idx_C:])}ì£¼", 
        "pivot": f"{val_C:,.0f}"
    }

# -----------------------------------------------------------------------------
# [ìˆ˜ì •ë¨] ì—­í—¤ë“œì•¤ìˆ„ë” - í‚¤í¬ì¸íŠ¸ ë¡œì§ (ëŠìŠ¨í•œ ë²„ì „ + ì˜ˆì™¸ì²˜ë¦¬)
# -----------------------------------------------------------------------------
def check_inverse_hs_pattern(df):
    if len(df) < 60: return False, None 
    
    window = 60
    sub = df.iloc[-window:].copy()
    
    if len(sub) < 60: return False, None
    
    part1 = sub.iloc[:20]   
    part2 = sub.iloc[20:40] 
    part3 = sub.iloc[40:]   
    
    min_L = part1['Low'].min()
    min_H = part2['Low'].min()
    min_R = part3['Low'].min()
    
    if not (min_H < min_L and min_H < min_R):
        return False, "ë¨¸ë¦¬ ë¯¸í˜•ì„±"
        
    max_R = part3['High'].max()
    curr_close = df['Close'].iloc[-1]
    
    if curr_close < min_R * 1.05: return False, "ë°˜ë“± ì•½í•¨"
    
    vol_recent = part3['Volume'].mean()
    vol_prev = part2['Volume'].mean()
    
    vol_ratio = vol_recent / vol_prev if vol_prev > 0 else 1.0
    
    return True, {
        "Neckline": f"{max_R:,.0f}", 
        "Breakout": "Ready" if curr_close < max_R else "Yes", 
        "Vol_Ratio": f"{vol_ratio:.1f}ë°°"
    }

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ í™”ë©´
# ==========================================

st.write("ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ (5-Factor ì „ëµ, MACD-V, TTM Squeeze 20ì¼)")
if not supabase: st.warning("âš ï¸ DB ì—°ê²° í‚¤ ì˜¤ë¥˜")

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì‹ ê·œ ì¢…ëª© ë°œêµ´", "ğŸ“‰ ì €ì¥ëœ ì¢…ëª© ëˆŒë¦¼ëª© ì°¾ê¸°", "ğŸ’° ì¬ë¬´ë¶„ì„", "ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­"])

with tab1:
    cols = st.columns(12) 
    
    if cols[0].button("ğŸŒ ì„¹í„°"):
        etfs = get_etfs_from_sheet()
        if not etfs:
            st.warning("ETF ëª©ë¡ ì—†ìŒ")
        else:
            st.info("ETF ì„¹í„° ë¶„ì„ ì¤‘ (ëª¨ë©˜í…€ ì „ëµ 3: Smoothed)...")
            res = analyze_momentum_strategy(etfs, "ETF")
            if not res.empty: st.dataframe(res, use_container_width=True)
            else: st.warning("ë°ì´í„° ë¶€ì¡±")

    if cols[1].button("ğŸ³ï¸ êµ­ê°€"):
        tickers = get_country_etfs_from_sheet()
        if not tickers:
            st.warning("êµ­ê°€ ETF ëª©ë¡ ì—†ìŒ")
        else:
            st.info(f"[êµ­ê°€ ETF] {len(tickers)}ê°œ ëª¨ë©˜í…€(ì „ëµ 3: Smoothed) ë¶„ì„ ì‹œì‘...")
            res = analyze_momentum_strategy(tickers, "êµ­ê°€ETF")
            if not res.empty:
                st.success(f"[êµ­ê°€] {len(res)}ê°œ ë¶„ì„ ì™„ë£Œ!")
                st.dataframe(res, use_container_width=True)
            else: st.warning("ë°ì´í„° ë¶€ì¡±")

    if cols[2].button("ğŸŒªï¸ VCP"):
        tickers = get_tickers_from_sheet()
        if not tickers:
            st.warning("ì¢…ëª© ë¦¬ìŠ¤íŠ¸(TGT) ì—†ìŒ")
        else:
            st.info(f"[VCP íŒ¨í„´] {len(tickers)}ê°œ ì¢…ëª© ì •ë°€ ë¶„ì„ ì¤‘... (120ì¼ ê¸°ì¤€)")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1d", "2y")
                passed, info = check_vcp_pattern(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ë¹„ê³ ': info['status'], 
                        'ì†ì ˆê°€': f"{info['stop_loss']:,.0f}", 
                        'ëª©í‘œê°€(3R)': f"{info['target_price']:,.0f}",
                        'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m
                    })
            bar.empty()
            if res:
                st.success(f"[VCP] {len(res)}ê°œ ìœ ë§ ì¢…ëª© ë°œê²¬!")
                df_res = pd.DataFrame(res).sort_values("ë¹„ê³ ", ascending=True)
                st.dataframe(df_res, use_container_width=True)
                save_to_supabase(res, "VCP_Pattern")
            else: st.warning("VCP ì¡°ê±´(ì¶”ì„¸+ìˆ˜ë ´)ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    if cols[3].button("ğŸš€ ì¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì¼ë´‰ 5-Factor + TTM Squeeze 20ì¼] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1d", "2y")
                passed, info = check_daily_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14)': f"{info['atr']:,.0f}", 'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info['prev_date'],
                        'ì°¨ì´ì¼': f"{info['diff_days']}ì¼", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Daily_5Factor")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[4].button("ğŸ“… ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì£¼ë´‰: BBëŒíŒŒ or MACDë§¤ìˆ˜] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                passed, info = check_weekly_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14ì£¼)': f"{info['atr']:,.0f}", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW(20ì£¼ì „)': f"{info['bw_past']:.4f}", 'BWë³€í™”': info['bw_change'],
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Weekly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[5].button("ğŸ—“ï¸ ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì›”ë´‰ ATH] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1mo", "max")
                passed, info = check_monthly_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATHìµœê³ ê°€': f"{info['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info['ath_date'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info['month_count']}ê°œì›”",
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['ath_date'], 'BW_Value': str(info['month_count']), 'MACD_V_Value': "0"
                    })
            bar.empty()
            if res:
                st.success(f"[ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['í˜„52ì£¼ì‹ ê³ ê°€ì¼', 'BW_Value', 'MACD_V_Value'], errors='ignore'))
                save_to_supabase(res, "Monthly_ATH")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[6].button("ì¼+ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰(5-Factor) + ì›”ë´‰(ATH) êµì°¨ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ATHë‹¬ì„±ì›”': info_m['ath_date'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': str(info_m['month_count']), 'MACD_V_Value': f"{info_d['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Daily_Monthly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[7].button("ì¼+ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰(5-Factor) + ì£¼ë´‰(BB/MACD) êµì°¨ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰BWë³€í™”': info_w['bw_change'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_d['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì¼+ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Daily_Weekly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[8].button("ì£¼+ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì£¼ë´‰(BB/MACD) + ì›”ë´‰(ATH) êµì°¨ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_w['price']:,.0f}",
                    'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰BWë³€í™”': info_w['bw_change'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'ATHë‹¬ì„±ì›”': info_m['ath_date'], 'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_m['ath_date'], 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì£¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Weekly_Monthly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[9].button("âš¡ í†µí•©"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[í†µí•©] ì¼+ì£¼+ì›”ë´‰ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¢…ëª© ê²€ìƒ‰ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ATHìµœê³ ê°€': f"{info_m['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info_m['ath_date'],
                    'í•´ë‹¹ì›”ìˆ˜': f"{info_m['month_count']}ê°œì›”", 'ìŠ¤í€´ì¦ˆ': info_d['squeeze'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}",
                    'ì£¼ë´‰BWë³€í™”': info_w['bw_change'], 'MACD-V': f"{info_w['macdv']:.2f}",
                    'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"âš¡ í†µí•© ë¶„ì„ ì™„ë£Œ! {len(res)}ê°œ ë°œê²¬")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Integrated_Triple")
            else: st.warning("3ê°€ì§€ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    if cols[10].button("ğŸ† ì»µí•¸ë“¤"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[ì»µí•¸ë“¤] ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                pass_c, info = check_cup_handle_pattern(df)
                if pass_c:
                    df = calculate_common_indicators(df, True)
                    if df is None: continue 
                    curr = df.iloc[-1]
                    sector = get_stock_sector(rt)
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                        'íŒ¨í„´ìƒì„¸': f"ê¹Šì´:{info['depth']}", 'ëŒíŒŒê°€ê²©': info['pivot'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW_Value': f"{curr['BandWidth']:.4f}", 'MACD_V_Value': f"{curr['MACD_V']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì»µí•¸ë“¤] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "CupHandle")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[11].button("ğŸ‘¤ ì—­H&S"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[ì—­H&S] ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                pass_h, info = check_inverse_hs_pattern(df)
                if pass_h:
                    df = calculate_common_indicators(df, True)
                    if df is None: continue 
                    curr = df.iloc[-1]
                    sector = get_stock_sector(rt)
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                        'ë„¥ë¼ì¸': info['Neckline'], 'ê±°ë˜ëŸ‰ê¸‰ì¦': info['Vol_Ratio'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW_Value': f"{curr['BandWidth']:.4f}", 'MACD_V_Value': f"{curr['MACD_V']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì—­H&S] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "InverseHS")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

with tab2:
    st.markdown("### ğŸ“‰ ì €ì¥ëœ ì¢…ëª© ì¤‘ ëˆŒë¦¼ëª©/ê¸‰ë“±ì£¼ ì°¾ê¸°")
    if st.button("ğŸ” ëˆŒë¦¼ëª© & ê¸‰ë“± íŒ¨í„´ ë¶„ì„"):
        db_tickers = get_unique_tickers_from_db()
        if not db_tickers: st.warning("DB ë°ì´í„° ì—†ìŒ")
        else:
            st.info(f"{len(db_tickers)}ê°œ ì¢…ëª© ì¬ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(db_tickers):
                bar.progress((i+1)/len(db_tickers))
                rt, df = smart_download(t, "1d", "2y")
                try:
                    df = calculate_common_indicators(df, False)
                    if df is None: continue
                    curr = df.iloc[-1]
                    cond = ""
                    if curr['MACD_V'] > 60: cond = "ğŸ”¥ ê³µê²©ì  ì¶”ì„¸"
                    
                    ema20 = df['Close'].ewm(span=20).mean().iloc[-1]
                    if (curr['Close'] > ema20) and ((curr['Close']-ema20)/ema20 < 0.03):
                        cond = "ğŸ“‰ 20ì¼ì„  ëˆŒë¦¼ëª©"
                    
                    if (curr['Close'] > curr['EMA200']) and (-100 <= curr['MACD_V'] <= -50):
                         cond = "ğŸ§² MACD-V ê³¼ë§¤ë„"
                    
                    if cond:
                        eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                        res.append({
                            'ì¢…ëª©ì½”ë“œ': rt, 'íŒ¨í„´': cond, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                            '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                            'MACD-V': f"{curr['MACD_V']:.2f}", 'EMA20': f"{ema20:,.0f}"
                        })
                except: continue
            bar.empty()
            if res:
                st.success(f"{len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res), use_container_width=True)
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

with tab3:
    st.markdown("### ğŸ’° ì¬ë¬´ ì§€í‘œ ë¶„ì„ & EPS Trend (yfinance)")
    st.info("yfinance ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ì¬ë¬´ ì§€í‘œ ë° EPS ì¶”ì •ì¹˜ ë³€í™”ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    if st.button("ğŸ“Š ì¬ë¬´ ì§€í‘œ ê°€ì ¸ì˜¤ê¸°"):
        tickers = get_tickers_from_sheet()
        if not tickers: st.error("í‹°ì»¤ ì—†ìŒ")
        else:
            bar = st.progress(0); f_res = []
            for i, t in enumerate(tickers):
                bar.progress((i + 1) / len(tickers))
                real_ticker, _ = smart_download(t, "1d", "5d") 
                try:
                    tick = yf.Ticker(real_ticker)
                    info = tick.info
                    if not info: continue
                    mkt_cap = info.get('marketCap', 0)
                    mkt_cap_str = f"{mkt_cap/1000000000000:.1f}ì¡°" if mkt_cap > 1000000000000 else f"{mkt_cap/100000000:.0f}ì–µ" if mkt_cap else "-"
                    rev_growth = info.get('revenueGrowth', 0)
                    rev_str = f"{rev_growth*100:.1f}%" if rev_growth else "-"
                    eps_growth = info.get('earningsGrowth', 0)
                    eps_growth_str = f"{eps_growth*100:.1f}%" if eps_growth else "-"
                    fwd_eps = info.get('forwardEps', '-')
                    peg = info.get('pegRatio', '-')
                    try:
                        trend_data = tick.eps_trend
                        if trend_data:
                            curr_year_data = trend_data[0] 
                            curr_est = curr_year_data.get('current', 0)
                            ago30 = curr_year_data.get('30daysAgo', 0)
                            ago90 = curr_year_data.get('90daysAgo', 0)
                            trend_30 = "â†—ï¸" if curr_est > ago30 else "â†˜ï¸" if curr_est < ago30 else "-"
                            trend_90 = "â†—ï¸" if curr_est > ago90 else "â†˜ï¸" if curr_est < ago90 else "-"
                            eps_trend_str = f"30ì¼{trend_30} | 90ì¼{trend_90}"
                        else: eps_trend_str = "-"
                    except: eps_trend_str = "-"
                    rec = info.get('recommendationKey', '-').upper().replace('_', ' ')
                    target = info.get('targetMeanPrice')
                    curr_p = info.get('currentPrice', 0)
                    upside = f"{(target - curr_p) / curr_p * 100:.1f}%" if (target and curr_p) else "-"
                    
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(real_ticker)
                    
                    f_res.append({
                        "ì¢…ëª©": real_ticker, "ì„¹í„°": info.get('sector', '-'), "ì‚°ì—…": info.get('industry', '-'),
                        "ì‹œê°€ì´ì•¡": mkt_cap_str, "ë§¤ì¶œì„±ì¥(YoY)": rev_str, "EPSì„±ì¥(YoY)": eps_growth_str,
                        "ì„ í–‰EPS": fwd_eps, "PEG": peg, "EPSì¶”ì„¸(ì˜¬í•´)": eps_trend_str,
                        "1Wë³€í™”": eps1w, "1Më³€í™”": eps1m, "3Më³€í™”": eps3m,
                        "íˆ¬ìì˜ê²¬": rec, "ìƒìŠ¹ì—¬ë ¥": upside
                    })
                except Exception as e: continue
            bar.empty()
            if f_res:
                df_fin = pd.DataFrame(f_res)
                st.success(f"âœ… ì´ {len(df_fin)}ê°œ ê¸°ì—… ì¬ë¬´/EPS ë¶„ì„ ì™„ë£Œ")
                st.dataframe(df_fin, use_container_width=True)
            else: st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ==============================================================================
# [NEW] 4. ì—‘ì…€ ë°ì´í„° ë§¤ì¹­ íƒ­ (DB ì €ì¥ & ì´ˆê¸°í™” & í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš©)
# ==============================================================================
with tab4:
    st.markdown("### ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­ (í€€í‹°ì™€ì´ì¦ˆ DB ì—°ë™)")
    st.info("í€€í‹°ì™€ì´ì¦ˆ ì—‘ì…€(quant_master.xlsx)ì„ ì—…ë¡œë“œí•˜ì—¬ Supabase DBì— ì €ì¥í•©ë‹ˆë‹¤.\n\n"
            "**[ì£¼ì˜ì‚¬í•­]**\n"
            "- Supabase DBì˜ `quant_data` í…Œì´ë¸” ì»¬ëŸ¼ì´ **TEXT** íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
            "**[í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš©]**\n"
            "- êµ¬ê¸€ ì‹œíŠ¸(TGT)ì— ìˆëŠ” ì¢…ëª©ë§Œ í•„í„°ë§í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n")
    
    col_upload, col_reset = st.columns([3, 1])
    
    with col_upload:
        uploaded_file = st.file_uploader("ğŸ“¥ quant_master.xlsx íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx'])
    
    # [DB ì´ˆê¸°í™” ë²„íŠ¼]
    with col_reset:
        st.write("") # ì¤„ë§ì¶¤
        st.write("") 
        if st.button("ğŸ—‘ï¸ [ì£¼ì˜] DB ì´ˆê¸°í™” (ì „ì²´ ì‚­ì œ)", type="primary"):
            try:
                # ëª¨ë“  ë°ì´í„° ì‚­ì œ (idê°€ 0ì´ ì•„ë‹Œ ëª¨ë“  í–‰)
                supabase.table("quant_data").delete().neq("id", 0).execute()
                st.success("DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                fetch_latest_quant_data_from_db.clear()
            except Exception as e:
                st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨ (Supabase ê¶Œí•œ í™•ì¸ í•„ìš”): {e}")

    # [ë””ë²„ê¹… ì˜µì…˜]
    show_debug_log = st.checkbox("ğŸ” ë””ë²„ê¹… ë¡œê·¸ ë³´ê¸° (ì™œ ì €ì¥ì´ ì•ˆ ë˜ëŠ”ì§€ í™•ì¸)")

    # --- ì„œë¸Œ í•¨ìˆ˜: ì—‘ì…€ ì‹œíŠ¸ íŒŒì‹± (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ ì¶”ê°€, ë¬¸ìì—´ ì²˜ë¦¬) ---
    def parse_sheet_ticker_value(sheet_df, allowed_tickers, debug_mode=False):
        extracted = {}
        for index, row in sheet_df.iterrows():
            try:
                raw_ticker = str(row[0]).strip()
                if not raw_ticker or raw_ticker.lower() in ['code', 'ticker', 'nan', 'item type', 'comparison date']:
                    continue
                
                # 1. ì •ê·œí™” (Quant -> DB Format)
                norm_ticker = normalize_ticker_for_db_storage(raw_ticker)
                
                # [ë””ë²„ê¹…] íŠ¹ì • í‹°ì»¤ê°€ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸
                if debug_mode and "RKLB" in norm_ticker:
                    st.write(f"ğŸ“¢ [DEBUG] ë°œê²¬ëœ í‹°ì»¤: {raw_ticker} -> ì •ê·œí™”: {norm_ticker} -> í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€: {norm_ticker in allowed_tickers}")

                # 2. [í•µì‹¬] í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
                if norm_ticker not in allowed_tickers:
                    continue

                # 3. [í•µì‹¬] ê°’ ê°€ì ¸ì˜¤ê¸° (ë¬¸ìì—´ ê·¸ëŒ€ë¡œ)
                val = row[3] # Dì—´
                if pd.isna(val):
                    final_val = "-"
                else:
                    final_val = str(val).strip()
                    # ë¬¸ìì—´ "nan" ë˜ëŠ” ë¹ˆ ê°’ ì²˜ë¦¬
                    if final_val.lower() == 'nan' or final_val == "":
                        final_val = "-"
                
                extracted[norm_ticker] = final_val
            except Exception:
                continue
        return extracted

    if uploaded_file and st.button("ğŸ”„ DB ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘"):
        try:
            # 0. êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê´€ë¦¬ ì¢…ëª©(Target) ê°€ì ¸ì˜¤ê¸°
            st.info("êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            tgt_stocks = get_tickers_from_sheet()
            tgt_etfs = [x[0] for x in get_etfs_from_sheet()]
            tgt_countries = [x[0] for x in get_country_etfs_from_sheet()]
            
            # ê´€ë¦¬ ì¢…ëª© í•©ì¹˜ê¸° ë° ì •ê·œí™”
            raw_targets = set(tgt_stocks + tgt_etfs + tgt_countries)
            allowed_db_tickers = set()
            for t in raw_targets:
                # êµ¬ê¸€ ì‹œíŠ¸ì— ìˆëŠ” í‹°ì»¤ë¥¼ DB ì €ì¥ í¬ë§·ìœ¼ë¡œ ë³€í™˜
                # ì˜ˆ: 005930.KS -> 005930, AAPL -> AAPL
                t_clean = t.split('.')[0] 
                t_clean = t_clean.split('-')[0]
                allowed_db_tickers.add(t_clean)
            
            st.success(f"ê´€ë¦¬ ëŒ€ìƒ ì¢…ëª© {len(allowed_db_tickers)}ê°œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

            if show_debug_log:
                if "RKLB" in allowed_db_tickers:
                    st.success("âœ… RKLBê°€ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("âŒ RKLBê°€ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤! êµ¬ê¸€ ì‹œíŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

            # 1. ì—‘ì…€ íŒŒì¼ ì½ê¸° (ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì½ê¸°)
            # [ì¤‘ìš”] dtype=str ì˜µì…˜ì„ ì¤˜ì„œ ì²˜ìŒë¶€í„° ë¬¸ìë¡œ ì½ì–´ë“¤ì„
            xls = pd.read_excel(uploaded_file, sheet_name=None, header=None, dtype=str)
            
            sheet_map = {'1w': None, '1m': None, '3m': None}
            for sheet_name in xls.keys():
                s_name = sheet_name.lower().strip()
                if '1w' in s_name: sheet_map['1w'] = xls[sheet_name]
                elif '1m' in s_name: sheet_map['1m'] = xls[sheet_name]
                elif '3m' in s_name: sheet_map['3m'] = xls[sheet_name]
            
            if not (sheet_map['1w'] is not None and sheet_map['1m'] is not None and sheet_map['3m'] is not None):
                st.error("ì—‘ì…€ íŒŒì¼ì— 1w, 1m, 3m ì‹œíŠ¸ê°€ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                # 2. íŒŒì‹± (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì „ë‹¬)
                data_1w = parse_sheet_ticker_value(sheet_map['1w'], allowed_db_tickers, show_debug_log)
                data_1m = parse_sheet_ticker_value(sheet_map['1m'], allowed_db_tickers, show_debug_log)
                data_3m = parse_sheet_ticker_value(sheet_map['3m'], allowed_db_tickers, show_debug_log)
                
                # 3. í†µí•©
                all_tickers = set(data_1w.keys()) | set(data_1m.keys()) | set(data_3m.keys())
                
                if not all_tickers:
                    st.warning("ì—‘ì…€ íŒŒì¼ì—ì„œ ê´€ë¦¬ ì¢…ëª©(TGT)ê³¼ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    # 4. DB ì¤‘ë³µ ì²´í¬ (ë¬¸ìì—´ ë¹„êµ)
                    today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')
                    existing_map = {}
                    try:
                        res = supabase.table("quant_data")\
                            .select("*")\
                            .gte("created_at", f"{today_str} 00:00:00")\
                            .lte("created_at", f"{today_str} 23:59:59")\
                            .execute()
                        if res.data:
                            for rec in res.data:
                                existing_map[rec['ticker']] = (
                                    str(rec.get('change_1w') or "-"),
                                    str(rec.get('change_1m') or "-"),
                                    str(rec.get('change_3m') or "-")
                                )
                    except:
                        pass
                    
                    rows_to_insert = []
                    skipped_count = 0
                    
                    for t in all_tickers:
                        v_1w = data_1w.get(t, "-")
                        v_1m = data_1m.get(t, "-")
                        v_3m = data_3m.get(t, "-")
                        
                        # ì¤‘ë³µ ì²´í¬ (ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ë¹„êµ)
                        if t in existing_map:
                            e_1w, e_1m, e_3m = existing_map[t]
                            if (e_1w == v_1w) and (e_1m == v_1m) and (e_3m == v_3m):
                                skipped_count += 1
                                continue
                        
                        rows_to_insert.append({
                            "ticker": t,
                            "change_1w": v_1w,
                            "change_1m": v_1m,
                            "change_3m": v_3m
                        })
                    
                    if rows_to_insert:
                        # 100ê°œì”© ë‚˜ëˆ ì„œ ì €ì¥
                        chunk_size = 100
                        for i in range(0, len(rows_to_insert), chunk_size):
                            chunk = rows_to_insert[i:i+chunk_size]
                            supabase.table("quant_data").insert(chunk).execute()
                        
                        st.success(f"âœ… DB ì—…ë¡œë“œ ì™„ë£Œ! (TGT í•„í„°ë§ ì ìš©ë¨. ì‹ ê·œ: {len(rows_to_insert)}ê±´, ì¤‘ë³µìƒëµ: {skipped_count}ê±´)")
                        
                        # ìºì‹œ ì´ˆê¸°í™”
                        fetch_latest_quant_data_from_db.clear()
                        GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()
                    else:
                        st.info(f"ë³€ë™ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. (ì¤‘ë³µ ìƒëµ: {skipped_count}ê±´)")
                
        except Exception as e:
            st.error(f"ì‘ì—… ì‹¤íŒ¨: {e}")

    st.markdown("---")
    st.markdown("#### ğŸ‘ï¸ í˜„ì¬ DB ì €ì¥ ë°ì´í„° (ì „ì²´ ì¡°íšŒ)")
    if st.button("ë°ì´í„° ì¡°íšŒí•˜ê¸°"):
        try:
            # id, created_at ì œì™¸í•˜ê³  í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            # limit ì œê±°í•˜ì—¬ ì „ì²´ ì¡°íšŒ
            response = supabase.table("quant_data")\
                .select("ticker, change_1w, change_1m, change_3m")\
                .order("created_at", desc=True)\
                .execute()
            
            if response.data:
                df_view = pd.DataFrame(response.data)
                # ì»¬ëŸ¼ ì´ë¦„ì´ ê·¸ëŒ€ë¡œ ë‚˜ì˜¤ì§€ë§Œ, ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ ëª…ì‹œì  ì„ íƒ ê°€ëŠ¥ (ì´ë¯¸ selectì—ì„œ ì§€ì •í–ˆìœ¼ë¯€ë¡œ ìƒëµ ê°€ëŠ¥)
                st.dataframe(df_view, use_container_width=True)
            else:
                st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")

st.markdown("---")
with st.expander("ğŸ—„ï¸ ì „ì²´ ì €ì¥ ê¸°ë¡ ë³´ê¸° / ê´€ë¦¬"):
    col_e1, col_e2 = st.columns([1, 1])
    with col_e1:
        if st.button("ğŸ”„ ê¸°ë¡ ìƒˆë¡œê³ ì¹¨"):
            try:
                response = supabase.table("history").select("*").order("created_at", desc=True).limit(50).execute()
                if response.data: st.dataframe(pd.DataFrame(response.data), use_container_width=True)
            except Exception as e: st.error(str(e))
    with col_e2:
        if st.button("ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ (ìµœì‹ ë³¸ë§Œ ìœ ì§€)"):
            remove_duplicates_from_db()
