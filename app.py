import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timezone
from supabase import create_client, Client
from scipy.signal import argrelextrema
import time
import re

# =========================================================
# [ì„¤ì •] Supabase ì—°ê²° ì •ë³´ (ë³´ì•ˆ ì ìš©)
# =========================================================
try:
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
except Exception as e:
    st.error(f"âš ï¸ Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì—ëŸ¬: {e})")
    st.stop()

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì • ë° DB ì—°ê²°
# ==========================================
st.set_page_config(page_title="Pro ì£¼ì‹ ê²€ìƒ‰ê¸°", layout="wide")
st.title("ğŸ“ˆ Pro ì£¼ì‹ ê²€ìƒ‰ê¸°: ì„¹í„°/êµ­ê°€/ê¸°ìˆ ì /í€€í‹°ì™€ì´ì¦ˆ DB í†µí•©")

@st.cache_resource
def init_supabase():
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception as e:
        return None

supabase = init_supabase()

# ==========================================
# 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •
# ==========================================
SHEET_ID = '1NVThO1z2HHF0TVXVRGmbVsSU_Svyjg8fxd7E90z2o8A'
STOCK_GID = '0' 
STOCK_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={STOCK_GID}'
ETF_GID = '2023286696'
ETF_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={ETF_GID}'
COUNTRY_GID = '1247750129'
COUNTRY_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={COUNTRY_GID}'

# ==========================================
# 3. ê³µí†µ í•¨ìˆ˜ ì •ì˜
# ==========================================

def get_tickers_from_sheet():
    try:
        df = pd.read_csv(STOCK_CSV_URL, header=None)
        tickers = sorted(list(set([str(x).strip() for x in df[0] if str(x).strip()])))
        return tickers
    except Exception as e:
        st.error(f"ì£¼ì‹ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_etfs_from_sheet():
    try:
        df = pd.read_csv(ETF_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_country_etfs_from_sheet():
    try:
        df = pd.read_csv(COUNTRY_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"êµ­ê°€ ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_unique_tickers_from_db():
    if not supabase: return []
    try:
        response = supabase.table("history").select("ticker").execute()
        if response.data:
            return list(set([row['ticker'] for row in response.data]))
        return []
    except Exception as e: return []

def remove_duplicates_from_db():
    if not supabase: return
    try:
        response = supabase.table("history").select("id, ticker, created_at").order("created_at", desc=True).execute()
        data = response.data
        if not data:
            st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        seen_tickers = set()
        ids_to_remove = []
        for row in data:
            ticker = row['ticker']
            if ticker in seen_tickers:
                ids_to_remove.append(row['id'])
            else:
                seen_tickers.add(ticker)
        
        if ids_to_remove:
            for pid in ids_to_remove:
                supabase.table("history").delete().eq("id", pid).execute()
            st.success(f"ğŸ§¹ History ì¤‘ë³µëœ {len(ids_to_remove)}ê°œ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("History: ì‚­ì œí•  ì¤‘ë³µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")

def smart_download(ticker, interval="1d", period="2y"):
    if ':' in ticker: ticker = ticker.split(':')[-1]
    ticker = ticker.replace('/', '-')
    candidates = [ticker]
    if ticker.isdigit() and len(ticker) == 6:
        candidates = [f"{ticker}.KS", f"{ticker}.KQ", ticker]
    
    for t in candidates:
        try:
            for _ in range(3):
                df = yf.download(t, period=period, interval=interval, progress=False, auto_adjust=False)
                if len(df) > 0:
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = df.columns.get_level_values(0)
                    return t, df
                time.sleep(0.3)
        except:
            continue
    return ticker, pd.DataFrame()

# [ì¤‘ìš”] ì¢…ëª© ì •ë³´ ìºì‹± (ì„¹í„° ì •ë³´ í‘œì‹œìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
@st.cache_data(ttl=3600*24) 
def get_ticker_info_safe(ticker):
    try:
        tick = yf.Ticker(ticker)
        for _ in range(3):
            try:
                meta = tick.info
                if meta: return meta
            except:
                time.sleep(0.5)
        return None
    except:
        return None

def get_stock_sector(ticker):
    meta = get_ticker_info_safe(ticker)
    if not meta: return "Unknown"
    
    quote_type = meta.get('quoteType', '').upper()
    if 'ETF' in quote_type or 'FUND' in quote_type:
        name = meta.get('shortName', '')
        if not name: name = meta.get('longName', 'ETF')
        return f"[ETF] {name}"
    
    sector = meta.get('sector', '')
    if not sector: sector = meta.get('industry', '')
    if not sector: sector = meta.get('shortName', '')
    
    translations = {
        'Technology': 'ê¸°ìˆ ', 'Healthcare': 'í—¬ìŠ¤ì¼€ì–´', 'Financial Services': 'ê¸ˆìœµ',
        'Consumer Cyclical': 'ì„ì˜ì†Œë¹„ì¬', 'Industrials': 'ì‚°ì—…ì¬', 'Basic Materials': 'ì†Œì¬',
        'Energy': 'ì—ë„ˆì§€', 'Utilities': 'ìœ í‹¸ë¦¬í‹°', 'Real Estate': 'ë¶€ë™ì‚°',
        'Communication Services': 'í†µì‹ ', 'Consumer Defensive': 'í•„ìˆ˜ì†Œë¹„ì¬',
        'Semiconductors': 'ë°˜ë„ì²´'
    }
    return translations.get(sector, sector)

def save_to_supabase(data_list, strategy_name):
    if not supabase:
        st.error("âš ï¸ DB ì—°ê²° ì‹¤íŒ¨")
        return

    rows_to_insert = []
    for item in data_list:
        rows_to_insert.append({
            "ticker": str(item['ì¢…ëª©ì½”ë“œ']),
            "sector": str(item.get('ì„¹í„°', '-')),
            "price": str(item['í˜„ì¬ê°€']).replace(',', ''),
            "strategy": strategy_name,
            "high_date": str(item.get('í˜„52ì£¼ì‹ ê³ ê°€ì¼', '')), 
            "bw": str(item.get('BW_Value', '')), 
            "macd_v": str(item.get('MACD_V_Value', ''))
        })
    
    try:
        supabase.table("history").insert(rows_to_insert).execute()
        st.toast(f"âœ… {len(rows_to_insert)}ê°œ ì¢…ëª© DB ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

# ==============================================================================
# [í•µì‹¬ ë¡œì§] ì •ê·œí™” ë° DB ì¡°íšŒ
# ==============================================================================
def normalize_ticker_for_db_storage(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith("-US"): return t_str[:-3].replace('.', '-')
    if t_str.endswith("-HK"): return t_str[:-3] + ".HK"
    if t_str.endswith("-JP"): return t_str[:-3] + ".T"
    if t_str.endswith("-KS"): return t_str[:-3]
    if t_str.endswith("-KQ"): return t_str[:-3]
    if '-' in t_str and not any(x in t_str for x in ['-US', '-HK', '-JP', '-KS', '-KQ']): return t_str.split('-')[0]
    return t_str

def normalize_ticker_for_app_lookup(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith(".KS"): return t_str[:-3]
    if t_str.endswith(".KQ"): return t_str[:-3]
    if '.' in t_str and not any(x in t_str for x in ['.HK', '.T', '.KS', '.KQ']): return t_str.replace('.', '-')
    return t_str

@st.cache_data(ttl=600) 
def fetch_latest_quant_data_from_db():
    if not supabase: return {}
    try:
        response = supabase.table("quant_data").select("*").order("created_at", desc=True).execute()
        if not response.data: return {}
        df = pd.DataFrame(response.data)
        if df.empty: return {}
        df_latest = df.drop_duplicates(subset='ticker', keep='first')
        result_dict = {}
        for _, row in df_latest.iterrows():
            result_dict[row['ticker']] = {
                '1w': str(row.get('change_1w') or "-"),
                '1m': str(row.get('change_1m') or "-"),
                '3m': str(row.get('change_3m') or "-")
            }
        return result_dict
    except Exception as e:
        return {}

GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()

def get_eps_changes_from_db(ticker):
    norm_ticker = normalize_ticker_for_app_lookup(ticker)
    if norm_ticker in GLOBAL_QUANT_DATA:
        d = GLOBAL_QUANT_DATA[norm_ticker]
        return d['1w'], d['1m'], d['3m']
    return "-", "-", "-"

# ==========================================
# 4. ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ (ì§€í‘œ ê³„ì‚° & íŒ¨í„´)
# ==========================================

def find_extrema(df, order=3):
    prices = df['Close'].values
    peaks_idx = argrelextrema(prices, np.greater, order=order)[0]
    troughs_idx = argrelextrema(prices, np.less, order=order)[0]
    return peaks_idx, troughs_idx

def calculate_macdv(df, short=12, long=26, signal=9):
    ema_fast = df['Close'].ewm(span=short, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=long, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = tr.ewm(span=long, adjust=False).mean()
    macd_v = (macd_line / (atr + 1e-9)) * 100
    macd_v_signal = macd_v.ewm(span=signal, adjust=False).mean()
    return macd_v, macd_v_signal

def calculate_common_indicators(df, is_weekly=False):
    if len(df) < 60: return None
    df = df.copy()
    period = 20 if is_weekly else 60
    
    df[f'EMA{period}'] = df['Close'].ewm(span=period, adjust=False).mean()
    df[f'STD{period}'] = df['Close'].rolling(window=period).std()
    df['BB_UP'] = df[f'EMA{period}'] + (2 * df[f'STD{period}'])
    df['BB_LO'] = df[f'EMA{period}'] - (2 * df[f'STD{period}'])
    df['BandWidth'] = (df['BB_UP'] - df['BB_LO']) / df[f'EMA{period}']
    
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD_Line'] = df['EMA12'] - df['EMA26']
    df['MACD_Signal'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()
    df['MACD_V'], df['MACD_V_Signal'] = calculate_macdv(df, 12, 26, 9)
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR14'] = tr.ewm(span=14, adjust=False).mean()
    return df

def calculate_daily_indicators(df):
    if len(df) < 260: return None
    df = df.copy()
    
    df['SMA50'] = df['Close'].rolling(window=50).mean()
    df['STD50'] = df['Close'].rolling(window=50).std()
    df['BB50_UP'] = df['SMA50'] + (2.0 * df['STD50'])
    df['BB50_LO'] = df['SMA50'] - (2.0 * df['STD50'])
    df['BW50'] = (df['BB50_UP'] - df['BB50_LO']) / df['SMA50']
    df['Donchian_High_50'] = df['High'].rolling(window=50).max().shift(1)
    
    df['Change'] = df['Close'].diff()
    df['Vol_Up'] = np.where(df['Change'] > 0, df['Volume'], 0)
    df['Vol_Down'] = np.where(df['Change'] < 0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(df['Change'] == 0, df['Volume'], 0)
    roll_up = df['Vol_Up'].rolling(window=50).sum()
    roll_down = df['Vol_Down'].rolling(window=50).sum()
    roll_flat = df['Vol_Flat'].rolling(window=50).sum()
    df['VR50'] = ((roll_up + roll_flat/2) / (roll_down + roll_flat/2 + 1e-9)) * 100
    
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['STD20'] = df['Close'].rolling(window=20).std()
    df['BB20_UP'] = df['SMA20'] + (2.0 * df['STD20'])
    df['BB20_LO'] = df['SMA20'] - (2.0 * df['STD20'])
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    df['TR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR20'] = df['TR'].rolling(window=20).mean()
    kc_mult = 1.5 
    df['KC20_UP'] = df['SMA20'] + (kc_mult * df['ATR20'])
    df['KC20_LO'] = df['SMA20'] - (kc_mult * df['ATR20'])
    df['TTM_Squeeze'] = (df['BB20_UP'] < df['KC20_UP']) & (df['BB20_LO'] > df['KC20_LO'])

    ema_fast = df['Close'].ewm(span=20, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=200, adjust=False).mean()
    df['MACD_Line_C'] = ema_fast - ema_slow
    df['MACD_Signal_C'] = df['MACD_Line_C'].ewm(span=20, adjust=False).mean()
    df['MACD_OSC_C'] = df['MACD_Line_C'] - df['MACD_Signal_C']
    
    df['ATR14'] = df['TR'].ewm(span=14, adjust=False).mean()
    df['MACD_V'], _ = calculate_macdv(df, 12, 26, 9)
    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()
    return df

# -----------------------------------------------------------------------------
# [VCP íŒ¨í„´] 60ì¼ ê¸°ì¤€, 20ì¼ êµ¬ê°„, ë³€ë™ì„± ì¶•ì†Œ í™•ì¸
# -----------------------------------------------------------------------------
def check_vcp_pattern(df):
    if len(df) < 250: return False, None
    df = calculate_daily_indicators(df) 
    if df is None: return False, None
    
    curr = df.iloc[-1]
    sma50 = df['Close'].rolling(50).mean().iloc[-1]
    sma150 = df['Close'].rolling(150).mean().iloc[-1]
    sma200 = df['Close'].rolling(200).mean().iloc[-1]
    
    # 1. ì¶”ì„¸
    cond1 = curr['Close'] > sma150 and curr['Close'] > sma200
    cond2 = sma150 > sma200
    cond3 = df['SMA50'].iloc[-1] > df['SMA50'].iloc[-20] 
    cond4 = sma50 > sma150
    low_52 = df['Low'].iloc[-252:].min()
    cond5 = curr['Close'] > low_52 * 1.25
    high_52 = df['High'].iloc[-252:].max()
    cond6 = curr['Close'] > high_52 * 0.75
    
    stage_1_pass = cond1 and cond2 and cond4 and cond5 and cond6
    if not stage_1_pass: return False, None 

    # 2. íŒŒë™ (60ì¼ ê¸°ì¤€, 20ì¼ì”© 3êµ¬ê°„)
    window = 60
    subset = df.iloc[-window:]
    p1 = subset.iloc[:20]    # 20ì¼
    p2 = subset.iloc[20:40]  # 20ì¼
    p3 = subset.iloc[40:]    # 20ì¼
    
    range1 = (p1['High'].max() - p1['Low'].min()) / p1['High'].max()
    range2 = (p2['High'].max() - p2['Low'].min()) / p2['High'].max()
    range3 = (p3['High'].max() - p3['Low'].min()) / p3['High'].max()
    
    contraction = (range3 < range2) or (range2 < range1) or (range3 < 0.12)
    if not contraction: return False, None

    # 3. ì…‹ì—… (ê±°ë˜ëŸ‰)
    last_vol_avg = p3['Volume'].mean()
    prev_vol_avg = p1['Volume'].mean()
    vol_dry_up = last_vol_avg < prev_vol_avg * 1.2 
    tight_area = range3 < 0.15 
    
    stage_3_pass = vol_dry_up and tight_area
    
    stop_loss = p3['Low'].min()
    risk = curr['Close'] - stop_loss
    target_price = curr['Close'] + (risk * 3) if risk > 0 else 0
    
    # 4. ëŒíŒŒ
    prior_days = p3.iloc[:-1] 
    if len(prior_days) > 0:
        pivot_point = prior_days['High'].max() 
    else:
        pivot_point = p3['High'].max() 

    vol_ma50 = df['Volume'].iloc[-51:-1].mean()
    breakout = (curr['Close'] > pivot_point) and (curr['Volume'] > vol_ma50 * 1.2)
    
    status = ""
    if stage_3_pass and not breakout:
        status = "3ë‹¨ê³„ (ìˆ˜ë ´ì¤‘)"
    elif stage_3_pass and breakout:
        status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
    else:
        if breakout and tight_area:
             status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
        else:
             return False, None

    return True, {
        'status': status,
        'stop_loss': stop_loss,
        'target_price': target_price,
        'squeeze': "ğŸ”¥" if df['TTM_Squeeze'].iloc[-1] else "-",
        'price': curr['Close'],
        'pivot': pivot_point # ì°¨íŠ¸ ê·¸ë¦¬ê¸°ìš© í”¼ë´‡ ë°˜í™˜
    }

# -----------------------------------------------------------------------------
# [NEW] ì¼ë´‰ -> ì£¼ë´‰ ë³€í™˜ í›„ MACD ìƒíƒœ ê³„ì‚° í•¨ìˆ˜
# -----------------------------------------------------------------------------
def get_weekly_macd_status(daily_df):
    try:
        # ì¼ë´‰ ë°ì´í„°ë¥¼ ì£¼ë´‰(ê¸ˆìš”ì¼ ê¸°ì¤€)ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
        df_w = daily_df.resample('W-FRI').agg({
            'Close': 'last', 'High': 'max', 'Low': 'min', 'Volume': 'sum'
        }).dropna()
        
        if len(df_w) < 26: return "-"

        # ì£¼ë´‰ MACD (12, 26, 9) ê³„ì‚°
        ema12 = df_w['Close'].ewm(span=12, adjust=False).mean()
        ema26 = df_w['Close'].ewm(span=26, adjust=False).mean()
        macd_line = ema12 - ema26
        signal_line = macd_line.ewm(span=9, adjust=False).mean()
        
        curr_macd = macd_line.iloc[-1]
        curr_sig = signal_line.iloc[-1]
        prev_macd = macd_line.iloc[-2]
        prev_sig = signal_line.iloc[-2]
        
        # ìƒíƒœ íŒë³„
        if curr_macd > curr_sig:
            # ì´ë²ˆì£¼ì— ë§‰ ê³¨ë“ í¬ë¡œìŠ¤ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
            if prev_macd <= prev_sig:
                return "âš¡GC (ë§¤ìˆ˜ì‹ í˜¸)"
            else:
                return "ğŸ”µ Buy (ìœ ì§€)"
        else:
            return "ğŸ”» Sell (ë§¤ë„)"
    except:
        return "-"

# -----------------------------------------------------------------------------
# [NEW] VCP ì°¨íŠ¸ ê·¸ë¦¬ê¸° í•¨ìˆ˜ (Plotly)
# -----------------------------------------------------------------------------
def plot_vcp_chart(df, ticker, info):
    # ìµœê·¼ 1ë…„ì¹˜ ë°ì´í„°ë§Œ í‘œì‹œ
    df_plot = df.iloc[-252:].copy()
    
    fig = go.Figure()

    # 1. ìº”ë“¤ ì°¨íŠ¸
    fig.add_trace(go.Candlestick(
        x=df_plot.index,
        open=df_plot['Open'], high=df_plot['High'],
        low=df_plot['Low'], close=df_plot['Close'],
        name='Price'
    ))

    # 2. ì´ë™í‰ê· ì„ 
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(50).mean(), line=dict(color='green', width=1), name='SMA 50'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(150).mean(), line=dict(color='blue', width=1), name='SMA 150'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(200).mean(), line=dict(color='red', width=1), name='SMA 200'))

    # 3. í”¼ë´‡ í¬ì¸íŠ¸ (ëŒíŒŒ ê¸°ì¤€) - ë¹¨ê°„ ì ì„ 
    fig.add_hline(y=info['pivot'], line_dash="dot", line_color="red", annotation_text="Pivot (Breakout)")

    # 4. ìŠ¤íƒ‘ë¡œìŠ¤ (ì†ì ˆ ë¼ì¸) - íŒŒë€ ì ì„ 
    fig.add_hline(y=info['stop_loss'], line_dash="dot", line_color="blue", annotation_text="Stop Loss")

    fig.update_layout(
        title=f"{ticker} - VCP Analysis Chart",
        xaxis_rangeslider_visible=False,
        height=600,
        template="plotly_dark" # ë‹¤í¬ ëª¨ë“œ
    )
    return fig

# ... (ë‚˜ë¨¸ì§€ ì²´í¬ í•¨ìˆ˜ë“¤: check_daily_condition ë“± ê¸°ì¡´ ìœ ì§€) ...
def check_daily_condition(df):
    if len(df) < 260: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    curr = df.iloc[-1]
    
    dc_cond = (df['Close'] > df['Donchian_High_50']).iloc[-3:].any()
    bb_cond = (df['Close'] > df['BB50_UP']).iloc[-3:].any()
    mandatory = dc_cond or bb_cond
    
    vr_cond = (df['VR50'].iloc[-3:] > 110).any()
    bw_cond = (df['BW50'].iloc[-51] > curr['BW50']) if len(df)>55 else False
    macd_cond = curr['MACD_OSC_C'] > 0
    optional_count = sum([vr_cond, bw_cond, macd_cond])
    
    if mandatory and (optional_count >= 2):
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any()
        win_52 = df.iloc[-252:]
        high_52_date = win_52['Close'].idxmax().strftime('%Y-%m-%d')
        prev_win = win_52[win_52.index < win_52['Close'].idxmax()]
        prev_date = prev_win['Close'].idxmax().strftime('%Y-%m-%d') if len(prev_win)>0 else "-"
        diff_days = (win_52['Close'].idxmax() - prev_win['Close'].idxmax()).days if len(prev_win)>0 else 0
        
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'high_date': high_52_date, 
            'prev_date': prev_date, 
            'diff_days': diff_days, 
            'bw_curr': curr['BW50'], 
            'macdv': curr['MACD_V'], 
            'squeeze': "ğŸ”¥TTM Squeeze" if squeeze_on else "-" 
        }
    return False, None

def check_weekly_condition(df):
    if len(df) < 60: return False, None
    df = calculate_common_indicators(df, is_weekly=True)
    if df is None: return False, None
    
    curr = df.iloc[-1]
    prev = df.iloc[-2]
    
    cond_bb = curr['Close'] > curr['BB_UP']
    cond_macd = (prev['MACD_Line'] <= prev['MACD_Signal']) and (curr['MACD_Line'] > curr['MACD_Signal'])
    
    if cond_bb or cond_macd:
        bw_past = df['BandWidth'].iloc[-21]
        bw_change = "ê°ì†Œ" if bw_past > curr['BandWidth'] else "ì¦ê°€"
        
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'bw_curr': curr['BandWidth'], 
            'bw_past': bw_past, 
            'bw_change': f"{bw_change} (BB/MACD)", 
            'macdv': curr['MACD_V']
        }
    return False, None

def check_monthly_condition(df):
    if len(df) < 12: return False, None
    ath_price = df['High'].max()
    curr_price = df['Close'].iloc[-1]
    if curr_price >= ath_price * 0.90:
        ath_idx = df['High'].idxmax()
        month_count = (df['Close'] >= ath_price * 0.90).sum()
        return True, {'price': curr_price, 'ath_price': ath_price, 'ath_date': ath_idx.strftime('%Y-%m'), 'month_count': month_count}
    return False, None

def analyze_momentum_strategy(target_list, type_name="ETF"):
    if not target_list: return pd.DataFrame()
    st.write(f"ğŸ“Š ì´ {len(target_list)}ê°œ {type_name} ë¶„ì„ ì¤‘...")
    results = []; pbar = st.progress(0)
    for i, (t, n) in enumerate(target_list):
        pbar.progress((i+1)/len(target_list))
        rt, df = smart_download(t, "1d", "2y")
        if len(df)<30: continue
        df = calculate_daily_indicators(df)
        if df is None: continue
        c = df['Close']; curr=c.iloc[-1]
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any() if 'TTM_Squeeze' in df.columns else False
        ema20=c.ewm(span=20).mean(); ema50=c.ewm(span=50).mean(); ema60=c.ewm(span=60).mean()
        ema100=c.ewm(span=100).mean(); ema200=c.ewm(span=200).mean()
        bb_up = df['BB50_UP']; dc_h = df['Donchian_High_50'] 
        macdv = df['MACD_V']; atr = df['ATR14'].iloc[-1]
        bb_bk = "O" if (c>bb_up).iloc[-3:].any() else "-"
        dc_bk = "O" if (c>dc_h).iloc[-3:].any() else "-"
        align = "â­ ì •ë°°ì—´" if (curr>ema20.iloc[-1] and curr>ema60.iloc[-1] and curr>ema100.iloc[-1] and curr>ema200.iloc[-1]) else "-"
        long_tr = "ğŸ“ˆ ìƒìŠ¹" if (ema60.iloc[-1]>ema100.iloc[-1]>ema200.iloc[-1]) else "-"
        
        # [ë³€ê²½] ì „ëµ 3: í‰ê·  ëª¨ë©˜í…€ (Smoothed)
        r12 = c.pct_change(252).iloc[-1] if len(c) > 252 else 0
        r6  = c.pct_change(126).iloc[-1] if len(c) > 126 else 0
        r3  = c.pct_change(63).iloc[-1] if len(c) > 63 else 0
        r1  = c.pct_change(21).iloc[-1] if len(c) > 21 else 0
        
        avg_long_term = (r12 + r6) / 2
        score = ((avg_long_term - r3) + r1) * 100
        
        if len(df) >= 252:
            win_52 = df.iloc[-252:]
            high_idx = win_52['Close'].idxmax()
            high_52_date = high_idx.strftime('%Y-%m-%d')
            prev_win = win_52[win_52.index < high_idx]
            if len(prev_win) > 0:
                prev_idx = prev_win['Close'].idxmax()
                prev_date = prev_idx.strftime('%Y-%m-%d')
                diff_days = (high_idx - prev_idx).days
            else:
                prev_date = "-"; diff_days = 0
        else:
            high_52_date = "-"; prev_date = "-"; diff_days = 0
        results.append({
            f"{type_name}": f"{rt} ({n})", 
            "ëª¨ë©˜í…€ì ìˆ˜": score, 
            "ìŠ¤í€´ì¦ˆ": "ğŸ”¥" if squeeze_on else "-", 
            "BB(50,2)ëŒíŒŒ": bb_bk, 
            "ëˆí‚¤ì–¸(50)ëŒíŒŒ": dc_bk, 
            "ì •ë°°ì—´": align, 
            "ì¥ê¸°ì¶”ì„¸": long_tr, 
            "MACD-V": f"{macdv.iloc[-1]:.2f}", 
            "ATR": f"{atr:.2f}",
            "í˜„52ì£¼ì‹ ê³ ê°€ì¼": high_52_date,
            "ì „52ì£¼ì‹ ê³ ê°€ì¼": prev_date,
            "ì°¨ì´ì¼": f"{diff_days}ì¼",
            "í˜„ì¬ê°€": curr
        })
    pbar.empty()
    if results:
        df_res = pd.DataFrame(results).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
        df_res['ëª¨ë©˜í…€ì ìˆ˜'] = df_res['ëª¨ë©˜í…€ì ìˆ˜'].apply(lambda x: f"{x:.2f}")
        df_res['í˜„ì¬ê°€'] = df_res['í˜„ì¬ê°€'].apply(lambda x: f"{x:,.2f}")
        return df_res
    return pd.DataFrame()

def check_cup_handle_pattern(df):
    if len(df) < 26: return False, None
    sub = df.iloc[-26:].copy()
    if len(sub) < 26: return False, None
    idx_A = sub['High'].idxmax(); val_A = sub.loc[idx_A, 'High']
    if idx_A == sub.index[-1]: return False, "Aê°€ ëì "
    after_A = sub.loc[idx_A:]
    if len(after_A) < 5: return False, "ê¸°ê°„ ì§§ìŒ"
    idx_B = after_A['Low'].idxmin(); val_B = after_A.loc[idx_B, 'Low']
    if val_B > val_A * 0.85: return False, "ê¹Šì´ ì–•ìŒ"
    after_B = sub.loc[idx_B:]
    if len(after_B) < 2: return False, "ë°˜ë“± ì§§ìŒ"
    idx_C = after_B['High'].idxmax(); val_C = after_B.loc[idx_C, 'High']
    if val_C < val_A * 0.85: return False, "íšŒë³µ ë¯¸ë‹¬"
    curr_close = df['Close'].iloc[-1]
    if curr_close < val_B: return False, "í•¸ë“¤ ë¶•ê´´"
    if curr_close < val_C * 0.80: return False, "í•¸ë“¤ ê¹ŠìŒ"
    return True, {"depth": f"{(1 - val_B/val_A)*100:.1f}%", "handle_weeks": f"{len(df.loc[idx_C:])}ì£¼", "pivot": f"{val_C:,.0f}"}

def check_inverse_hs_pattern(df):
    if len(df) < 60: return False, None
    window = 60; sub = df.iloc[-window:].copy()
    if len(sub) < 60: return False, None
    part1 = sub.iloc[:20]; part2 = sub.iloc[20:40]; part3 = sub.iloc[40:]
    min_L = part1['Low'].min(); min_H = part2['Low'].min(); min_R = part3['Low'].min()
    if not (min_H < min_L and min_H < min_R): return False, "ë¨¸ë¦¬ ë¯¸í˜•ì„±"
    max_R = part3['High'].max(); curr_close = df['Close'].iloc[-1]
    if curr_close < min_R * 1.05: return False, "ë°˜ë“± ì•½í•¨"
    vol_recent = part3['Volume'].mean(); vol_prev = part2['Volume'].mean()
    vol_ratio = vol_recent / vol_prev if vol_prev > 0 else 1.0
    return True, {"Neckline": f"{max_R:,.0f}", "Breakout": "Ready" if curr_close < max_R else "Yes", "Vol_Ratio": f"{vol_ratio:.1f}ë°°"}

# -----------------------------------------------------------------------------
# [NEW] ë‚˜ì¹¨íŒìš© ì „ëµ ë¶„ì„ í•¨ìˆ˜ (ìµœì í™”)
# -----------------------------------------------------------------------------
def get_compass_signal():
    # 1. ì„¤ì •
    OFFENSE = ["QQQ", "SPY", "EFA", "GLD", "EEM"]
    CASH = "BIL"
    ALL_TICKERS = list(set(OFFENSE + [CASH]))
    
    # 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœê·¼ 2ë…„ì¹˜ë§Œ)
    try:
        data = yf.download(ALL_TICKERS, period="2y", progress=False, auto_adjust=False)['Close']
        if data.empty: return None, "ë°ì´í„° ì—†ìŒ"
    except:
        return None, "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"

    # 3. ì›”ë´‰ ë¦¬ìƒ˜í”Œë§
    monthly_data = data.resample('ME').last()
    
    if len(monthly_data) < 13: return None, "ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 13ê°œì›” í•„ìš”)"

    # 4. ì§€í‘œ ê³„ì‚° (ë§ˆì§€ë§‰ ì‹œì  ê¸°ì¤€)
    # pct_changeëŠ” (í˜„ì¬ - ê³¼ê±°) / ê³¼ê±°
    m12 = monthly_data.pct_change(12).iloc[-1]
    m6  = monthly_data.pct_change(6).iloc[-1]
    m3  = monthly_data.pct_change(3).iloc[-1]
    m1  = monthly_data.pct_change(1).iloc[-1]

    # 5. ì „ëµ 3 (Smoothed) ìŠ¤ì½”ì–´ ê³„ì‚°
    # ê³µì‹: ((12M + 6M) / 2 - 3M) + 1M
    scores = {}
    for ticker in OFFENSE:
        if ticker not in m12.index: continue
        
        r12 = m12[ticker]
        r6  = m6[ticker]
        r3  = m3[ticker]
        r1  = m1[ticker]
        
        # NaN ì²´í¬
        if np.isnan(r12): continue
        
        avg_long = (r12 + r6) / 2
        score = (avg_long - r3) + r1
        scores[ticker] = {
            "Score": score * 100,
            "12M_Trend": r12 # ì ˆëŒ€ ëª¨ë©˜í…€ í™•ì¸ìš©
        }
    
    if not scores: return None, "ê³„ì‚° ë¶ˆê°€"

    # 6. ìˆœìœ„ ì‚°ì •
    df_scores = pd.DataFrame(scores).T
    df_scores = df_scores.sort_values("Score", ascending=False)
    
    best_ticker = df_scores.index[0]
    best_score = df_scores.iloc[0]['Score']
    best_trend = df_scores.iloc[0]['12M_Trend']
    
    # 7. í¬ì§€ì…˜ ê²°ì • (ì ˆëŒ€ ëª¨ë©˜í…€ í•„í„°)
    final_position = best_ticker if (best_score > 0 and best_trend > 0) else CASH
    
    return df_scores, final_position

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ í™”ë©´
# ==========================================

# [ë³€ê²½] íƒ­ ìˆœì„œ ë³€ê²½: ë‚˜ì¹¨íŒ(tab_compass)ì„ ë§¨ ì•ìœ¼ë¡œ
tab_compass, tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ§­ ë‚˜ì¹¨íŒ", "ğŸŒ ì„¹í„°", "ğŸ³ï¸ êµ­ê°€", "ğŸ“Š ê¸°ìˆ ì  ë¶„ì„", "ğŸ’° ì¬ë¬´ë¶„ì„", "ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­"])

# -----------------------------------------------------------------------------
# [íƒ­ 1] ë‚˜ì¹¨íŒ (ê°€ì¥ ì™¼ìª½ìœ¼ë¡œ ì´ë™)
# -----------------------------------------------------------------------------
with tab_compass:
    st.markdown("### ğŸ§­ íˆ¬ì ë‚˜ì¹¨íŒ (Smoothed Momentum Strategy)")
    st.markdown("""
    ì´ íƒ­ì€ **'ì „ëµ 3 (í‰ê·  ëª¨ë©˜í…€)'** ë¡œì§ì„ ê¸°ë°˜ìœ¼ë¡œ **í˜„ì¬ ì‹œì (Today)**ì—ì„œ ê°€ì¥ ë§¤ë ¥ì ì¸ ìì‚°ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.
    
    **ì „ëµ ë¡œì§:**
    1. **í›„ë³´êµ°:** QQQ(ë‚˜ìŠ¤ë‹¥), SPY(S&P500), EFA(ì„ ì§„êµ­), GLD(ê¸ˆ), EEM(ì‹ í¥êµ­)
    2. **ì ìˆ˜ ì‚°ì¶œ:** `((12ê°œì›”+6ê°œì›”)/2 - 3ê°œì›”) + 1ê°œì›”` ìˆ˜ìµë¥ 
    3. **ë°©ì–´ ê¸°ì œ:** 1ë“± ì¢…ëª©ì˜ 12ê°œì›” ìˆ˜ìµë¥ ì´ ë§ˆì´ë„ˆìŠ¤ë©´ **í˜„ê¸ˆ(BIL)** ë³´ìœ 
    """)
    
    if st.button("ğŸš€ ì§€ê¸ˆ ì–´ë””ì— íˆ¬ìí•´ì•¼ í• ê¹Œ? (ë¶„ì„ ì‹œì‘)", type="primary"):
        with st.spinner("ìµœê·¼ 2ë…„ì¹˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°©í–¥ì„ ì¡ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            df_result, position = get_compass_signal()
            
            if df_result is not None:
                col1, col2 = st.columns(2)
                with col1:
                    st.success(f"ğŸ¯ í˜„ì¬ ì¶”ì²œ í¬ì§€ì…˜: **{position}**")
                    if position == "BIL":
                        st.caption("ğŸš¨ ì‹œì¥ ìƒí™©ì´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜„ê¸ˆ(ì´ˆë‹¨ê¸°ì±„)ìœ¼ë¡œ ëŒ€í”¼í•˜ì„¸ìš”.")
                    else:
                        st.caption(f"ğŸš€ ìƒìŠ¹ ëª¨ë©˜í…€ì´ ê°€ì¥ ê°•í•œ **{position}**ì— ì˜¬ë¼íƒ€ì„¸ìš”!")
                
                with col2:
                    top_score = df_result.iloc[0]['Score']
                    st.metric("1ë“± ëª¨ë©˜í…€ ì ìˆ˜", f"{top_score:.2f}ì ")

                st.markdown("---")
                st.markdown("#### ğŸ“Š ìì‚°ë³„ ìƒì„¸ ìŠ¤ì½”ì–´ (ë†’ì€ ìˆœ)")
                
                df_display = df_result.copy()
                df_display['Score'] = df_display['Score'].apply(lambda x: f"{x:.2f}")
                df_display['12M_Trend'] = df_display['12M_Trend'].apply(lambda x: f"{x*100:.1f}%")
                df_display.columns = ["ëª¨ë©˜í…€ ì ìˆ˜", "12ê°œì›” ì¶”ì„¸(ì ˆëŒ€)"]
                
                st.dataframe(df_display, use_container_width=True)
                
                st.info("""
                **í•´ì„ ê°€ì´ë“œ:**
                * **ëª¨ë©˜í…€ ì ìˆ˜:** ë†’ì„ìˆ˜ë¡ ìƒìŠ¹ì„¸ê°€ ê²¬ê³ í•˜ê³  ìµœê·¼ ëˆŒë¦¼ëª©ì„ ì˜ ì†Œí™”í•œ ì¢…ëª©ì…ë‹ˆë‹¤.
                * **12ê°œì›” ì¶”ì„¸:** ì´ ê°’ì´ ë§ˆì´ë„ˆìŠ¤(-)ë¼ë©´, ì ìˆ˜ê°€ ì•„ë¬´ë¦¬ ë†’ì•„ë„ **í•˜ë½ì¥**ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í˜„ê¸ˆ(BIL)ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
                """)
            else:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {position}")

# -----------------------------------------------------------------------------
# [íƒ­ 2] ì„¹í„° (ë‘ ë²ˆì§¸ë¡œ ì´ë™)
# -----------------------------------------------------------------------------
with tab1:
    cols = st.columns(12) 
    if cols[0].button("ğŸŒ ì„¹í„°"):
        etfs = get_etfs_from_sheet()
        if not etfs: st.warning("ETF ëª©ë¡ ì—†ìŒ")
        else:
            st.info("ETF ì„¹í„° ë¶„ì„ ì¤‘ (ëª¨ë©˜í…€ ì „ëµ 3: Smoothed)...")
            res = analyze_momentum_strategy(etfs, "ETF")
            if not res.empty: st.dataframe(res, use_container_width=True)
            else: st.warning("ë°ì´í„° ë¶€ì¡±")

# -----------------------------------------------------------------------------
# [íƒ­ 3] êµ­ê°€ (ê¸°ì¡´ ìœ„ì¹˜ ìœ ì§€)
# -----------------------------------------------------------------------------
with tab2:
    cols = st.columns(12)
    if cols[0].button("ğŸ³ï¸ êµ­ê°€"):
        tickers = get_country_etfs_from_sheet()
        if not tickers: st.warning("êµ­ê°€ ETF ëª©ë¡ ì—†ìŒ")
        else:
            st.info(f"[êµ­ê°€ ETF] {len(tickers)}ê°œ ëª¨ë©˜í…€(ì „ëµ 3) ë¶„ì„ ì‹œì‘...")
            res = analyze_momentum_strategy(tickers, "êµ­ê°€ETF")
            if not res.empty:
                st.success(f"[êµ­ê°€] {len(res)}ê°œ ë¶„ì„ ì™„ë£Œ!")
                st.dataframe(res, use_container_width=True)
            else: st.warning("ë°ì´í„° ë¶€ì¡±")

# -----------------------------------------------------------------------------
# [íƒ­ 4] ê¸°ìˆ ì  ë¶„ì„ (VCP í¬í•¨)
# -----------------------------------------------------------------------------
with tab3:
    cols = st.columns(12)
    
    # [NEW] VCP ë²„íŠ¼ (ì°¨íŠ¸ ê²€ì¦ + ì •ë ¬ ìˆ˜ì • + ê°œë³„ì£¼ í•„í„°ë§ ì‚­ì œ + 2ì—´ ê·¸ë¦¬ë“œ ì°¨íŠ¸ + ì£¼ë´‰MACD)
    if cols[0].button("ğŸŒªï¸ VCP"):
        tickers = get_tickers_from_sheet()
        if not tickers: st.warning("ì¢…ëª© ë¦¬ìŠ¤íŠ¸(TGT) ì—†ìŒ")
        else:
            st.info(f"êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì´ **{len(tickers)}**ê°œ ì¢…ëª©ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            
            # ì§„í–‰ìƒí™© í‘œì‹œìš©
            status_text = st.empty()
            bar = st.progress(0)
            
            res = []
            chart_data_cache = {}
            
            # ì¹´ìš´í„° ë³€ìˆ˜
            count_total = len(tickers)
            
            for i, t in enumerate(tickers):
                status_text.text(f"â³ ì§„í–‰ ì¤‘... ({i+1}/{count_total}) - {t}")
                bar.progress((i+1)/len(tickers))
                
                # 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì¦‰ì‹œ ì‹œë„)
                # í‹°ì»¤ í´ë Œì§• (ê³µë°± ì œê±°)
                t_clean = t.strip()
                
                try:
                    # smart_downloadê°€ ë‚´ë¶€ì ìœ¼ë¡œ ticker, ticker.KS ë“± ì‹œë„í•¨
                    final_ticker, df = smart_download(t_clean, "1d", "2y")
                except:
                    continue

                if len(df) < 250: continue

                # 2. VCP íŒ¨í„´ ì²´í¬
                passed, info = check_vcp_pattern(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(final_ticker)
                    
                    # [NEW] ì£¼ë´‰ MACD ìƒíƒœ ê³„ì‚°
                    weekly_macd_status = get_weekly_macd_status(df)
                    
                    # ì„¹í„° ì •ë³´ (í‘œì‹œìš©ìœ¼ë¡œë§Œ ê°€ì ¸ì˜¤ê¸°)
                    sector = get_stock_sector(final_ticker)
                    
                    chart_data_cache[final_ticker] = {'df': df, 'info': info}
                    
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': final_ticker, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ë¹„ê³ ': info['status'], 
                        'ì£¼ë´‰MACD': weekly_macd_status, # [NEW] ì£¼ë´‰ MACD ì»¬ëŸ¼ ì¶”ê°€
                        'ì†ì ˆê°€': f"{info['stop_loss']:,.0f}", 
                        'ëª©í‘œê°€(3R)': f"{info['target_price']:,.0f}",
                        'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'Pivot': f"{info['pivot']:,.0f}" 
                    })
            bar.empty()
            status_text.empty() 
            
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ì´ {count_total}ê°œ ì „ì²´ ì¢…ëª©ì„ ê²€ì‚¬í–ˆìŠµë‹ˆë‹¤.")
            
            if res:
                # [ìˆ˜ì •] ë¹„ê³  ì—´ì„ ë‚´ë¦¼ì°¨ìˆœ(ascending=False)ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ 4ë‹¨ê³„ê°€ ìœ„ë¡œ ì˜¤ê²Œ í•¨
                df_res = pd.DataFrame(res).sort_values("ë¹„ê³ ", ascending=False)
                st.dataframe(df_res, use_container_width=True)
                
                # [NEW] 4ë‹¨ê³„ ëŒíŒŒ ì¢…ëª© ìë™ ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬ (2ì—´ ê·¸ë¦¬ë“œ)
                breakout_targets = [r for r in res if "4ë‹¨ê³„" in r['ë¹„ê³ ']]

                if breakout_targets:
                    st.markdown("---")
                    st.markdown("### ğŸš€ ëŒíŒŒ ì¢…ëª© ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬ (Step 4)")
                    
                    # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ ìƒì„±
                    for i in range(0, len(breakout_targets), 2):
                        c1, c2 = st.columns(2)
                        
                        # ì™¼ìª½ ì°¨íŠ¸
                        item1 = breakout_targets[i]
                        ticker1 = item1['ì¢…ëª©ì½”ë“œ']
                        if ticker1 in chart_data_cache:
                            cached1 = chart_data_cache[ticker1]
                            fig1 = plot_vcp_chart(cached1['df'], ticker1, cached1['info'])
                            c1.plotly_chart(fig1, use_container_width=True)
                            c1.caption(f"**{ticker1}** ({item1['ì„¹í„°']}) | {item1['ì£¼ë´‰MACD']} | Pivot: {item1['Pivot']}")

                        # ì˜¤ë¥¸ìª½ ì°¨íŠ¸ (í™€ìˆ˜ ê°œì¼ ê²½ìš° ì—ëŸ¬ ë°©ì§€)
                        if i + 1 < len(breakout_targets):
                            item2 = breakout_targets[i+1]
                            ticker2 = item2['ì¢…ëª©ì½”ë“œ']
                            if ticker2 in chart_data_cache:
                                cached2 = chart_data_cache[ticker2]
                                fig2 = plot_vcp_chart(cached2['df'], ticker2, cached2['info'])
                                c2.plotly_chart(fig2, use_container_width=True)
                                c2.caption(f"**{ticker2}** ({item2['ì„¹í„°']}) | {item2['ì£¼ë´‰MACD']} | Pivot: {item2['Pivot']}")
                
                save_to_supabase(res, "VCP_Pattern")
            else: st.warning("VCP ì¡°ê±´(ì¶”ì„¸+ìˆ˜ë ´)ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    if cols[1].button("ğŸš€ ì¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì¼ë´‰ 5-Factor] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1d", "2y")
                passed, info = check_daily_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14)': f"{info['atr']:,.0f}", 'ìŠ¤í€´ì¦ˆ': info['squeeze'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info['prev_date'],
                        'ì°¨ì´ì¼': f"{info['diff_days']}ì¼", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Daily_5Factor")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[2].button("ğŸ“… ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì£¼ë´‰] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                passed, info = check_weekly_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATR(14ì£¼)': f"{info['atr']:,.0f}", 'BWí˜„ì¬': f"{info['bw_curr']:.4f}",
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW(20ì£¼ì „)': f"{info['bw_past']:.4f}", 'BWë³€í™”': info['bw_change'],
                        'MACD-V': f"{info['macdv']:.2f}", 'BW_Value': f"{info['bw_curr']:.4f}", 'MACD_V_Value': f"{info['macdv']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Weekly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[3].button("ğŸ—“ï¸ ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info(f"[ì›”ë´‰] {len(tickers)}ê°œ ë¶„ì„ ì‹œì‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1mo", "max")
                passed, info = check_monthly_condition(df)
                if passed:
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    sector = get_stock_sector(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info['price']:,.0f}",
                        'ATHìµœê³ ê°€': f"{info['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info['ath_date'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info['month_count']}ê°œì›”",
                        'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['ath_date'], 'BW_Value': str(info['month_count']), 'MACD_V_Value': "0"
                    })
            bar.empty()
            if res:
                st.success(f"[ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res).drop(columns=['í˜„52ì£¼ì‹ ê³ ê°€ì¼', 'BW_Value', 'MACD_V_Value'], errors='ignore'))
                save_to_supabase(res, "Monthly_ATH")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[4].button("ì¼+ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰+ì›”ë´‰ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ATHë‹¬ì„±ì›”': info_m['ath_date'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': str(info_m['month_count']), 'MACD_V_Value': f"{info_d['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Daily_Monthly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[5].button("ì¼+ì£¼ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì¼ë´‰+ì£¼ë´‰ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰BWë³€í™”': info_w['bw_change'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_d['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì¼+ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Daily_Weekly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[6].button("ì£¼+ì›”ë´‰"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("ì£¼ë´‰+ì›”ë´‰ ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_w['price']:,.0f}",
                    'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰BWë³€í™”': info_w['bw_change'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'ATHë‹¬ì„±ì›”': info_m['ath_date'], 'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_m['ath_date'], 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"[ì£¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "Weekly_Monthly")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[7].button("âš¡ í†µí•©"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("í†µí•©(ì¼+ì£¼+ì›”) ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df_d = smart_download(t, "1d", "2y")
                pass_d, info_d = check_daily_condition(df_d)
                if not pass_d: continue
                _, df_w = smart_download(t, "1wk", "2y")
                pass_w, info_w = check_weekly_condition(df_w)
                if not pass_w: continue
                _, df_m = smart_download(t, "1mo", "max")
                pass_m, info_m = check_monthly_condition(df_m)
                if not pass_m: continue
                sector = get_stock_sector(rt)
                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                res.append({
                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",
                    'ATHìµœê³ ê°€': f"{info_m['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info_m['ath_date'],
                    'í•´ë‹¹ì›”ìˆ˜': f"{info_m['month_count']}ê°œì›”", 'ìŠ¤í€´ì¦ˆ': info_d['squeeze'],
                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],
                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}",
                    'ì£¼ë´‰BWë³€í™”': info_w['bw_change'], 'MACD-V': f"{info_w['macdv']:.2f}",
                    'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"
                })
            bar.empty()
            if res:
                st.success(f"âš¡ í†µí•© ë¶„ì„ ì™„ë£Œ! {len(res)}ê°œ ë°œê²¬")
                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))
                save_to_supabase(res, "Integrated_Triple")
            else: st.warning("3ê°€ì§€ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    if cols[8].button("ğŸ† ì»µí•¸ë“¤"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[ì»µí•¸ë“¤] ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                pass_c, info = check_cup_handle_pattern(df)
                if pass_c:
                    df = calculate_common_indicators(df, True)
                    if df is None: continue 
                    curr = df.iloc[-1]
                    sector = get_stock_sector(rt)
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                        'íŒ¨í„´ìƒì„¸': f"ê¹Šì´:{info['depth']}", 'ëŒíŒŒê°€ê²©': info['pivot'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW_Value': f"{curr['BandWidth']:.4f}", 'MACD_V_Value': f"{curr['MACD_V']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì»µí•¸ë“¤] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "CupHandle")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    if cols[9].button("ğŸ‘¤ ì—­H&S"):
        tickers = get_tickers_from_sheet()
        if tickers:
            st.info("[ì—­H&S] ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(tickers):
                bar.progress((i+1)/len(tickers))
                rt, df = smart_download(t, "1wk", "2y")
                pass_h, info = check_inverse_hs_pattern(df)
                if pass_h:
                    df = calculate_common_indicators(df, True)
                    if df is None: continue 
                    curr = df.iloc[-1]
                    sector = get_stock_sector(rt)
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                    res.append({
                        'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                        'ë„¥ë¼ì¸': info['Neckline'], 'ê±°ë˜ëŸ‰ê¸‰ì¦': info['Vol_Ratio'],
                        '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                        'BW_Value': f"{curr['BandWidth']:.4f}", 'MACD_V_Value': f"{curr['MACD_V']:.2f}"
                    })
            bar.empty()
            if res:
                st.success(f"[ì—­H&S] {len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res))
                save_to_supabase(res, "InverseHS")
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

    st.markdown("### ğŸ“‰ ì €ì¥ëœ ì¢…ëª© ì¤‘ ëˆŒë¦¼ëª©/ê¸‰ë“±ì£¼ ì°¾ê¸°")
    if st.button("ğŸ” ëˆŒë¦¼ëª© & ê¸‰ë“± íŒ¨í„´ ë¶„ì„"):
        db_tickers = get_unique_tickers_from_db()
        if not db_tickers: st.warning("DB ë°ì´í„° ì—†ìŒ")
        else:
            st.info(f"{len(db_tickers)}ê°œ ì¢…ëª© ì¬ë¶„ì„ ì¤‘...")
            bar = st.progress(0); res = []
            for i, t in enumerate(db_tickers):
                bar.progress((i+1)/len(db_tickers))
                rt, df = smart_download(t, "1d", "2y")
                try:
                    df = calculate_common_indicators(df, False)
                    if df is None: continue
                    curr = df.iloc[-1]
                    cond = ""
                    if curr['MACD_V'] > 60: cond = "ğŸ”¥ ê³µê²©ì  ì¶”ì„¸"
                    ema20 = df['Close'].ewm(span=20).mean().iloc[-1]
                    if (curr['Close'] > ema20) and ((curr['Close']-ema20)/ema20 < 0.03): cond = "ğŸ“‰ 20ì¼ì„  ëˆŒë¦¼ëª©"
                    if (curr['Close'] > curr['EMA200']) and (-100 <= curr['MACD_V'] <= -50): cond = "ğŸ§² MACD-V ê³¼ë§¤ë„"
                    if cond:
                        eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)
                        res.append({
                            'ì¢…ëª©ì½”ë“œ': rt, 'íŒ¨í„´': cond, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",
                            '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,
                            'MACD-V': f"{curr['MACD_V']:.2f}", 'EMA20': f"{ema20:,.0f}"
                        })
                except: continue
            bar.empty()
            if res:
                st.success(f"{len(res)}ê°œ ë°œê²¬!")
                st.dataframe(pd.DataFrame(res), use_container_width=True)
            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")

with tab4:
    st.markdown("### ğŸ’° ì¬ë¬´ ì§€í‘œ ë¶„ì„ & EPS Trend (yfinance)")
    if st.button("ğŸ“Š ì¬ë¬´ ì§€í‘œ ê°€ì ¸ì˜¤ê¸°"):
        tickers = get_tickers_from_sheet()
        if not tickers: st.error("í‹°ì»¤ ì—†ìŒ")
        else:
            bar = st.progress(0); f_res = []
            for i, t in enumerate(tickers):
                bar.progress((i + 1) / len(tickers))
                real_ticker, _ = smart_download(t, "1d", "5d") 
                try:
                    tick = yf.Ticker(real_ticker)
                    info = tick.info
                    if not info: continue
                    mkt_cap = info.get('marketCap', 0)
                    mkt_cap_str = f"{mkt_cap/1000000000000:.1f}ì¡°" if mkt_cap > 1000000000000 else f"{mkt_cap/100000000:.0f}ì–µ" if mkt_cap else "-"
                    rev_growth = info.get('revenueGrowth', 0)
                    rev_str = f"{rev_growth*100:.1f}%" if rev_growth else "-"
                    eps_growth = info.get('earningsGrowth', 0)
                    eps_growth_str = f"{eps_growth*100:.1f}%" if eps_growth else "-"
                    fwd_eps = info.get('forwardEps', '-')
                    peg = info.get('pegRatio', '-')
                    try:
                        trend_data = tick.eps_trend
                        if trend_data:
                            curr_year_data = trend_data[0] 
                            curr_est = curr_year_data.get('current', 0)
                            ago30 = curr_year_data.get('30daysAgo', 0)
                            ago90 = curr_year_data.get('90daysAgo', 0)
                            trend_30 = "â†—ï¸" if curr_est > ago30 else "â†˜ï¸" if curr_est < ago30 else "-"
                            trend_90 = "â†—ï¸" if curr_est > ago90 else "â†˜ï¸" if curr_est < ago90 else "-"
                            eps_trend_str = f"30ì¼{trend_30} | 90ì¼{trend_90}"
                        else: eps_trend_str = "-"
                    except: eps_trend_str = "-"
                    rec = info.get('recommendationKey', '-').upper().replace('_', ' ')
                    target = info.get('targetMeanPrice')
                    curr_p = info.get('currentPrice', 0)
                    upside = f"{(target - curr_p) / curr_p * 100:.1f}%" if (target and curr_p) else "-"
                    eps1w, eps1m, eps3m = get_eps_changes_from_db(real_ticker)
                    f_res.append({
                        "ì¢…ëª©": real_ticker, "ì„¹í„°": info.get('sector', '-'), "ì‚°ì—…": info.get('industry', '-'),
                        "ì‹œê°€ì´ì•¡": mkt_cap_str, "ë§¤ì¶œì„±ì¥(YoY)": rev_str, "EPSì„±ì¥(YoY)": eps_growth_str,
                        "ì„ í–‰EPS": fwd_eps, "PEG": peg, "EPSì¶”ì„¸(ì˜¬í•´)": eps_trend_str,
                        "1Wë³€í™”": eps1w, "1Më³€í™”": eps1m, "3Më³€í™”": eps3m,
                        "íˆ¬ìì˜ê²¬": rec, "ìƒìŠ¹ì—¬ë ¥": upside
                    })
                except Exception as e: continue
            bar.empty()
            if f_res:
                df_fin = pd.DataFrame(f_res)
                st.success(f"âœ… ì´ {len(df_fin)}ê°œ ê¸°ì—… ì¬ë¬´/EPS ë¶„ì„ ì™„ë£Œ")
                st.dataframe(df_fin, use_container_width=True)
            else: st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

with tab5:
    st.markdown("### ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­ (í€€í‹°ì™€ì´ì¦ˆ DB ì—°ë™)")
    col_upload, col_reset = st.columns([3, 1])
    with col_upload:
        uploaded_file = st.file_uploader("ğŸ“¥ quant_master.xlsx íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx'])
    with col_reset:
        st.write("") 
        st.write("") 
        if st.button("ğŸ—‘ï¸ [ì£¼ì˜] DB ì´ˆê¸°í™” (ì „ì²´ ì‚­ì œ)", type="primary"):
            try:
                supabase.table("quant_data").delete().neq("id", 0).execute()
                st.success("DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                fetch_latest_quant_data_from_db.clear()
            except Exception as e:
                st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    show_debug_log = st.checkbox("ğŸ” ë””ë²„ê¹… ë¡œê·¸ ë³´ê¸°")

    def parse_sheet_ticker_value(sheet_df, allowed_tickers, debug_mode=False):
        extracted = {}
        for index, row in sheet_df.iterrows():
            try:
                raw_ticker = str(row[0]).strip()
                if not raw_ticker or raw_ticker.lower() in ['code', 'ticker', 'nan', 'item type', 'comparison date']: continue
                norm_ticker = normalize_ticker_for_db_storage(raw_ticker)
                if debug_mode and "RKLB" in norm_ticker: st.write(f"ğŸ“¢ [DEBUG] ë°œê²¬ëœ í‹°ì»¤: {raw_ticker} -> ì •ê·œí™”: {norm_ticker}")
                if norm_ticker not in allowed_tickers: continue
                val = row[3] 
                if pd.isna(val): final_val = "-"
                else:
                    final_val = str(val).strip()
                    if final_val.lower() == 'nan' or final_val == "": final_val = "-"
                extracted[norm_ticker] = final_val
            except Exception: continue
        return extracted

    if uploaded_file and st.button("ğŸ”„ DB ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘"):
        try:
            st.info("êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            tgt_stocks = get_tickers_from_sheet()
            tgt_etfs = [x[0] for x in get_etfs_from_sheet()]
            tgt_countries = [x[0] for x in get_country_etfs_from_sheet()]
            raw_targets = set(tgt_stocks + tgt_etfs + tgt_countries)
            allowed_db_tickers = set()
            for t in raw_targets:
                t_clean = t.split('.')[0] 
                t_clean = t_clean.split('-')[0]
                allowed_db_tickers.add(t_clean)
            
            st.success(f"ê´€ë¦¬ ëŒ€ìƒ ì¢…ëª© {len(allowed_db_tickers)}ê°œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            xls = pd.read_excel(uploaded_file, sheet_name=None, header=None, dtype=str)
            sheet_map = {'1w': None, '1m': None, '3m': None}
            for sheet_name in xls.keys():
                s_name = sheet_name.lower().strip()
                if '1w' in s_name: sheet_map['1w'] = xls[sheet_name]
                elif '1m' in s_name: sheet_map['1m'] = xls[sheet_name]
                elif '3m' in s_name: sheet_map['3m'] = xls[sheet_name]
            
            if not (sheet_map['1w'] is not None and sheet_map['1m'] is not None and sheet_map['3m'] is not None):
                st.error("ì—‘ì…€ íŒŒì¼ì— 1w, 1m, 3m ì‹œíŠ¸ê°€ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                data_1w = parse_sheet_ticker_value(sheet_map['1w'], allowed_db_tickers, show_debug_log)
                data_1m = parse_sheet_ticker_value(sheet_map['1m'], allowed_db_tickers, show_debug_log)
                data_3m = parse_sheet_ticker_value(sheet_map['3m'], allowed_db_tickers, show_debug_log)
                all_tickers = set(data_1w.keys()) | set(data_1m.keys()) | set(data_3m.keys())
                
                if not all_tickers: st.warning("ë§¤ì¹­ë˜ëŠ” ë°ì´í„° ì—†ìŒ")
                else:
                    today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')
                    existing_map = {}
                    try:
                        res = supabase.table("quant_data").select("*").gte("created_at", f"{today_str} 00:00:00").lte("created_at", f"{today_str} 23:59:59").execute()
                        if res.data:
                            for rec in res.data:
                                existing_map[rec['ticker']] = (str(rec.get('change_1w') or "-"), str(rec.get('change_1m') or "-"), str(rec.get('change_3m') or "-"))
                    except: pass
                    
                    rows_to_insert = []
                    skipped_count = 0
                    for t in all_tickers:
                        v_1w = data_1w.get(t, "-"); v_1m = data_1m.get(t, "-"); v_3m = data_3m.get(t, "-")
                        if t in existing_map:
                            e_1w, e_1m, e_3m = existing_map[t]
                            if (e_1w == v_1w) and (e_1m == v_1m) and (e_3m == v_3m):
                                skipped_count += 1
                                continue
                        rows_to_insert.append({"ticker": t, "change_1w": v_1w, "change_1m": v_1m, "change_3m": v_3m})
                    
                    if rows_to_insert:
                        chunk_size = 100
                        for i in range(0, len(rows_to_insert), chunk_size):
                            chunk = rows_to_insert[i:i+chunk_size]
                            supabase.table("quant_data").insert(chunk).execute()
                        st.success(f"âœ… DB ì—…ë¡œë“œ ì™„ë£Œ! (ì‹ ê·œ: {len(rows_to_insert)}ê±´, ì¤‘ë³µìƒëµ: {skipped_count}ê±´)")
                        fetch_latest_quant_data_from_db.clear()
                        GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()
                    else: st.info(f"ë³€ë™ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. (ì¤‘ë³µ ìƒëµ: {skipped_count}ê±´)")
        except Exception as e: st.error(f"ì‘ì—… ì‹¤íŒ¨: {e}")

    st.markdown("---")
    if st.button("ë°ì´í„° ì¡°íšŒí•˜ê¸°"):
        try:
            response = supabase.table("quant_data").select("ticker, change_1w, change_1m, change_3m").order("created_at", desc=True).execute()
            if response.data: st.dataframe(pd.DataFrame(response.data), use_container_width=True)
            else: st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e: st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")

st.markdown("---")
with st.expander("ğŸ—„ï¸ ì „ì²´ ì €ì¥ ê¸°ë¡ ë³´ê¸° / ê´€ë¦¬"):
    col_e1, col_e2 = st.columns([1, 1])
    with col_e1:
        if st.button("ğŸ”„ ê¸°ë¡ ìƒˆë¡œê³ ì¹¨"):
            try:
                response = supabase.table("history").select("*").order("created_at", desc=True).limit(50).execute()
                if response.data: st.dataframe(pd.DataFrame(response.data), use_container_width=True)
            except Exception as e: st.error(str(e))
    with col_e2:
        if st.button("ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ (ìµœì‹ ë³¸ë§Œ ìœ ì§€)"):
            remove_duplicates_from_db()
