import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timezone
from supabase import create_client, Client
from scipy.signal import argrelextrema
import time
import concurrent.futures # [ì¶”ê°€] ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ

# =========================================================
# [ì„¤ì •] Supabase ì—°ê²° ì •ë³´ (ë³´ì•ˆ ì ìš©)
# =========================================================
try:
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
except Exception as e:
    st.error(f"âš ï¸ Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì—ëŸ¬: {e})")
    st.stop()

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì • ë° DB ì—°ê²°
# ==========================================
st.set_page_config(page_title="Pro ì£¼ì‹ ê²€ìƒ‰ê¸°", layout="wide")
st.title("ğŸ“ˆ Pro ì£¼ì‹ ê²€ìƒ‰ê¸°: ì„¹í„°/êµ­ê°€/ê¸°ìˆ ì /í€€í‹°ì™€ì´ì¦ˆ DB í†µí•©")

@st.cache_resource
def init_supabase():
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception as e:
        return None

supabase = init_supabase()

# ==========================================
# 2. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„¤ì •
# ==========================================
SHEET_ID = '1NVThO1z2HHF0TVXVRGmbVsSU_Svyjg8fxd7E90z2o8A'
STOCK_GID = '0' 
STOCK_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={STOCK_GID}'
ETF_GID = '2023286696'
ETF_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={ETF_GID}'
COUNTRY_GID = '1247750129'
COUNTRY_CSV_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={COUNTRY_GID}'

# ==========================================
# 3. ê³µí†µ í•¨ìˆ˜ ì •ì˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ==========================================

def get_tickers_from_sheet():
    try:
        df = pd.read_csv(STOCK_CSV_URL, header=None)
        tickers = sorted(list(set([str(x).strip() for x in df[0] if str(x).strip()])))
        return tickers
    except Exception as e:
        st.error(f"ì£¼ì‹ ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_etfs_from_sheet():
    try:
        df = pd.read_csv(ETF_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_country_etfs_from_sheet():
    try:
        df = pd.read_csv(COUNTRY_CSV_URL, header=None)
        etf_list = []
        for index, row in df.iterrows():
            raw_ticker = str(row[0]).strip()
            if not raw_ticker or raw_ticker.lower() in ['ticker', 'symbol', 'ì¢…ëª©ì½”ë“œ', 'í‹°ì»¤', 'nan']:
                continue
            if ':' in raw_ticker:
                ticker = raw_ticker.split(':')[-1].strip()
            else:
                ticker = raw_ticker
            name = str(row[1]).strip() if len(row) > 1 else ticker
            if ticker:
                etf_list.append((ticker, name))
        return etf_list
    except Exception as e:
        st.error(f"êµ­ê°€ ETF ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_unique_tickers_from_db():
    if not supabase: return []
    try:
        response = supabase.table("history").select("ticker").execute()
        if response.data:
            return list(set([row['ticker'] for row in response.data]))
        return []
    except Exception as e: return []

def remove_duplicates_from_db():
    if not supabase: return
    try:
        response = supabase.table("history").select("id, ticker, created_at").order("created_at", desc=True).execute()
        data = response.data
        if not data:
            st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        seen_tickers = set()
        ids_to_remove = []
        for row in data:
            ticker = row['ticker']
            if ticker in seen_tickers:
                ids_to_remove.append(row['id'])
            else:
                seen_tickers.add(ticker)
        
        if ids_to_remove:
            for pid in ids_to_remove:
                supabase.table("history").delete().eq("id", pid).execute()
            st.success(f"ğŸ§¹ History ì¤‘ë³µëœ {len(ids_to_remove)}ê°œ ë°ì´í„°ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("History: ì‚­ì œí•  ì¤‘ë³µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")

# [ìˆ˜ì •] ë³‘ë ¬ ì²˜ë¦¬ ì‹œ yfinance ìŠ¤ë ˆë“œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ threads=False ì˜µì…˜ ì¶”ê°€
def smart_download(ticker, interval="1d", period="2y"):
    if ':' in ticker: ticker = ticker.split(':')[-1]
    ticker = ticker.replace('/', '-')
    candidates = [ticker]
    if ticker.isdigit() and len(ticker) == 6:
        candidates = [f"{ticker}.KS", f"{ticker}.KQ", ticker]
    
    for t in candidates:
        try:
            for _ in range(3):
                # threads=False ì¶”ê°€ (ë³‘ë ¬ ì²˜ë¦¬ ì¶©ëŒ ë°©ì§€)
                df = yf.download(t, period=period, interval=interval, progress=False, auto_adjust=False, threads=False)
                if len(df) > 0:
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = df.columns.get_level_values(0)
                    return t, df
                time.sleep(0.3)
        except:
            continue
    return ticker, pd.DataFrame()

# [ì¤‘ìš”] ì¢…ëª© ì •ë³´ ìºì‹± (ì„¹í„° ì •ë³´ í‘œì‹œìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
@st.cache_data(ttl=3600*24) 
def get_ticker_info_safe(ticker):
    try:
        tick = yf.Ticker(ticker)
        for _ in range(3):
            try:
                meta = tick.info
                if meta: return meta
            except:
                time.sleep(0.5)
        return None
    except:
        return None

def get_stock_sector(ticker):
    meta = get_ticker_info_safe(ticker)
    if not meta: return "Unknown"
    
    quote_type = meta.get('quoteType', '').upper()
    if 'ETF' in quote_type or 'FUND' in quote_type:
        name = meta.get('shortName', '')
        if not name: name = meta.get('longName', 'ETF')
        return f"[ETF] {name}"
    
    sector = meta.get('sector', '')
    if not sector: sector = meta.get('industry', '')
    if not sector: sector = meta.get('shortName', '')
    
    translations = {
        'Technology': 'ê¸°ìˆ ', 'Healthcare': 'í—¬ìŠ¤ì¼€ì–´', 'Financial Services': 'ê¸ˆìœµ',
        'Consumer Cyclical': 'ì„ì˜ì†Œë¹„ì¬', 'Industrials': 'ì‚°ì—…ì¬', 'Basic Materials': 'ì†Œì¬',
        'Energy': 'ì—ë„ˆì§€', 'Utilities': 'ìœ í‹¸ë¦¬í‹°', 'Real Estate': 'ë¶€ë™ì‚°',
        'Communication Services': 'í†µì‹ ', 'Consumer Defensive': 'í•„ìˆ˜ì†Œë¹„ì¬',
        'Semiconductors': 'ë°˜ë„ì²´'
    }
    return translations.get(sector, sector)

def save_to_supabase(data_list, strategy_name):
    if not supabase:
        st.error("âš ï¸ DB ì—°ê²° ì‹¤íŒ¨")
        return

    rows_to_insert = []
    for item in data_list:
        rows_to_insert.append({
            "ticker": str(item['ì¢…ëª©ì½”ë“œ']),
            "sector": str(item.get('ì„¹í„°', '-')),
            "price": str(item['í˜„ì¬ê°€']).replace(',', ''),
            "strategy": strategy_name,
            "high_date": str(item.get('í˜„52ì£¼ì‹ ê³ ê°€ì¼', '')), 
            "bw": str(item.get('BW_Value', '')), 
            "macd_v": str(item.get('MACD_V_Value', ''))
        })
    
    try:
        supabase.table("history").insert(rows_to_insert).execute()
        st.toast(f"âœ… {len(rows_to_insert)}ê°œ ì¢…ëª© DB ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

# ==============================================================================
# [í•µì‹¬ ë¡œì§] ì •ê·œí™” ë° DB ì¡°íšŒ (ê¸°ì¡´ ìœ ì§€)
# ==============================================================================
def normalize_ticker_for_db_storage(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith("-US"): return t_str[:-3].replace('.', '-')
    if t_str.endswith("-HK"): return t_str[:-3] + ".HK"
    if t_str.endswith("-JP"): return t_str[:-3] + ".T"
    if t_str.endswith("-KS"): return t_str[:-3]
    if t_str.endswith("-KQ"): return t_str[:-3]
    if '-' in t_str and not any(x in t_str for x in ['-US', '-HK', '-JP', '-KS', '-KQ']): return t_str.split('-')[0]
    return t_str

def normalize_ticker_for_app_lookup(t):
    if not t: return ""
    t_str = str(t).upper().strip()
    if t_str.endswith(".KS"): return t_str[:-3]
    if t_str.endswith(".KQ"): return t_str[:-3]
    if '.' in t_str and not any(x in t_str for x in ['.HK', '.T', '.KS', '.KQ']): return t_str.replace('.', '-')
    return t_str

@st.cache_data(ttl=600) 
def fetch_latest_quant_data_from_db():
    if not supabase: return {}
    try:
        response = supabase.table("quant_data").select("*").order("created_at", desc=True).execute()
        if not response.data: return {}
        df = pd.DataFrame(response.data)
        if df.empty: return {}
        df_latest = df.drop_duplicates(subset='ticker', keep='first')
        result_dict = {}
        for _, row in df_latest.iterrows():
            result_dict[row['ticker']] = {
                '1w': str(row.get('change_1w') or "-"),
                '1m': str(row.get('change_1m') or "-"),
                '3m': str(row.get('change_3m') or "-")
            }
        return result_dict
    except Exception as e:
        return {}

GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()

def get_eps_changes_from_db(ticker):
    norm_ticker = normalize_ticker_for_app_lookup(ticker)
    if norm_ticker in GLOBAL_QUANT_DATA:
        d = GLOBAL_QUANT_DATA[norm_ticker]
        return d['1w'], d['1m'], d['3m']
    return "-", "-", "-"

# ==========================================
# 4. ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ (ì§€í‘œ ê³„ì‚° & íŒ¨í„´) - ê¸°ì¡´ ì½”ë“œ 100% ë™ì¼
# ==========================================

def calculate_macdv(df, short=12, long=26, signal=9):
    ema_fast = df['Close'].ewm(span=short, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=long, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = tr.ewm(span=long, adjust=False).mean()
    macd_v = (macd_line / (atr + 1e-9)) * 100
    macd_v_signal = macd_v.ewm(span=signal, adjust=False).mean()
    return macd_v, macd_v_signal

def calculate_common_indicators(df, is_weekly=False):
    if len(df) < 60: return None
    df = df.copy()
    period = 20 if is_weekly else 60
    
    df[f'EMA{period}'] = df['Close'].ewm(span=period, adjust=False).mean()
    df[f'STD{period}'] = df['Close'].rolling(window=period).std()
    df['BB_UP'] = df[f'EMA{period}'] + (2 * df[f'STD{period}'])
    df['BB_LO'] = df[f'EMA{period}'] - (2 * df[f'STD{period}'])
    df['BandWidth'] = (df['BB_UP'] - df['BB_LO']) / df[f'EMA{period}']
    
    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD_Line'] = df['EMA12'] - df['EMA26']
    df['MACD_Signal'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()
    df['MACD_V'], df['MACD_V_Signal'] = calculate_macdv(df, 12, 26, 9)
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR14'] = tr.ewm(span=14, adjust=False).mean()
    return df

def calculate_daily_indicators(df):
    if len(df) < 260: return None
    df = df.copy()
    
    df['SMA50'] = df['Close'].rolling(window=50).mean()
    df['STD50'] = df['Close'].rolling(window=50).std()
    df['BB50_UP'] = df['SMA50'] + (2.0 * df['STD50'])
    df['BB50_LO'] = df['SMA50'] - (2.0 * df['STD50'])
    df['BW50'] = (df['BB50_UP'] - df['BB50_LO']) / df['SMA50']
    df['Donchian_High_50'] = df['High'].rolling(window=50).max().shift(1)
    
    df['Change'] = df['Close'].diff()
    df['Vol_Up'] = np.where(df['Change'] > 0, df['Volume'], 0)
    df['Vol_Down'] = np.where(df['Change'] < 0, df['Volume'], 0)
    df['Vol_Flat'] = np.where(df['Change'] == 0, df['Volume'], 0)
    roll_up = df['Vol_Up'].rolling(window=50).sum()
    roll_down = df['Vol_Down'].rolling(window=50).sum()
    roll_flat = df['Vol_Flat'].rolling(window=50).sum()
    df['VR50'] = ((roll_up + roll_flat/2) / (roll_down + roll_flat/2 + 1e-9)) * 100
    
    df['SMA20'] = df['Close'].rolling(window=20).mean()
    df['STD20'] = df['Close'].rolling(window=20).std()
    df['BB20_UP'] = df['SMA20'] + (2.0 * df['STD20'])
    df['BB20_LO'] = df['SMA20'] - (2.0 * df['STD20'])
    
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    df['TR'] = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR20'] = df['TR'].rolling(window=20).mean()
    kc_mult = 1.5 
    df['KC20_UP'] = df['SMA20'] + (kc_mult * df['ATR20'])
    df['KC20_LO'] = df['SMA20'] - (kc_mult * df['ATR20'])
    df['TTM_Squeeze'] = (df['BB20_UP'] < df['KC20_UP']) & (df['BB20_LO'] > df['KC20_LO'])

    ema_fast = df['Close'].ewm(span=20, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=200, adjust=False).mean()
    df['MACD_Line_C'] = ema_fast - ema_slow
    df['MACD_Signal_C'] = df['MACD_Line_C'].ewm(span=20, adjust=False).mean()
    df['MACD_OSC_C'] = df['MACD_Line_C'] - df['MACD_Signal_C']
    
    df['ATR14'] = df['TR'].ewm(span=14, adjust=False).mean()
    df['MACD_V'], _ = calculate_macdv(df, 12, 26, 9)
    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()
    return df

# -----------------------------------------------------------------------------
# [VCP íŒ¨í„´] 
# -----------------------------------------------------------------------------
def check_vcp_pattern(df):
    if len(df) < 250: return False, None
    df = calculate_daily_indicators(df) 
    if df is None: return False, None
    
    curr = df.iloc[-1]
    sma50 = df['Close'].rolling(50).mean().iloc[-1]
    sma150 = df['Close'].rolling(150).mean().iloc[-1]
    sma200 = df['Close'].rolling(200).mean().iloc[-1]
    
    # 1. ì¶”ì„¸
    cond1 = curr['Close'] > sma150 and curr['Close'] > sma200
    cond2 = sma150 > sma200
    cond3 = df['SMA50'].iloc[-1] > df['SMA50'].iloc[-20] 
    cond4 = sma50 > sma150
    low_52 = df['Low'].iloc[-252:].min()
    cond5 = curr['Close'] > low_52 * 1.25
    high_52 = df['High'].iloc[-252:].max()
    cond6 = curr['Close'] > high_52 * 0.75
    
    stage_1_pass = cond1 and cond2 and cond4 and cond5 and cond6
    if not stage_1_pass: return False, None 

    # 2. íŒŒë™ (60ì¼ ê¸°ì¤€, 20ì¼ì”© 3êµ¬ê°„)
    window = 60
    subset = df.iloc[-window:]
    p1 = subset.iloc[:20]    # 20ì¼
    p2 = subset.iloc[20:40]  # 20ì¼
    p3 = subset.iloc[40:]    # 20ì¼
    
    range1 = (p1['High'].max() - p1['Low'].min()) / p1['High'].max()
    range2 = (p2['High'].max() - p2['Low'].min()) / p2['High'].max()
    range3 = (p3['High'].max() - p3['Low'].min()) / p3['High'].max()
    
    contraction = (range3 < range2) or (range2 < range1) or (range3 < 0.12)
    if not contraction: return False, None

    # 3. ì…‹ì—… (ê±°ë˜ëŸ‰)
    last_vol_avg = p3['Volume'].mean()
    prev_vol_avg = p1['Volume'].mean()
    vol_dry_up = last_vol_avg < prev_vol_avg * 1.2 
    tight_area = range3 < 0.15 
    
    stage_3_pass = vol_dry_up and tight_area
    
    stop_loss = p3['Low'].min()
    risk = curr['Close'] - stop_loss
    target_price = curr['Close'] + (risk * 3) if risk > 0 else 0
    
    # 4. ëŒíŒŒ
    prior_days = p3.iloc[:-1] 
    if len(prior_days) > 0:
        pivot_point = prior_days['High'].max() 
    else:
        pivot_point = p3['High'].max() 

    vol_ma50 = df['Volume'].iloc[-51:-1].mean()
    breakout = (curr['Close'] > pivot_point) and (curr['Volume'] > vol_ma50 * 1.2)
    
    status = ""
    if stage_3_pass and not breakout:
        status = "3ë‹¨ê³„ (ìˆ˜ë ´ì¤‘)"
    elif stage_3_pass and breakout:
        status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
    else:
        if breakout and tight_area:
             status = "4ë‹¨ê³„ (ëŒíŒŒ!ğŸš€)"
        else:
             return False, None

    return True, {
        'status': status,
        'stop_loss': stop_loss,
        'target_price': target_price,
        'squeeze': "ğŸ”¥" if df['TTM_Squeeze'].iloc[-1] else "-",
        'price': curr['Close'],
        'pivot': pivot_point # ì°¨íŠ¸ ê·¸ë¦¬ê¸°ìš© í”¼ë´‡ ë°˜í™˜
    }

def get_weekly_macd_status(daily_df):
    try:
        # ì¼ë´‰ ë°ì´í„°ë¥¼ ì£¼ë´‰(ê¸ˆìš”ì¼ ê¸°ì¤€)ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
        df_w = daily_df.resample('W-FRI').agg({
            'Close': 'last', 'High': 'max', 'Low': 'min', 'Volume': 'sum'
        }).dropna()
        
        if len(df_w) < 26: return "-"

        # ì£¼ë´‰ MACD (12, 26, 9) ê³„ì‚°
        ema12 = df_w['Close'].ewm(span=12, adjust=False).mean()
        ema26 = df_w['Close'].ewm(span=26, adjust=False).mean()
        macd_line = ema12 - ema26
        signal_line = macd_line.ewm(span=9, adjust=False).mean()
        
        curr_macd = macd_line.iloc[-1]
        curr_sig = signal_line.iloc[-1]
        prev_macd = macd_line.iloc[-2]
        prev_sig = signal_line.iloc[-2]
        
        # ìƒíƒœ íŒë³„
        if curr_macd > curr_sig:
            # ì´ë²ˆì£¼ì— ë§‰ ê³¨ë“ í¬ë¡œìŠ¤ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸
            if prev_macd <= prev_sig:
                return "âš¡GC (ë§¤ìˆ˜ì‹ í˜¸)"
            else:
                return "ğŸ”µ Buy (ìœ ì§€)"
        else:
            return "ğŸ”» Sell (ë§¤ë„)"
    except:
        return "-"

def plot_vcp_chart(df, ticker, info):
    # ìµœê·¼ 1ë…„ì¹˜ ë°ì´í„°ë§Œ í‘œì‹œ
    df_plot = df.iloc[-252:].copy()
    
    fig = go.Figure()

    # 1. ìº”ë“¤ ì°¨íŠ¸
    fig.add_trace(go.Candlestick(
        x=df_plot.index,
        open=df_plot['Open'], high=df_plot['High'],
        low=df_plot['Low'], close=df_plot['Close'],
        name='Price'
    ))

    # 2. ì´ë™í‰ê· ì„ 
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(50).mean(), line=dict(color='green', width=1), name='SMA 50'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(150).mean(), line=dict(color='blue', width=1), name='SMA 150'))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot['Close'].rolling(200).mean(), line=dict(color='red', width=1), name='SMA 200'))

    # 3. í”¼ë´‡ í¬ì¸íŠ¸ (ëŒíŒŒ ê¸°ì¤€) - ë¹¨ê°„ ì ì„ 
    fig.add_hline(y=info['pivot'], line_dash="dot", line_color="red", annotation_text="Pivot (Breakout)")

    # 4. ìŠ¤íƒ‘ë¡œìŠ¤ (ì†ì ˆ ë¼ì¸) - íŒŒë€ ì ì„ 
    fig.add_hline(y=info['stop_loss'], line_dash="dot", line_color="blue", annotation_text="Stop Loss")

    fig.update_layout(
        title=f"{ticker} - VCP Analysis Chart",
        xaxis_rangeslider_visible=False,
        height=600,
        template="plotly_dark" # ë‹¤í¬ ëª¨ë“œ
    )
    return fig

# ... (ë‚˜ë¨¸ì§€ ì²´í¬ í•¨ìˆ˜ë“¤: check_daily_condition ë“± ê¸°ì¡´ ìœ ì§€) ...
def check_daily_condition(df):
    if len(df) < 260: return False, None
    df = calculate_daily_indicators(df)
    if df is None: return False, None
    curr = df.iloc[-1]
    
    dc_cond = (df['Close'] > df['Donchian_High_50']).iloc[-3:].any()
    bb_cond = (df['Close'] > df['BB50_UP']).iloc[-3:].any()
    mandatory = dc_cond or bb_cond
    
    vr_cond = (df['VR50'].iloc[-3:] > 110).any()
    bw_cond = (df['BW50'].iloc[-51] > curr['BW50']) if len(df)>55 else False
    macd_cond = curr['MACD_OSC_C'] > 0
    optional_count = sum([vr_cond, bw_cond, macd_cond])
    
    if mandatory and (optional_count >= 2):
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any()
        win_52 = df.iloc[-252:]
        high_52_date = win_52['Close'].idxmax().strftime('%Y-%m-%d')
        prev_win = win_52[win_52.index < win_52['Close'].idxmax()]
        prev_date = prev_win['Close'].idxmax().strftime('%Y-%m-%d') if len(prev_win)>0 else "-"
        diff_days = (win_52['Close'].idxmax() - prev_win['Close'].idxmax()).days if len(prev_win)>0 else 0
        
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'high_date': high_52_date, 
            'prev_date': prev_date, 
            'diff_days': diff_days, 
            'bw_curr': curr['BW50'], 
            'macdv': curr['MACD_V'], 
            'squeeze': "ğŸ”¥TTM Squeeze" if squeeze_on else "-" 
        }
    return False, None

def check_weekly_condition(df):
    if len(df) < 40: return False, None
    
    # --- 1. ì§€í‘œ ê³„ì‚° ---
    # SMA 30 (ìƒëª…ì„ )
    df['SMA30'] = df['Close'].rolling(window=30).mean()
    
    # EMA 20 (ì¶”ì„¸ì„ )
    df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()
    
    # RSI 14
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / (loss + 1e-9)
    df['RSI14'] = 100 - (100 / (1 + rs))

    # [ì„ í–‰ì¡°ê±´ìš©] MACD (12, 26, 9)
    e12 = df['Close'].ewm(span=12, adjust=False).mean()
    e26 = df['Close'].ewm(span=26, adjust=False).mean()
    macd = e12 - e26
    sig = macd.ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = macd - sig

    # [ì¡°ê±´1ìš©] BB (12, 2)
    sma12 = df['Close'].rolling(12).mean()
    std12 = df['Close'].rolling(12).std()
    bb_up_12 = sma12 + (2 * std12)
    
    # [ì¡°ê±´2ìš©] MACD (12, 36, 9)
    e12_c = df['Close'].ewm(span=12, adjust=False).mean()
    e36_c = df['Close'].ewm(span=36, adjust=False).mean()
    macd_c = e12_c - e36_c
    sig_c = macd_c.ewm(span=9, adjust=False).mean()
    
    # MACD-V (ê²°ê³¼ í‘œì‹œìš©)
    df['MACD_V'], _ = calculate_macdv(df, 12, 26, 9)
    
    # ATR (ê²°ê³¼ í‘œì‹œìš©)
    high_low = df['High'] - df['Low']
    high_close = np.abs(df['High'] - df['Close'].shift())
    low_close = np.abs(df['Low'] - df['Close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['ATR14'] = tr.ewm(span=14, adjust=False).mean()

    curr = df.iloc[-1]
    
    # --- 2. í•„ìˆ˜ ì„ í–‰ ì¡°ê±´ (Trend Filter) ---
    # 1) 30ì£¼ ì´ë™í‰ê· ì„  ìœ„ (ì¥ê¸° ì¶”ì„¸)
    cond_basic_1 = curr['Close'] > curr['SMA30']
    
    # 2) RSI > 50 (ë§¤ìˆ˜ì„¸ ìš°ìœ„)
    cond_basic_2 = curr['RSI14'] > 50
    
    # 3) MACD ì˜¤ì‹¤ë ˆì´í„° ìƒíƒœ (ìƒìŠ¹ ì¤‘ì´ê±°ë‚˜ or ì´ë¯¸ ì–‘ìˆ˜ê¶Œì—ì„œ ë²„í‹°ê¸°)
    if len(df) < 2: return False, None
    cond_basic_3 = (df['MACD_Hist'].iloc[-1] > df['MACD_Hist'].iloc[-2]) or (df['MACD_Hist'].iloc[-1] > 0)

    if not (cond_basic_1 and cond_basic_2 and cond_basic_3):
        return False, None

    # --- 3. ì£¼ë´‰ì¡°ê±´ (1) : ëŒíŒŒìˆ˜ë ´ (Squat) - ì¡°ê±´ ì™„í™” (ê±°ë˜ëŸ‰ ì œí•œ ì‚­ì œ) ---
    is_strat_1 = False
    
    # ê³¼ê±° 12ì£¼ ë°ì´í„° (ì´ë²ˆì£¼ ì œì™¸)
    past_12w = df.iloc[-13:-1]
    
    if len(past_12w) > 0:
        # A. ê³¼ê±°ì˜ ì˜ê´‘: ì§€ë‚œ 12ì£¼ ì•ˆì— BB ìƒë‹¨ì„ ëŒíŒŒí•œ ì ì´ ìˆëŠ”ê°€?
        past_breakout = (past_12w['Close'] > bb_up_12.loc[past_12w.index]).any()
        
        # B. í˜„ì¬ì˜ íœ´ì‹: ì´ë²ˆ ì£¼ëŠ” ëŒíŒŒ ìƒíƒœê°€ ì•„ë‹˜ (ë°´ë“œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜´ or ë°´ë“œ ê·¼ì²˜)
        current_rest = curr['Close'] <= (bb_up_12.iloc[-1] * 1.02)
        
        if past_breakout and current_rest:
            # C. ê°€ê²© ì§€ì§€ (Price Support): 
            # ê³ ì  ëŒ€ë¹„ ë„ˆë¬´ ë§ì´ ë¹ ì§€ì§€ ì•Šì•˜ëŠ”ê°€? (ìµœê·¼ 12ì£¼ ê³ ê°€ì˜ 85% ì´ìƒ ê°€ê²© ìœ ì§€)
            recent_high = past_12w['High'].max()
            price_support = curr['Close'] >= (recent_high * 0.85)
            
            # D. ì¶”ì„¸ ì§€ì§€ (Trend Support):
            # í˜„ì¬ ì¢…ê°€ê°€ 20ì£¼ EMA ìœ„ì— ìˆëŠ”ê°€?
            ema_support = curr['Close'] > curr['EMA20']
            
            if price_support and ema_support:
                is_strat_1 = True

    # --- 4. ì£¼ë´‰ì¡°ê±´ (2) : MACD ë§¤ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
    is_strat_2 = False
    prev_macd_c = macd_c.iloc[-2]
    prev_sig_c = sig_c.iloc[-2]
    curr_macd_c = macd_c.iloc[-1]
    curr_sig_c = sig_c.iloc[-1]
    
    if (prev_macd_c <= prev_sig_c) and (curr_macd_c > curr_sig_c):
        is_strat_2 = True

    # --- 5. ê²°ê³¼ ë°˜í™˜ ---
    status_list = []
    if is_strat_1: status_list.append("ëŒíŒŒìˆ˜ë ´(ëˆŒë¦¼)")
    if is_strat_2: status_list.append("MACDë§¤ìˆ˜")
    
    if status_list:
        final_status = " / ".join(status_list)
        return True, {
            'price': curr['Close'], 
            'atr': curr['ATR14'], 
            'bw_curr': 0, 
            'bw_change': final_status, 
            'macdv': curr['MACD_V']
        }
    
    return False, None

def check_monthly_condition(df):
    if len(df) < 12: return False, None
    ath_price = df['High'].max()
    curr_price = df['Close'].iloc[-1]
    if curr_price >= ath_price * 0.90:
        ath_idx = df['High'].idxmax()
        month_count = (df['Close'] >= ath_price * 0.90).sum()
        return True, {'price': curr_price, 'ath_price': ath_price, 'ath_date': ath_idx.strftime('%Y-%m'), 'month_count': month_count}
    return False, None

# [ì›ë˜ ë¡œì§ í•¨ìˆ˜ ìœ ì§€]
def analyze_momentum_strategy_single_ticker(item):
    # ë‹¨ì¼ ì¢…ëª© ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬ìš©)
    t, n, type_name = item
    try:
        rt, df = smart_download(t, "1d", "2y")
        if len(df)<30: return None
        df = calculate_daily_indicators(df)
        if df is None: return None
        c = df['Close']; curr=c.iloc[-1]
        squeeze_on = df['TTM_Squeeze'].iloc[-5:].any() if 'TTM_Squeeze' in df.columns else False
        ema20=c.ewm(span=20).mean(); ema50=c.ewm(span=50).mean(); ema60=c.ewm(span=60).mean()
        ema100=c.ewm(span=100).mean(); ema200=c.ewm(span=200).mean()
        bb_up = df['BB50_UP']; dc_h = df['Donchian_High_50'] 
        macdv = df['MACD_V']; atr = df['ATR14'].iloc[-1]
        bb_bk = "O" if (c>bb_up).iloc[-3:].any() else "-"
        dc_bk = "O" if (c>dc_h).iloc[-3:].any() else "-"
        align = "â­ ì •ë°°ì—´" if (curr>ema20.iloc[-1] and curr>ema60.iloc[-1] and curr>ema100.iloc[-1] and curr>ema200.iloc[-1]) else "-"
        long_tr = "ğŸ“ˆ ìƒìŠ¹" if (ema60.iloc[-1]>ema100.iloc[-1]>ema200.iloc[-1]) else "-"
        
        # [ë³€ê²½] ì „ëµ 3: í‰ê·  ëª¨ë©˜í…€ (Smoothed)
        r12 = c.pct_change(252).iloc[-1] if len(c) > 252 else 0
        r6  = c.pct_change(126).iloc[-1] if len(c) > 126 else 0
        r3  = c.pct_change(63).iloc[-1] if len(c) > 63 else 0
        r1  = c.pct_change(21).iloc[-1] if len(c) > 21 else 0
        
        avg_long_term = (r12 + r6) / 2
        score = ((avg_long_term - r3) + r1) * 100
        
        if len(df) >= 252:
            win_52 = df.iloc[-252:]
            high_idx = win_52['Close'].idxmax()
            high_52_date = high_idx.strftime('%Y-%m-%d')
            prev_win = win_52[win_52.index < high_idx]
            if len(prev_win) > 0:
                prev_idx = prev_win['Close'].idxmax()
                prev_date = prev_idx.strftime('%Y-%m-%d')
                diff_days = (high_idx - prev_idx).days
            else:
                prev_date = "-"; diff_days = 0
        else:
            high_52_date = "-"; prev_date = "-"; diff_days = 0
            
        return {
            f"{type_name}": f"{rt} ({n})", 
            "ëª¨ë©˜í…€ì ìˆ˜": score, 
            "ìŠ¤í€´ì¦ˆ": "ğŸ”¥" if squeeze_on else "-", 
            "BB(50,2)ëŒíŒŒ": bb_bk, 
            "ëˆí‚¤ì–¸(50)ëŒíŒŒ": dc_bk, 
            "ì •ë°°ì—´": align, 
            "ì¥ê¸°ì¶”ì„¸": long_tr, 
            "MACD-V": f"{macdv.iloc[-1]:.2f}", 
            "ATR": f"{atr:.2f}",
            "í˜„52ì£¼ì‹ ê³ ê°€ì¼": high_52_date,
            "ì „52ì£¼ì‹ ê³ ê°€ì¼": prev_date,
            "ì°¨ì´ì¼": f"{diff_days}ì¼",
            "í˜„ì¬ê°€": curr
        }
    except:
        return None

def analyze_momentum_strategy_parallel(target_list, type_name="ETF"):
    # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
    if not target_list: return pd.DataFrame()
    
    st.write(f"ğŸ“Š ì´ {len(target_list)}ê°œ {type_name} ë¶„ì„ ì¤‘ (ë³‘ë ¬ ì²˜ë¦¬)...")
    
    # ì‘ì—… ëª©ë¡ ìƒì„±
    tasks = [(t, n, type_name) for t, n in target_list]
    results = run_parallel_analysis(tasks, analyze_momentum_strategy_single_ticker)

    if results:
        df_res = pd.DataFrame(results).sort_values("ëª¨ë©˜í…€ì ìˆ˜", ascending=False)
        df_res['ëª¨ë©˜í…€ì ìˆ˜'] = df_res['ëª¨ë©˜í…€ì ìˆ˜'].apply(lambda x: f"{x:.2f}")
        df_res['í˜„ì¬ê°€'] = df_res['í˜„ì¬ê°€'].apply(lambda x: f"{x:,.2f}")
        return df_res
    return pd.DataFrame()

def check_cup_handle_pattern(df):
    if len(df) < 26: return False, None
    sub = df.iloc[-26:].copy()
    if len(sub) < 26: return False, None
    idx_A = sub['High'].idxmax(); val_A = sub.loc[idx_A, 'High']
    if idx_A == sub.index[-1]: return False, "Aê°€ ëì "
    after_A = sub.loc[idx_A:]
    if len(after_A) < 5: return False, "ê¸°ê°„ ì§§ìŒ"
    idx_B = after_A['Low'].idxmin(); val_B = after_A.loc[idx_B, 'Low']
    if val_B > val_A * 0.85: return False, "ê¹Šì´ ì–•ìŒ"
    after_B = sub.loc[idx_B:]
    if len(after_B) < 2: return False, "ë°˜ë“± ì§§ìŒ"
    idx_C = after_B['High'].idxmax(); val_C = after_B.loc[idx_C, 'High']
    if val_C < val_A * 0.85: return False, "íšŒë³µ ë¯¸ë‹¬"
    curr_close = df['Close'].iloc[-1]<br>    if curr_close < val_B: return False, "í•¸ë“¤ ë¶•ê´´"<br>    if curr_close < val_C * 0.80: return False, "í•¸ë“¤ ê¹ŠìŒ"<br>    return True, {"depth": f"{(1 - val_B/val_A)*100:.1f}%", "handle_weeks": f"{len(df.loc[idx_C:])}ì£¼", "pivot": f"{val_C:,.0f}"}<br><br>def check_inverse_hs_pattern(df):<br>    if len(df) < 60: return False, None<br>    window = 60; sub = df.iloc[-window:].copy()<br>    if len(sub) < 60: return False, None<br>    part1 = sub.iloc[:20]; part2 = sub.iloc[20:40]; part3 = sub.iloc[40:]<br>    min_L = part1['Low'].min(); min_H = part2['Low'].min(); min_R = part3['Low'].min()<br>    if not (min_H < min_L and min_H < min_R): return False, "ë¨¸ë¦¬ ë¯¸í˜•ì„±"<br>    max_R = part3['High'].max(); curr_close = df['Close'].iloc[-1]<br>    if curr_close < min_R * 1.05: return False, "ë°˜ë“± ì•½í•¨"<br>    vol_recent = part3['Volume'].mean(); vol_prev = part2['Volume'].mean()<br>    vol_ratio = vol_recent / vol_prev if vol_prev > 0 else 1.0<br>    return True, {"Neckline": f"{max_R:,.0f}", "Breakout": "Ready" if curr_close < max_R else "Yes", "Vol_Ratio": f"{vol_ratio:.1f}ë°°"}<br><br># -----------------------------------------------------------------------------<br># [NEW] ë‚˜ì¹¨íŒìš© ì „ëµ ë¶„ì„ í•¨ìˆ˜ (ìµœì í™”)<br># -----------------------------------------------------------------------------<br>def get_compass_signal():<br>    # 1. ì„¤ì • (ìˆ˜ì •ë¨: SPY->SCHD, EFA->IMTM, EEM->EMGF)<br>    OFFENSE = ["QQQ", "SCHD", "IMTM", "GLD", "EMGF"]<br>    CASH = "BIL"<br>    ALL_TICKERS = list(set(OFFENSE + [CASH]))<br>    <br>    # 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœê·¼ 2ë…„ì¹˜ë§Œ)<br>    try:<br>        data = yf.download(ALL_TICKERS, period="2y", progress=False, auto_adjust=False)['Close']<br>        if data.empty: return None, "ë°ì´í„° ì—†ìŒ"<br>    except:<br>        return None, "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"<br><br>    # 3. ì›”ë´‰ ë¦¬ìƒ˜í”Œë§<br>    monthly_data = data.resample('ME').last()<br>    <br>    if len(monthly_data) < 13: return None, "ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 13ê°œì›” í•„ìš”)"<br><br>    # 4. ì§€í‘œ ê³„ì‚° (ë§ˆì§€ë§‰ ì‹œì  ê¸°ì¤€)<br>    # pct_changeëŠ” (í˜„ì¬ - ê³¼ê±°) / ê³¼ê±°<br>    m12 = monthly_data.pct_change(12).iloc[-1]<br>    m6  = monthly_data.pct_change(6).iloc[-1]<br>    m3  = monthly_data.pct_change(3).iloc[-1]<br>    m1  = monthly_data.pct_change(1).iloc[-1]<br><br>    # 5. ì „ëµ 3 (Smoothed) ìŠ¤ì½”ì–´ ê³„ì‚°<br>    # ê³µì‹: ((12M + 6M) / 2 - 3M) + 1M<br>    scores = {}<br>    for ticker in OFFENSE:<br>        if ticker not in m12.index: continue<br>        <br>        r12 = m12[ticker]<br>        r6  = m6[ticker]<br>        r3  = m3[ticker]<br>        r1  = m1[ticker]<br>        <br>        # NaN ì²´í¬<br>        if np.isnan(r12): continue<br>        <br>        avg_long = (r12 + r6) / 2<br>        score = (avg_long - r3) + r1<br>        scores[ticker] = {<br>            "Score": score * 100,<br>            "12M_Trend": r12 # ì ˆëŒ€ ëª¨ë©˜í…€ í™•ì¸ìš©<br>        }<br>    <br>    if not scores: return None, "ê³„ì‚° ë¶ˆê°€"<br><br>    # 6. ìˆœìœ„ ì‚°ì •<br>    df_scores = pd.DataFrame(scores).T<br>    df_scores = df_scores.sort_values("Score", ascending=False)<br>    <br>    best_ticker = df_scores.index[0]<br>    best_score = df_scores.iloc[0]['Score']<br>    best_trend = df_scores.iloc[0]['12M_Trend']<br>    <br>    # 7. í¬ì§€ì…˜ ê²°ì • (ì ˆëŒ€ ëª¨ë©˜í…€ í•„í„°)<br>    final_position = best_ticker if (best_score > 0 and best_trend > 0) else CASH<br>    <br>    return df_scores, final_position<br><br># ==========================================<br># [ì¶”ê°€] ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜ (í•µì‹¬)<br># ==========================================<br>def run_parallel_analysis(items, func, max_workers=10):<br>    """<br>    ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ì™€ ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ë°›ì•„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜<br>    """<br>    results = []<br>    bar = st.progress(0)<br>    status_text = st.empty()<br>    total = len(items)<br>    <br>    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:<br>        # Future ê°ì²´ ìƒì„±<br>        future_to_item = {executor.submit(func, item): item for item in items}<br>        <br>        completed_count = 0<br>        for future in concurrent.futures.as_completed(future_to_item):<br>            try:<br>                data = future.result()<br>                if data:<br>                    results.append(data)<br>            except Exception as e:<br>                pass # ì—ëŸ¬ ë°œìƒ ì‹œ ê±´ë„ˆëœ€<br>            <br>            completed_count += 1<br>            bar.progress(completed_count / total)<br>            status_text.text(f"â³ ë³‘ë ¬ ë¶„ì„ ì§„í–‰ ì¤‘... ({completed_count}/{total})")<br>            <br>    bar.empty()<br>    status_text.empty()<br>    return results<br><br># --- ê° ë²„íŠ¼ì— ë§¤í•‘ë  ë³‘ë ¬ ì‘ì—… í•¨ìˆ˜ë“¤ ---<br>def task_vcp(t):<br>    try:<br>        t_clean = t.strip()<br>        final_ticker, df = smart_download(t_clean, "1d", "2y")<br>        if len(df) < 250: return None<br>        passed, info = check_vcp_pattern(df)<br>        if passed:<br>            eps1w, eps1m, eps3m = get_eps_changes_from_db(final_ticker)<br>            weekly_macd_status = get_weekly_macd_status(df)<br>            sector = get_stock_sector(final_ticker)<br>            return {<br>                'ì¢…ëª©ì½”ë“œ': final_ticker, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': info['price'],<br>                'ë¹„ê³ ': info['status'], 'ì£¼ë´‰MACD': weekly_macd_status,<br>                'ì†ì ˆê°€': info['stop_loss'], 'ëª©í‘œê°€(3R)': info['target_price'],<br>                'ìŠ¤í€´ì¦ˆ': info['squeeze'], '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                'Pivot': info['pivot'], 'chart_df': df, 'chart_info': info # ì°¨íŠ¸ìš© ë°ì´í„° í¬í•¨<br>            }<br>    except: return None<br><br>def task_daily(t):<br>    try:<br>        rt, df = smart_download(t, "1d", "2y")<br>        passed, info = check_daily_condition(df)<br>        if passed:<br>            eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>            sector = get_stock_sector(rt)<br>            return {<br>                'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': info['price'],<br>                'ATR(14)': info['atr'], 'ìŠ¤í€´ì¦ˆ': info['squeeze'],<br>                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info['prev_date'],<br>                'ì°¨ì´ì¼': f"{info['diff_days']}ì¼", 'BWí˜„ì¬': info['bw_curr'],<br>                'MACD-V': info['macdv'], 'BW_Value': info['bw_curr'], 'MACD_V_Value': info['macdv']<br>            }<br>    except: return None<br><br>def task_weekly(t):<br>    try:<br>        rt, df = smart_download(t, "1wk", "2y")<br>        passed, info = check_weekly_condition(df)<br>        if passed:<br>            eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>            sector = get_stock_sector(rt)<br>            return {<br>                'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': info['price'],<br>                'ATR(14ì£¼)': info['atr'], 'êµ¬ë¶„': info['bw_change'],<br>                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                'MACD-V': info['macdv'], 'BW_Value': info['bw_curr'], 'MACD_V_Value': info['macdv']<br>            }<br>    except: return None<br><br>def task_monthly(t):<br>    try:<br>        rt, df = smart_download(t, "1mo", "max")<br>        passed, info = check_monthly_condition(df)<br>        if passed:<br>            eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>            sector = get_stock_sector(rt)<br>            return {<br>                'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': info['price'],<br>                'ATHìµœê³ ê°€': info['ath_price'], 'ATHë‹¬ì„±ì›”': info['ath_date'],<br>                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info['month_count']}ê°œì›”",<br>                'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info['ath_date'], 'BW_Value': str(info['month_count']), 'MACD_V_Value': "0"<br>            }<br>    except: return None<br><br>def task_cup(t):<br>    try:<br>        rt, df = smart_download(t, "1wk", "2y")<br>        pass_c, info = check_cup_handle_pattern(df)<br>        if pass_c:<br>            df = calculate_common_indicators(df, True)<br>            if df is None: return None<br>            curr = df.iloc[-1]<br>            sector = get_stock_sector(rt)<br>            eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>            return {<br>                'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': curr['Close'],<br>                'íŒ¨í„´ìƒì„¸': f"ê¹Šì´:{info['depth']}", 'ëŒíŒŒê°€ê²©': info['pivot'],<br>                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                'BW_Value': curr['BandWidth'], 'MACD_V_Value': curr['MACD_V']<br>            }<br>    except: return None<br><br>def task_hs(t):<br>    try:<br>        rt, df = smart_download(t, "1wk", "2y")<br>        pass_h, info = check_inverse_hs_pattern(df)<br>        if pass_h:<br>            df = calculate_common_indicators(df, True)<br>            if df is None: return None<br>            curr = df.iloc[-1]<br>            sector = get_stock_sector(rt)<br>            eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>            return {<br>                'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': curr['Close'],<br>                'ë„¥ë¼ì¸': info['Neckline'], 'ê±°ë˜ëŸ‰ê¸‰ì¦': info['Vol_Ratio'],<br>                '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                'BW_Value': curr['BandWidth'], 'MACD_V_Value': curr['MACD_V']<br>            }<br>    except: return None<br><br># ==========================================<br># 5. ë©”ì¸ ì‹¤í–‰ í™”ë©´ (UI ì›ìƒë³µê·€)<br># ==========================================<br><br># [ë³€ê²½] íƒ­ ìˆœì„œ ë³€ê²½: ë‚˜ì¹¨íŒ(tab_compass)ì„ ë§¨ ì•ìœ¼ë¡œ<br>tab_compass, tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ§­ ë‚˜ì¹¨íŒ", "ğŸŒ ì„¹í„°", "ğŸ³ï¸ êµ­ê°€", "ğŸ“Š ê¸°ìˆ ì  ë¶„ì„", "ğŸ’° ì¬ë¬´ë¶„ì„", "ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­"])<br><br># -----------------------------------------------------------------------------<br># [íƒ­ 1] ë‚˜ì¹¨íŒ (ê°€ì¥ ì™¼ìª½ìœ¼ë¡œ ì´ë™)<br># -----------------------------------------------------------------------------<br>with tab_compass:<br>    st.markdown("### ğŸ§­ íˆ¬ì ë‚˜ì¹¨íŒ (Smoothed Momentum Strategy)")<br>    st.markdown("""<br>    ì´ íƒ­ì€ **'ì „ëµ 3 (í‰ê·  ëª¨ë©˜í…€)'** ë¡œì§ì„ ê¸°ë°˜ìœ¼ë¡œ **í˜„ì¬ ì‹œì (Today)**ì—ì„œ ê°€ì¥ ë§¤ë ¥ì ì¸ ìì‚°ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.<br>    <br>    **ì „ëµ ë¡œì§:**<br>    1. **í›„ë³´êµ°:** QQQ(ë‚˜ìŠ¤ë‹¥), SCHD(ë°°ë‹¹ì„±ì¥), IMTM(ì„ ì§„êµ­ëª¨ë©˜í…€), GLD(ê¸ˆ), EMGF(ì‹ í¥êµ­ë©€í‹°íŒ©í„°)<br>    2. **ì ìˆ˜ ì‚°ì¶œ:** `((12ê°œì›”+6ê°œì›”)/2 - 3ê°œì›”) + 1ê°œì›”` ìˆ˜ìµë¥ <br>    3. **ë°©ì–´ ê¸°ì œ:** 1ë“± ì¢…ëª©ì˜ 12ê°œì›” ìˆ˜ìµë¥ ì´ ë§ˆì´ë„ˆìŠ¤ë©´ **í˜„ê¸ˆ(BIL)** ë³´ìœ <br>    """)<br>    <br>    if st.button("ğŸš€ ì§€ê¸ˆ ì–´ë””ì— íˆ¬ìí•´ì•¼ í• ê¹Œ? (ë¶„ì„ ì‹œì‘)", type="primary"):<br>        with st.spinner("ìµœê·¼ 2ë…„ì¹˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°©í–¥ì„ ì¡ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):<br>            df_result, position = get_compass_signal()<br>            <br>            if df_result is not None:<br>                col1, col2 = st.columns(2)<br>                with col1:<br>                    st.success(f"ğŸ¯ í˜„ì¬ ì¶”ì²œ í¬ì§€ì…˜: **{position}**")<br>                    if position == "BIL":<br>                        st.caption("ğŸš¨ ì‹œì¥ ìƒí™©ì´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜„ê¸ˆ(ì´ˆë‹¨ê¸°ì±„)ìœ¼ë¡œ ëŒ€í”¼í•˜ì„¸ìš”.")<br>                    else:<br>                        st.caption(f"ğŸš€ ìƒìŠ¹ ëª¨ë©˜í…€ì´ ê°€ì¥ ê°•í•œ **{position}**ì— ì˜¬ë¼íƒ€ì„¸ìš”!")<br>                <br>                with col2:<br>                    top_score = df_result.iloc[0]['Score']<br>                    st.metric("1ë“± ëª¨ë©˜í…€ ì ìˆ˜", f"{top_score:.2f}ì ")<br><br>                st.markdown("---")<br>                st.markdown("#### ğŸ“Š ìì‚°ë³„ ìƒì„¸ ìŠ¤ì½”ì–´ (ë†’ì€ ìˆœ)")<br>                <br>                df_display = df_result.copy()<br>                df_display['Score'] = df_display['Score'].apply(lambda x: f"{x:.2f}")<br>                df_display['12M_Trend'] = df_display['12M_Trend'].apply(lambda x: f"{x*100:.1f}%")<br>                df_display.columns = ["ëª¨ë©˜í…€ ì ìˆ˜", "12ê°œì›” ì¶”ì„¸(ì ˆëŒ€)"]<br>                <br>                st.dataframe(df_display, use_container_width=True)<br>            else:<br>                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {position}")<br><br># -----------------------------------------------------------------------------<br># [íƒ­ 2] ì„¹í„° (ë‘ ë²ˆì§¸ë¡œ ì´ë™)<br># -----------------------------------------------------------------------------<br>with tab1:<br>    cols = st.columns(12) <br>    if cols[0].button("ğŸŒ ì„¹í„°"):<br>        etfs = get_etfs_from_sheet()<br>        if not etfs: st.warning("ETF ëª©ë¡ ì—†ìŒ")<br>        else:<br>            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë³€ê²½<br>            res = analyze_momentum_strategy_parallel(etfs, "ETF")<br>            if not res.empty: st.dataframe(res, use_container_width=True)<br>            else: st.warning("ë°ì´í„° ë¶€ì¡±")<br><br># -----------------------------------------------------------------------------<br># [íƒ­ 3] êµ­ê°€ (ê¸°ì¡´ ìœ„ì¹˜ ìœ ì§€)<br># -----------------------------------------------------------------------------<br>with tab2:<br>    cols = st.columns(12)<br>    if cols[0].button("ğŸ³ï¸ êµ­ê°€"):<br>        tickers = get_country_etfs_from_sheet()<br>        if not tickers: st.warning("êµ­ê°€ ETF ëª©ë¡ ì—†ìŒ")<br>        else:<br>            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë³€ê²½<br>            res = analyze_momentum_strategy_parallel(tickers, "êµ­ê°€ETF")<br>            if not res.empty:<br>                st.success(f"[êµ­ê°€] {len(res)}ê°œ ë¶„ì„ ì™„ë£Œ!")<br>                st.dataframe(res, use_container_width=True)<br>            else: st.warning("ë°ì´í„° ë¶€ì¡±")<br><br># -----------------------------------------------------------------------------<br># [íƒ­ 4] ê¸°ìˆ ì  ë¶„ì„ (VCP í¬í•¨)<br># -----------------------------------------------------------------------------<br>with tab3:<br>    cols = st.columns(12)<br>    <br>    # [VCP ë²„íŠ¼] ë³‘ë ¬ ì²˜ë¦¬ ì ìš©<br>    if cols[0].button("ğŸŒªï¸ VCP"):<br>        tickers = get_tickers_from_sheet()<br>        if not tickers: st.warning("ì¢…ëª© ë¦¬ìŠ¤íŠ¸(TGT) ì—†ìŒ")<br>        else:<br>            st.info(f"êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì´ **{len(tickers)}**ê°œ ì¢…ëª©ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤ (ë³‘ë ¬ ë¶„ì„).")<br>            <br>            # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰<br>            res = run_parallel_analysis(tickers, task_vcp, max_workers=20)<br>            <br>            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ì´ {len(res)}ê°œ ë°œê²¬.")<br>            <br>            if res:<br>                # ì°¨íŠ¸ ë°ì´í„°ì™€ í‘œì‹œ ë°ì´í„° ë¶„ë¦¬<br>                display_data = []<br>                chart_data_cache = {}<br>                for r in res:<br>                    row = r.copy()<br>                    chart_data_cache[row['ì¢…ëª©ì½”ë“œ']] = {'df': row.pop('chart_df'), 'info': row.pop('chart_info')}<br>                    # ìˆ«ì í¬ë§·íŒ…<br>                    row['í˜„ì¬ê°€'] = f"{row['í˜„ì¬ê°€']:,.0f}"<br>                    row['ì†ì ˆê°€'] = f"{row['ì†ì ˆê°€']:,.0f}"<br>                    row['ëª©í‘œê°€(3R)'] = f"{row['ëª©í‘œê°€(3R)']:,.0f}"<br>                    row['Pivot'] = f"{row['Pivot']:,.0f}"<br>                    display_data.append(row)<br><br>                df_res = pd.DataFrame(display_data).sort_values("ë¹„ê³ ", ascending=False)<br>                st.dataframe(df_res, use_container_width=True)<br>                <br>                # 4ë‹¨ê³„ ëŒíŒŒ ì¢…ëª© ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬<br>                breakout_targets = [r for r in display_data if "4ë‹¨ê³„" in r['ë¹„ê³ ']]<br>                if breakout_targets:<br>                    st.markdown("---")<br>                    st.markdown("### ğŸš€ ëŒíŒŒ ì¢…ëª© ì°¨íŠ¸ ê°¤ëŸ¬ë¦¬ (Step 4)")<br>                    for i in range(0, len(breakout_targets), 2):<br>                        c1, c2 = st.columns(2)<br>                        # ì™¼ìª½<br>                        item1 = breakout_targets[i]<br>                        t1 = item1['ì¢…ëª©ì½”ë“œ']<br>                        if t1 in chart_data_cache:<br>                            fig1 = plot_vcp_chart(chart_data_cache[t1]['df'], t1, chart_data_cache[t1]['info'])<br>                            c1.plotly_chart(fig1, use_container_width=True)<br>                            c1.caption(f"**{t1}** | {item1['ì£¼ë´‰MACD']}")<br>                        # ì˜¤ë¥¸ìª½<br>                        if i + 1 < len(breakout_targets):<br>                            item2 = breakout_targets[i+1]<br>                            t2 = item2['ì¢…ëª©ì½”ë“œ']<br>                            if t2 in chart_data_cache:<br>                                fig2 = plot_vcp_chart(chart_data_cache[t2]['df'], t2, chart_data_cache[t2]['info'])<br>                                c2.plotly_chart(fig2, use_container_width=True)<br>                                c2.caption(f"**{t2}** | {item2['ì£¼ë´‰MACD']}")<br>                <br>                save_to_supabase(display_data, "VCP_Pattern")<br>            else: st.warning("VCP ì¡°ê±´(ì¶”ì„¸+ìˆ˜ë ´)ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")<br><br>    if cols[1].button("ğŸš€ ì¼ë´‰"):<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            st.info(f"[ì¼ë´‰ 5-Factor] {len(tickers)}ê°œ ë³‘ë ¬ ë¶„ì„ ì‹œì‘...")<br>            res = run_parallel_analysis(tickers, task_daily, max_workers=20)<br>            <br>            if res:<br>                st.success(f"[ì¼ë´‰] {len(res)}ê°œ ë°œê²¬!")<br>                # í¬ë§·íŒ…<br>                df = pd.DataFrame(res)<br>                for c in ['í˜„ì¬ê°€', 'ATR(14)']: df[c] = df[c].apply(lambda x: f"{x:,.0f}" if isinstance(x,(int,float)) else x)<br>                for c in ['BWí˜„ì¬', 'MACD-V']: df[c] = df[c].apply(lambda x: f"{x:.2f}" if isinstance(x,(int,float)) else x)<br>                <br>                st.dataframe(df.drop(columns=['BW_Value', 'MACD_V_Value']), use_container_width=True)<br>                save_to_supabase(res, "Daily_5Factor")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    if cols[2].button("ğŸ“… ì£¼ë´‰"):<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            st.info(f"[ì£¼ë´‰] {len(tickers)}ê°œ ë³‘ë ¬ ë¶„ì„ ì‹œì‘...")<br>            res = run_parallel_analysis(tickers, task_weekly, max_workers=20)<br>            if res:<br>                st.success(f"[ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")<br>                df = pd.DataFrame(res)<br>                for c in ['í˜„ì¬ê°€', 'ATR(14ì£¼)']: df[c] = df[c].apply(lambda x: f"{x:,.0f}" if isinstance(x,(int,float)) else x)<br>                for c in ['MACD-V']: df[c] = df[c].apply(lambda x: f"{x:.2f}" if isinstance(x,(int,float)) else x)<br>                st.dataframe(df.drop(columns=['BW_Value', 'MACD_V_Value']), use_container_width=True)<br>                save_to_supabase(res, "Weekly")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    if cols[3].button("ğŸ—“ï¸ ì›”ë´‰"):<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            st.info(f"[ì›”ë´‰] {len(tickers)}ê°œ ë³‘ë ¬ ë¶„ì„ ì‹œì‘...")<br>            res = run_parallel_analysis(tickers, task_monthly, max_workers=20)<br>            if res:<br>                st.success(f"[ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")<br>                df = pd.DataFrame(res)<br>                for c in ['í˜„ì¬ê°€', 'ATHìµœê³ ê°€']: df[c] = df[c].apply(lambda x: f"{x:,.0f}" if isinstance(x,(int,float)) else x)<br>                st.dataframe(df.drop(columns=['BW_Value', 'MACD_V_Value'], errors='ignore'), use_container_width=True)<br>                save_to_supabase(res, "Monthly_ATH")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    # [í†µí•©] ê¸°ëŠ¥ì€ ë„ˆë¬´ ë³µì¡í•´ì„œ ì¼ë‹¨ ì§ë ¬ë¡œ ìœ ì§€í•˜ê±°ë‚˜, í•„ìš” ì‹œ ìœ„ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥ (ì—¬ê¸°ì„  ê¸°ì¡´ ì§ë ¬ ìœ ì§€)<br>    if cols[4].button("ì¼+ì›”ë´‰"):<br>        st.info("í†µí•© ë¶„ì„(ì¼+ì›”)ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ìˆœì°¨ ì‹¤í–‰ë©ë‹ˆë‹¤.")<br>        # ê¸°ì¡´ ë¡œì§ ìœ ì§€... (ìƒëµ ì—†ì´ ì›ë³¸ ì½”ë“œ ì‹¤í–‰)<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            bar = st.progress(0); res = []<br>            for i, t in enumerate(tickers):<br>                bar.progress((i+1)/len(tickers))<br>                rt, df_d = smart_download(t, "1d", "2y")<br>                pass_d, info_d = check_daily_condition(df_d)<br>                if not pass_d: continue<br>                _, df_m = smart_download(t, "1mo", "max")<br>                pass_m, info_m = check_monthly_condition(df_m)<br>                if not pass_m: continue<br>                sector = get_stock_sector(rt)<br>                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>                res.append({<br>                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",<br>                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ATHë‹¬ì„±ì›”': info_m['ath_date'],<br>                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                    'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",<br>                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],<br>                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': str(info_m['month_count']), 'MACD_V_Value': f"{info_d['macdv']:.2f}"<br>                })<br>            bar.empty()<br>            if res:<br>                st.success(f"[ì¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")<br>                st.dataframe(pd.DataFrame(res))<br>                save_to_supabase(res, "Daily_Monthly")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    if cols[5].button("ì¼+ì£¼ë´‰"):<br>        st.info("í†µí•© ë¶„ì„(ì¼+ì£¼) ìˆœì°¨ ì‹¤í–‰ ì¤‘...")<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            bar = st.progress(0); res = []<br>            for i, t in enumerate(tickers):<br>                bar.progress((i+1)/len(tickers))<br>                rt, df_d = smart_download(t, "1d", "2y")<br>                pass_d, info_d = check_daily_condition(df_d)<br>                if not pass_d: continue<br>                _, df_w = smart_download(t, "1wk", "2y")<br>                pass_w, info_w = check_weekly_condition(df_w)<br>                if not pass_w: continue<br>                sector = get_stock_sector(rt)<br>                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>                res.append({<br>                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",<br>                    'ìŠ¤í€´ì¦ˆ': info_d['squeeze'], 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰êµ¬ë¶„': info_w['bw_change'],<br>                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],<br>                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_d['macdv']:.2f}"<br>                })<br>            bar.empty()<br>            if res:<br>                st.success(f"[ì¼+ì£¼ë´‰] {len(res)}ê°œ ë°œê²¬!")<br>                st.dataframe(pd.DataFrame(res))<br>                save_to_supabase(res, "Daily_Weekly")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    if cols[6].button("ì£¼+ì›”ë´‰"):<br>        st.info("í†µí•© ë¶„ì„(ì£¼+ì›”) ìˆœì°¨ ì‹¤í–‰ ì¤‘...")<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            bar = st.progress(0); res = []<br>            for i, t in enumerate(tickers):<br>                bar.progress((i+1)/len(tickers))<br>                rt, df_w = smart_download(t, "1wk", "2y")<br>                pass_w, info_w = check_weekly_condition(df_w)<br>                if not pass_w: continue<br>                _, df_m = smart_download(t, "1mo", "max")<br>                pass_m, info_m = check_monthly_condition(df_m)<br>                if not pass_m: continue<br>                sector = get_stock_sector(rt)<br>                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>                res.append({<br>                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_w['price']:,.0f}",<br>                    'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}", 'ì£¼ë´‰êµ¬ë¶„': info_w['bw_change'],<br>                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                    'ATHë‹¬ì„±ì›”': info_m['ath_date'], 'ê³ ê¶Œì—­(ì›”ìˆ˜)': f"{info_m['month_count']}ê°œì›”",<br>                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_m['ath_date'], 'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"<br>                })<br>            bar.empty()<br>            if res:<br>                st.success(f"[ì£¼+ì›”ë´‰] {len(res)}ê°œ ë°œê²¬!")<br>                st.dataframe(pd.DataFrame(res))<br>                save_to_supabase(res, "Weekly_Monthly")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    if cols[7].button("âš¡ í†µí•©"):<br>        st.info("í†µí•©(ì¼+ì£¼+ì›”) ìˆœì°¨ ì‹¤í–‰ ì¤‘...")<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            bar = st.progress(0); res = []<br>            for i, t in enumerate(tickers):<br>                bar.progress((i+1)/len(tickers))<br>                rt, df_d = smart_download(t, "1d", "2y")<br>                pass_d, info_d = check_daily_condition(df_d)<br>                if not pass_d: continue<br>                _, df_w = smart_download(t, "1wk", "2y")<br>                pass_w, info_w = check_weekly_condition(df_w)<br>                if not pass_w: continue<br>                _, df_m = smart_download(t, "1mo", "max")<br>                pass_m, info_m = check_monthly_condition(df_m)<br>                if not pass_m: continue<br>                sector = get_stock_sector(rt)<br>                eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>                res.append({<br>                    'ì¢…ëª©ì½”ë“œ': rt, 'ì„¹í„°': sector, 'í˜„ì¬ê°€': f"{info_d['price']:,.0f}",<br>                    'ATHìµœê³ ê°€': f"{info_m['ath_price']:,.0f}", 'ATHë‹¬ì„±ì›”': info_m['ath_date'],<br>                    'í•´ë‹¹ì›”ìˆ˜': f"{info_m['month_count']}ê°œì›”", 'ìŠ¤í€´ì¦ˆ': info_d['squeeze'],<br>                    '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                    'í˜„52ì£¼ì‹ ê³ ê°€ì¼': info_d['high_date'], 'ì „52ì£¼ì‹ ê³ ê°€ì¼': info_d['prev_date'],<br>                    'ì°¨ì´ì¼': f"{info_d['diff_days']}ì¼", 'ì£¼ë´‰BW': f"{info_w['bw_curr']:.4f}",<br>                    'ì£¼ë´‰êµ¬ë¶„': info_w['bw_change'], 'MACD-V': f"{info_w['macdv']:.2f}",<br>                    'BW_Value': f"{info_w['bw_curr']:.4f}", 'MACD_V_Value': f"{info_w['macdv']:.2f}"<br>                })<br>            bar.empty()<br>            if res:<br>                st.success(f"âš¡ í†µí•© ë¶„ì„ ì™„ë£Œ! {len(res)}ê°œ ë°œê²¬")<br>                st.dataframe(pd.DataFrame(res).drop(columns=['BW_Value', 'MACD_V_Value']))<br>                save_to_supabase(res, "Integrated_Triple")<br>            else: st.warning("3ê°€ì§€ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")<br><br>    if cols[8].button("ğŸ† ì»µí•¸ë“¤"):<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            st.info("[ì»µí•¸ë“¤] ë³‘ë ¬ ë¶„ì„ ì‹œì‘...")<br>            res = run_parallel_analysis(tickers, task_cup, max_workers=20)<br>            if res:<br>                st.success(f"[ì»µí•¸ë“¤] {len(res)}ê°œ ë°œê²¬!")<br>                df = pd.DataFrame(res)<br>                for c in ['í˜„ì¬ê°€', 'ëŒíŒŒê°€ê²©']: df[c] = df[c].apply(lambda x: f"{x:,.0f}" if isinstance(x,(int,float)) else x)<br>                st.dataframe(df)<br>                save_to_supabase(res, "CupHandle")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    if cols[9].button("ğŸ‘¤ ì—­H&S"):<br>        tickers = get_tickers_from_sheet()<br>        if tickers:<br>            st.info("[ì—­H&S] ë³‘ë ¬ ë¶„ì„ ì‹œì‘...")<br>            res = run_parallel_analysis(tickers, task_hs, max_workers=20)<br>            if res:<br>                st.success(f"[ì—­H&S] {len(res)}ê°œ ë°œê²¬!")<br>                df = pd.DataFrame(res)<br>                for c in ['í˜„ì¬ê°€', 'ë„¥ë¼ì¸']: df[c] = df[c].apply(lambda x: f"{x:,.0f}" if isinstance(x,(int,float)) else x)<br>                st.dataframe(df)<br>                save_to_supabase(res, "InverseHS")<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>    st.markdown("### ğŸ“‰ ì €ì¥ëœ ì¢…ëª© ì¤‘ ëˆŒë¦¼ëª©/ê¸‰ë“±ì£¼ ì°¾ê¸°")<br>    if st.button("ğŸ” ëˆŒë¦¼ëª© & ê¸‰ë“± íŒ¨í„´ ë¶„ì„"):<br>        db_tickers = get_unique_tickers_from_db()<br>        if not db_tickers: st.warning("DB ë°ì´í„° ì—†ìŒ")<br>        else:<br>            st.info(f"{len(db_tickers)}ê°œ ì¢…ëª© ì¬ë¶„ì„ ì¤‘...")<br>            bar = st.progress(0); res = []<br>            for i, t in enumerate(db_tickers):<br>                bar.progress((i+1)/len(db_tickers))<br>                rt, df = smart_download(t, "1d", "2y")<br>                try:<br>                    df = calculate_common_indicators(df, False)<br>                    if df is None: continue<br>                    curr = df.iloc[-1]<br>                    cond = ""<br>                    if curr['MACD_V'] > 60: cond = "ğŸ”¥ ê³µê²©ì  ì¶”ì„¸"<br>                    ema20 = df['Close'].ewm(span=20).mean().iloc[-1]<br>                    if (curr['Close'] > ema20) and ((curr['Close']-ema20)/ema20 < 0.03): cond = "ğŸ“‰ 20ì¼ì„  ëˆŒë¦¼ëª©"<br>                    if (curr['Close'] > curr['EMA200']) and (-100 <= curr['MACD_V'] <= -50): cond = "ğŸ§² MACD-V ê³¼ë§¤ë„"<br>                    if cond:<br>                        eps1w, eps1m, eps3m = get_eps_changes_from_db(rt)<br>                        res.append({<br>                            'ì¢…ëª©ì½”ë“œ': rt, 'íŒ¨í„´': cond, 'í˜„ì¬ê°€': f"{curr['Close']:,.0f}",<br>                            '1Wë³€í™”': eps1w, '1Më³€í™”': eps1m, '3Më³€í™”': eps3m,<br>                            'MACD-V': f"{curr['MACD_V']:.2f}", 'EMA20': f"{ema20:,.0f}"<br>                        })<br>                except: continue<br>            bar.empty()<br>            if res:<br>                st.success(f"{len(res)}ê°œ ë°œê²¬!")<br>                st.dataframe(pd.DataFrame(res), use_container_width=True)<br>            else: st.warning("ì¡°ê±´ ë§Œì¡± ì—†ìŒ")<br><br>with tab4:<br>    st.markdown("### ğŸ’° ì¬ë¬´ ì§€í‘œ ë¶„ì„ & EPS Trend (yfinance)")<br>    if st.button("ğŸ“Š ì¬ë¬´ ì§€í‘œ ê°€ì ¸ì˜¤ê¸°"):<br>        tickers = get_tickers_from_sheet()<br>        if not tickers: st.error("í‹°ì»¤ ì—†ìŒ")<br>        else:<br>            # ì¬ë¬´ ì •ë³´ëŠ” yfinance í˜¸ì¶œ ì œí•œì´ ì‹¬í•´ ë³‘ë ¬ ì‹œ ì˜¤ë¥˜ê°€ ë§ìœ¼ë¯€ë¡œ ìˆœì°¨ ì‹¤í–‰ ìœ ì§€<br>            bar = st.progress(0); f_res = []<br>            for i, t in enumerate(tickers):<br>                bar.progress((i + 1) / len(tickers))<br>                real_ticker, _ = smart_download(t, "1d", "5d") <br>                try:<br>                    tick = yf.Ticker(real_ticker)<br>                    info = tick.info<br>                    if not info: continue<br>                    mkt_cap = info.get('marketCap', 0)<br>                    mkt_cap_str = f"{mkt_cap/1000000000000:.1f}ì¡°" if mkt_cap > 1000000000000 else f"{mkt_cap/100000000:.0f}ì–µ" if mkt_cap else "-"<br>                    rev_growth = info.get('revenueGrowth', 0)<br>                    rev_str = f"{rev_growth*100:.1f}%" if rev_growth else "-"<br>                    eps_growth = info.get('earningsGrowth', 0)<br>                    eps_growth_str = f"{eps_growth*100:.1f}%" if eps_growth else "-"<br>                    fwd_eps = info.get('forwardEps', '-')<br>                    peg = info.get('pegRatio', '-')<br>                    try:<br>                        trend_data = tick.eps_trend<br>                        if trend_data:<br>                            curr_year_data = trend_data[0] <br>                            curr_est = curr_year_data.get('current', 0)<br>                            ago30 = curr_year_data.get('30daysAgo', 0)<br>                            ago90 = curr_year_data.get('90daysAgo', 0)<br>                            trend_30 = "â†—ï¸" if curr_est > ago30 else "â†˜ï¸" if curr_est < ago30 else "-"<br>                            trend_90 = "â†—ï¸" if curr_est > ago90 else "â†˜ï¸" if curr_est < ago90 else "-"<br>                            eps_trend_str = f"30ì¼{trend_30} | 90ì¼{trend_90}"<br>                        else: eps_trend_str = "-"<br>                    except: eps_trend_str = "-"<br>                    rec = info.get('recommendationKey', '-').upper().replace('_', ' ')<br>                    target = info.get('targetMeanPrice')<br>                    curr_p = info.get('currentPrice', 0)<br>                    upside = f"{(target - curr_p) / curr_p * 100:.1f}%" if (target and curr_p) else "-"<br>                    eps1w, eps1m, eps3m = get_eps_changes_from_db(real_ticker)<br>                    f_res.append({<br>                        "ì¢…ëª©": real_ticker, "ì„¹í„°": info.get('sector', '-'), "ì‚°ì—…": info.get('industry', '-'),<br>                        "ì‹œê°€ì´ì•¡": mkt_cap_str, "ë§¤ì¶œì„±ì¥(YoY)": rev_str, "EPSì„±ì¥(YoY)": eps_growth_str,<br>                        "ì„ í–‰EPS": fwd_eps, "PEG": peg, "EPSì¶”ì„¸(ì˜¬í•´)": eps_trend_str,<br>                        "1Wë³€í™”": eps1w, "1Më³€í™”": eps1m, "3Më³€í™”": eps3m,<br>                        "íˆ¬ìì˜ê²¬": rec, "ìƒìŠ¹ì—¬ë ¥": upside<br>                    })<br>                except Exception as e: continue<br>            bar.empty()<br>            if f_res:<br>                df_fin = pd.DataFrame(f_res)<br>                st.success(f"âœ… ì´ {len(df_fin)}ê°œ ê¸°ì—… ì¬ë¬´/EPS ë¶„ì„ ì™„ë£Œ")<br>                st.dataframe(df_fin, use_container_width=True)<br>            else: st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")<br><br>with tab5:<br>    st.markdown("### ğŸ“‚ ì—‘ì…€ ë°ì´í„° ë§¤ì¹­ (í€€í‹°ì™€ì´ì¦ˆ DB ì—°ë™)")<br>    col_upload, col_reset = st.columns([3, 1])<br>    with col_upload:<br>        uploaded_file = st.file_uploader("ğŸ“¥ quant_master.xlsx íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx'])<br>    with col_reset:<br>        st.write("") <br>        st.write("") <br>        if st.button("ğŸ—‘ï¸ [ì£¼ì˜] DB ì´ˆê¸°í™” (ì „ì²´ ì‚­ì œ)", type="primary"):<br>            try:<br>                supabase.table("quant_data").delete().neq("id", 0).execute()<br>                st.success("DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")<br>                fetch_latest_quant_data_from_db.clear()<br>            except Exception as e:<br>                st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")<br><br>    show_debug_log = st.checkbox("ğŸ” ë””ë²„ê¹… ë¡œê·¸ ë³´ê¸°")<br><br>    def parse_sheet_ticker_value(sheet_df, allowed_tickers, debug_mode=False):<br>        extracted = {}<br>        for index, row in sheet_df.iterrows():<br>            try:<br>                raw_ticker = str(row[0]).strip()<br>                if not raw_ticker or raw_ticker.lower() in ['code', 'ticker', 'nan', 'item type', 'comparison date']: continue<br>                norm_ticker = normalize_ticker_for_db_storage(raw_ticker)<br>                if debug_mode and "RKLB" in norm_ticker: st.write(f"ğŸ“¢ [DEBUG] ë°œê²¬ëœ í‹°ì»¤: {raw_ticker} -> ì •ê·œí™”: {norm_ticker}")<br>                if norm_ticker not in allowed_tickers: continue<br>                val = row[3] <br>                if pd.isna(val): final_val = "-"<br>                else:<br>                    final_val = str(val).strip()<br>                    if final_val.lower() == 'nan' or final_val == "": final_val = "-"<br>                extracted[norm_ticker] = final_val<br>            except Exception: continue<br>        return extracted<br><br>    if uploaded_file and st.button("ğŸ”„ DB ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘"):<br>        try:<br>            st.info("êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê´€ë¦¬ ì¢…ëª©(TGT) ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")<br>            tgt_stocks = get_tickers_from_sheet()<br>            tgt_etfs = [x[0] for x in get_etfs_from_sheet()]<br>            tgt_countries = [x[0] for x in get_country_etfs_from_sheet()]<br>            raw_targets = set(tgt_stocks + tgt_etfs + tgt_countries)<br>            allowed_db_tickers = set()<br>            for t in raw_targets:<br>                t_clean = t.split('.')[0] <br>                t_clean = t_clean.split('-')[0]<br>                allowed_db_tickers.add(t_clean)<br>            <br>            st.success(f"ê´€ë¦¬ ëŒ€ìƒ ì¢…ëª© {len(allowed_db_tickers)}ê°œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")<br>            xls = pd.read_excel(uploaded_file, sheet_name=None, header=None, dtype=str)<br>            sheet_map = {'1w': None, '1m': None, '3m': None}<br>            for sheet_name in xls.keys():<br>                s_name = sheet_name.lower().strip()<br>                if '1w' in s_name: sheet_map['1w'] = xls[sheet_name]<br>                elif '1m' in s_name: sheet_map['1m'] = xls[sheet_name]<br>                elif '3m' in s_name: sheet_map['3m'] = xls[sheet_name]<br>            <br>            if not (sheet_map['1w'] is not None and sheet_map['1m'] is not None and sheet_map['3m'] is not None):<br>                st.error("ì—‘ì…€ íŒŒì¼ì— 1w, 1m, 3m ì‹œíŠ¸ê°€ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")<br>            else:<br>                data_1w = parse_sheet_ticker_value(sheet_map['1w'], allowed_db_tickers, show_debug_log)<br>                data_1m = parse_sheet_ticker_value(sheet_map['1m'], allowed_db_tickers, show_debug_log)<br>                data_3m = parse_sheet_ticker_value(sheet_map['3m'], allowed_db_tickers, show_debug_log)<br>                all_tickers = set(data_1w.keys()) | set(data_1m.keys()) | set(data_3m.keys())<br>                <br>                if not all_tickers: st.warning("ë§¤ì¹­ë˜ëŠ” ë°ì´í„° ì—†ìŒ")<br>                else:<br>                    today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')<br>                    existing_map = {}<br>                    try:<br>                        res = supabase.table("quant_data").select("*").gte("created_at", f"{today_str} 00:00:00").lte("created_at", f"{today_str} 23:59:59").execute()<br>                        if res.data:<br>                            for rec in res.data:<br>                                existing_map[rec['ticker']] = (str(rec.get('change_1w') or "-"), str(rec.get('change_1m') or "-"), str(rec.get('change_3m') or "-"))<br>                    except: pass<br>                    <br>                    rows_to_insert = []<br>                    skipped_count = 0<br>                    for t in all_tickers:<br>                        v_1w = data_1w.get(t, "-"); v_1m = data_1m.get(t, "-"); v_3m = data_3m.get(t, "-")<br>                        if t in existing_map:<br>                            e_1w, e_1m, e_3m = existing_map[t]<br>                            if (e_1w == v_1w) and (e_1m == v_1m) and (e_3m == v_3m):<br>                                skipped_count += 1<br>                                continue<br>                        rows_to_insert.append({"ticker": t, "change_1w": v_1w, "change_1m": v_1m, "change_3m": v_3m})<br>                    <br>                    if rows_to_insert:<br>                        chunk_size = 100<br>                        for i in range(0, len(rows_to_insert), chunk_size):<br>                            chunk = rows_to_insert[i:i+chunk_size]<br>                            supabase.table("quant_data").insert(chunk).execute()<br>                        st.success(f"âœ… DB ì—…ë¡œë“œ ì™„ë£Œ! (ì‹ ê·œ: {len(rows_to_insert)}ê±´, ì¤‘ë³µìƒëµ: {skipped_count}ê±´)")<br>                        fetch_latest_quant_data_from_db.clear()<br>                        GLOBAL_QUANT_DATA = fetch_latest_quant_data_from_db()<br>                    else: st.info(f"ë³€ë™ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. (ì¤‘ë³µ ìƒëµ: {skipped_count}ê±´)")<br>        except Exception as e: st.error(f"ì‘ì—… ì‹¤íŒ¨: {e}")<br><br>    st.markdown("---")<br>    if st.button("ë°ì´í„° ì¡°íšŒí•˜ê¸°"):<br>        try:<br>            response = supabase.table("quant_data").select("ticker, change_1w, change_1m, change_3m").order("created_at", desc=True).execute()<br>            if response.data: st.dataframe(pd.DataFrame(response.data), use_container_width=True)<br>            else: st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")<br>        except Exception as e: st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")<br><br>st.markdown("---")<br>with st.expander("ğŸ—„ï¸ ì „ì²´ ì €ì¥ ê¸°ë¡ ë³´ê¸° / ê´€ë¦¬"):<br>    col_e1, col_e2 = st.columns([1, 1])<br>    with col_e1:<br>        if st.button("ğŸ”„ ê¸°ë¡ ìƒˆë¡œê³ ì¹¨"):<br>            try:<br>                response = supabase.table("history").select("*").order("created_at", desc=True).limit(50).execute()<br>                if response.data: st.dataframe(pd.DataFrame(response.data), use_container_width=True)<br>            except Exception as e: st.error(str(e))<br>    with col_e2:<br>        if st.button("ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ (ìµœì‹ ë³¸ë§Œ ìœ ì§€)"):<br>            remove_duplicates_from_db()<br>```
